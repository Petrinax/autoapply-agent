{
  "https://www.linkedin.com/jobs/view/4268164368": {
    "job_url": "https://www.linkedin.com/jobs/view/4268164368",
    "job_summary": "SDE II - Backend Engineer\nSDE II - Backend Engineer with verification\nLivspace\nBengaluru, Karnataka, India (On-site)\n2 company alumni work here\n2 Walmart Global Tech India company alumni work here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nWe are seeking a talented and motivated Software Development Engineer II (SDE-II) to join our dynamic engineering team. As an SDE-II , you will be responsible for contributing to the development and maintenance of software applications. \n\nKey Responsibilities:\n\nWrite efficient, well-documented, and maintainable code using best practices.\nAnalyze and troubleshoot software defects and issues, providing timely resolutions.\nContribute to identifying and implementing improvements in the development process.\nWork closely with team members, including product managers, designers, and other developers, to deliver robust and scalable software solutions.\nDevelop and execute unit tests to ensure the reliability and correctness of code.\nCollaborate with quality assurance teams to identify and address software defects.\nCreate and maintain technical documentation, including design documents, coding standards, and release notes.\nActively participate in professional development activities and seek opportunities for continuous learning.\nStrong understanding of software development fundamentals and principles.\nKnowledge of data structures, algorithms, and object-oriented design.\nExcellent problem-solving and analytical skills.\nGood communication and collaboration skills.\nAbility to work effectively in a fast-paced and dynamic team environment.\n\n\n\n\nSkills And Expertise\n\nB.Tech/B.E. in Computer Science, Information Technology, or equivalent from a top-tier institute.\n3+ years of experience with software development\nExceptional written and verbal communication skills.\nExperience with one or more programming languages (e.g., Java, Python, Go).\nFamiliarity with version control systems (e.g., Git).\nUnderstanding of software development methodologies (e.g., Agile, Scrum)",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4263365607": {
    "job_url": "https://www.linkedin.com/jobs/view/4263365607",
    "job_summary": "Data Engineer 2\nData Engineer 2\nYubi\nBangalore Urban, Karnataka, India (On-site)\nActively reviewing applicants\nApplied",
    "job_details": "About the job\n\nData Engineer 2\n\nPosition Summary:\n\n As a Data Engineer, you will be part of a highly talented Data Engineering team. Responsible for developing reusable capabilities and tools to automate various types of data processing pipelines. You will be contributing to different stages of data engineering like data acquisition, ingestion, processing, monitoring pipelines and validating data.\n\nYour contribution will be really crucial in keeping various data ingestion and processing pipelines running successfully. Along with ensuring the data points available in the data lake are up to date, valid and usable. \n\nTechnology Experience:\n\n3+ years of experience in data engineering.\nComfortable and hands on with the Python programming.\nStrong experience in working with RDBMS and NoSQL systems.\nStrong experience in working on AWS ecosystem with hands-on experience in working with different AWS components like Airflow, EMR , Redshift, S3, Athena, PySpark etc.\nStrong experience in developing REST APIs with Python using frameworks like flask, fastapi.\nPrior experience in working with crawling libraries like BeautifulSoup in Python would be desirable.\nProven ability to work with SQL queries, including writing complex queries to retrieve key metrics. Skilled in connecting to, exploring, and understanding upstream data.\nExperience working with various data lake storage format types and ability to choose it based on the use cases.\n\nResponsibilities:\n\nDesign and build scalable data pipelines that can handle large volumes of data.\nDevelop ETL/ELT pipelines and extract the data from any upstream sources and sync with the data lakes with the format of parquet, iceberg, delta formats. \nOptimize and ensure the data pipelines are running successfully and ensure the business continuity.\nCollaborate with cross functional teams and source all the data required for the business use cases.\nStay up-to-date with emerging data technologies and trends to ensure the continuous improvement of our data infrastructure and architecture\nFollow best practices in data querying and manipulation to ensure data integrity.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": true,
    "easy_apply": false
  },
  "https://www.linkedin.com/jobs/view/4254829630": {
    "job_url": "https://www.linkedin.com/jobs/view/4254829630",
    "job_summary": "Python Developer\nPython Developer with verification\nRecro\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nLocation: Bengaluru, on-site\n\n\n\n\nExperience: 3-6 yrs\n\n\n\n\nNotice Period: Immediate\n\n\n\n\nNote: Last round of interview would be face-to-face\n\n\n\n\nKey Responsibilities:\n\n\n\n\nWrite clean, maintainable, and efficient Python code.\nDesign and implement scalable backend solutions using Python frameworks (e.g., Django, Flask, FastAPI).\nIntegrate with databases such as PostgreSQL, MySQL, or MongoDB.\nDevelop and maintain RESTful APIs.\nCollaborate with front-end developers, designers, and other team members to deliver high-quality products.\nWrite unit and integration tests to ensure code quality.\nOptimize applications for maximum performance and scalability.\nParticipate in code reviews and mentor junior developers if needed.\n\n\n\n\nRequired Skills & Qualifications:\n\n\n\n\nStrong proficiency in Python and understanding of OOP principles.\nHands-on experience with one or more Python web frameworks (Django, Flask, FastAPI).\nExperience with relational and non-relational databases.\nFamiliarity with version control tools (e.g., Git).\nKnowledge of RESTful API design and integration.\nExperience with cloud platforms (AWS, GCP, or Azure) is a plus.\nUnderstanding of CI/CD processes is a bonus.\nBachelors degree in Computer Science, Engineering, or a related field.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4208146636": {
    "job_url": "https://www.linkedin.com/jobs/view/4208146636",
    "job_summary": "Software Engineer (Backend)\nSoftware Engineer (Backend) with verification\nGames24x7\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nCompany Overview:\n\n\n\n\nGames24x7 is Indias leading and most valuable multi-gaming unicorn. Were a full-stack gaming company, offering awesome game-playing experiences to over 100 million players through our products - Rummy Circle, Indias first and largest online rummy platform, My11Circle, the countrys fastest-growing fantasy sports platform.\n\nA pioneer in the online skill gaming industry in India, Games24x7 was founded in 2006 when two New York University-trained economists Bhavin Pandya, and Trivikraman Thampy met at the computer lab and discovered their shared passion for online games. Weve always been a technology company at heart, and over the last decade and a half, weve built the organisation on a strong foundation of the science of gaming, leveraging behavioural science, artificial intelligence, and machine learning to provide immersive and hyper-personalised gaming experiences to each of our players.\n\nBacked by marquee investors including Tiger Global Management, The Raine Group, and Malabar Investment Advisors, Games24x7 is leading the charge in Indias gaming revolution, constantly innovating and offering novel entertainment to players!\n\nOur 800+ passionate teammates create their magic from our offices in Mumbai, Bengaluru, New Delhi, Miami.\n\nFor more information and career opportunities you may visit www.games24x7.com.\n\n\n\n\nSummary of Role\n\n\n\n\nThe SDE-1 will be part of the Engineering/Development team in Play Games24x7 Pvt. Ltd. and will be responsible for taking ownership of the core products of the company. The applicant must have good communication, interpersonal, technical and analytical skills in order to take part in the collaborative and cooperative development process that delivers the high quality software we use to provide the best possible playing experience to our players. The applicant must be an expert in the Java programming language and needs to be familiar with popular IDEs, tools and scripting languages on the Linux operating system. Familiarity with an RDBMS, preferably MySQL, is essential to succeed in this position.\n\n\n\n\nResponsibilities\n\n\n\n\n Participation in the requirements analysis, design, development and testing of applications.\n\n The candidate is expected to write code himself/herself.\n\n The candidate is expected to write code, code review, unit testing and deployment.\n\n Practical application of design principles with a focus on the user experience, usability, template designs, and client server concepts.\n\n Contributes to the development of project estimates, scheduling, and deliverables.\n\n Works closely with QA team to determine testing requirements to ensure full coverage and best quality of product.\n\n There is also the opportunity to mentor and guide junior team members in excelling their jobs.\n\n\n\n\nRequirements\n\n\n\n\n BE/B. Tech. from a reputed University.\n\n 1-3 Years of experience in software development, with emphasis on JAVA/J2EE Server side programming.\n\n Hands on experience in Core Java, Multithreading, RMI, Socket programming, JDBC, NIO, webservices and Design patterns.\n\n Should have Knowledge of distributed system, distributed caching, messaging frameworks, ESB etc.\n\n Knowledge of Linux operating system and PostgreSQL/MySQL/MongoDB/Cassandra database is essential.\n\n Familiarity with message queue systems and AMQP and Kafka is desirable.\n\n Should have experience as a participant in Agile methodologies.\n\n Should have excellent written and verbal communication skills and presentation skills.\n\n This is not a Fullstack requirement, we are purely looking out for Backend resources.\n\n\n\n\n*Games24x7 is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, colour, religion, sex, disability status, or any other characteristic protected by the law.*",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4266999791": {
    "job_url": "https://www.linkedin.com/jobs/view/4266999791",
    "job_summary": "Software Engineer\nSoftware Engineer\nGet Well\nBengaluru, Karnataka, India (On-site)\nViewed\nEasy Apply",
    "job_details": "About the job\n\nTitle: Software Engineer\n\nReporting to: Senior Director, Product Development\n\nLocation: Bengaluru (Bangalore)\n\nOpportunity\n\nGet Well is seeking a technically adept Software Engineer to implement scalable, secure services and processing systems within a regulated healthcare environment. This role is ideal for an early-career engineer eager to grow their skills in a dynamic, mission-driven team.\n\nResponsibilities\n\nPlatform Development Support\n\nAssist in designing, developing, and testing microservices and APIs (REST and FHIR) to support AI agents, clinical applications, and external integrations.Implement platform components under the guidance of senior engineers and architects, ensuring alignment with enterprise goals for scalability and reliability.Write clean, maintainable, and efficient code using modern programming frameworks (e.g., Spring Boot, Node.js, or Python Flask/FastAPI).\n\nSystem Maintenance & Optimization\n\n\nSupport the maintenance and optimization of platform services to ensure performance, scalability, and reliability in a healthcare-critical environment.\nAssist in implementing monitoring, logging, and alerting mechanisms to maintain system health and support issue resolution.\nParticipate in debugging and resolving technical issues under the mentorship of senior team members.\n\n\nCompliance & Security\n\n\nAdhere to secure coding practices and healthcare regulatory requirements (e.g., HIPAA, GDPR) as directed by senior engineers and governance teams.\nAssist in implementing data privacy measures, such as encryption and access controls, to ensure compliance with healthcare standards.\nSupport audit logging and documentation efforts to maintain traceability and compliance.\n\n\nCollaboration & Agile Practices\n\n\nCollaborate with cross-functional teams, including data engineers, AI/ML engineers, and product managers, to deliver integrated solutions.\nActively participate in agile development processes, including sprint planning, daily stand-ups, and retrospectives, to contribute to team goals.\nEngage in code reviews to learn best practices and improve code quality under the guidance of senior engineers.\n\n\nLearning & Growth\n\n\nStay informed about software engineering trends, cloud-native technologies, and healthcare interoperability standards through training and mentorship.\nContribute to prototyping and evaluating new tools or frameworks to enhance platform capabilities.\nActively seek feedback and apply best practices to grow technical expertise in software development.\n\n\nRequirements\n\nEducation & Experience\n\n\nBachelors or Masters degree in Computer Science or related technical discipline\n13 years of experience in software development, including internships, academic projects, or entry-level roles\nExposure to designing or implementing backend services or APIs is a plus.\n\n\nTechnical Proficiency\n\n\nProficiency in at least one programming language such as Java, Python, or JavaScript/TypeScript for building APIs or backend services.\nBasic understanding of cloud platforms (e.g., AWS, Azure, Google Cloud) and containerization technologies (e.g., Docker) is a plus.\nFamiliarity with API development frameworks (e.g., Spring Boot, FastAPI, Express.js) or version control systems (e.g., Git).\n\n\nProfessional Skills\n\n\nStrong problem-solving skills with a willingness to learn and tackle technical challenges.\nGood collaboration and communication skills, with the ability to work effectively in a team-oriented environment.\nProactive, detail-oriented, and eager to grow in a fast-paced, innovative setting.\n\n\nAbout Get Well\n\nNow part of the SAI Group family, Get Well is redefining digital patient engagement by putting patients in control of their personalized healthcare journeys, both inside and outside the hospital. Get Well is combining high-tech AI navigation with high-touch care experiences driving patient activation, loyalty, and outcomes while reducing the cost of care. For almost 25 years, Get Well has served more than 10 million patients per year across over 1,000 hospitals and clinical partner sites, working to use longitudinal data analytics to better serve patients and clinicians. AI innovator SAI Group led by Chairman Romesh Wadhwani is the lead growth investor in Get Well. Get Wells award-winning solutions were recognized again in 2024 by KLAS Research and AVIA Marketplace. Learn more at Get Well and follow-us on LinkedIn and Twitter.\n\nGet Well is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age or veteran status.\n\nAbout SAI Group\n\n\nSAIGroup commits to $1 Billion capital, an advanced AI platform that currently processes 300M+ patients, and 4000+ global employee base to solve enterprise AI and high priority healthcare problems. SAIGroup - Growing companies with advanced AI; https://www.cnbc.com/2023/12/08/75-year-old-tech-mogul-betting-1-billion-of-his-fortune-on-ai-future.html\nBio of our Chairman Dr. Romesh Wadhwani: Team - SAIGroup (Informal at Romesh Wadhwani - Wikipedia)\nTIME Magazine recently recognized Chairman Romesh Wadhwani as one of the Top 100 AI leaders in the world - Romesh and Sunil Wadhwani: The 100 Most Influential People in AI 2023 | TIME",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4259506224": {
    "job_url": "https://www.linkedin.com/jobs/view/4259506224",
    "job_summary": "Software Engineer\nSoftware Engineer with verification\nBrightEdge\nIndia (Remote)\nActively reviewing applicants\nApplied",
    "job_details": "About the job\n\nJob Description: Full Stack Engineer\n\nLocation: INDIA, Remote\n\nExperience: 4  6 years\n\nEmployment Type: Full time\n\nAbout the Role:\n\nWe are looking for a highly skilled Full Stack Engineer with 4 6 years of experience who is proficient in JavaScript, ReactJS, Python, databases, and cloud platforms (AWS/GCP). The ideal candidate should have experience working in fast-paced environments, preferably in startups, and be comfortable handling both front-end and back-end development.\n\n\n\n\nKey Responsibilities:\n\nDesign, develop, and maintain scalable web applications using ReactJS and Python.\nBuild and optimize APIs and backend services for high performance and scalability.\nWork with databases (SQL/NoSQL) for data modeling and efficient storage solutions.\nDeploy, manage, and optimize applications in AWS/GCP cloud environments.\nCollaborate with cross-functional teams to define, design, and ship new features.\nEnsure application security, performance, and maintainability.\nTroubleshoot, debug, and upgrade existing applications.\nFollow best practices in coding, testing, and DevOps for continuous improvement.\n\n\n\n\nRequired Skills & Qualifications:\n\n4  6 years of experience in full stack development.\nExpertise in JavaScript (ReactJS), Python, and backend development.\nStrong knowledge of databases (SQL & NoSQL) and data management.\nExperience with AWS or GCP cloud services for deployment and infrastructure management.\nFamiliarity with microservices architecture, RESTful APIs, and serverless computing.\nUnderstanding of CI/CD pipelines, Docker, and Kubernetes is a plus.\nExperience working in fast-moving, startup environments.\nStrong problem-solving skills, ability to work independently and in a team.\n\nWhy Join Us?\n\nOpportunity to work on cutting-edge technology in a dynamic environment.\nA fast-paced startup culture with rapid learning and growth opportunities.\nCompetitive salary, flexible work environment, and exciting challenges.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": true,
    "easy_apply": false
  },
  "https://www.linkedin.com/jobs/view/4270271859": {
    "job_url": "https://www.linkedin.com/jobs/view/4270271859",
    "job_summary": "Software Engineer\nSoftware Engineer with verification\nIQVIA\nBengaluru, Karnataka, India (Hybrid)\nCompany review time is typically 1 week\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nRole : Software development Engineer\n\nExperience : 1 Years to 3 Years\n\nJob Location : Kochi/Bangalore\n\n\n\n\nJob Description Summary\n\nWe are seeking a motivated and skilled MDM Developer to join our dynamic team focusing on Reltio MDM and ETL processes. The ideal candidate will possess 1 to 2 years of experience in ETL development, SQL queries and a strong background in database management. This role requires a proactive individual who can work collaboratively with project leads and independently manage tasks with good judgment.\n\n\n\n\nResponsibilities:\n\nCollaborate closely with project leads to execute assigned tasks effectively.\nDesign and develop MDM and ETL interfaces tailored to client specifications ensuring alignment with business objectives.\nProvide support in identifying and resolving production issues ensuring minimal disruption to operations.\nDocument work procedures and processes in accordance with established standards maintaining comprehensive records.\nDeliver high-quality code to the QA team ensuring thorough testing and validation.\nParticipate actively in peer reviews to uphold coding standards and improve overall code quality.\nMaintain and update standards documents ensuring compliance with organizational policies.\nAdhere to Quality Information Management System (QIMS) policies and standards promoting best practices.\nDemonstrate a solid understanding of the Software Development Life Cycle (SDLC).\nExperience with Agile or iterative development methodologies is advantageous.\nExhibit strong communication and collaboration skills fostering a positive team environment.\nQuickly grasp complex concepts and processes applying them effectively in project tasks.\nDisplay excellent time management and organizational skills prioritizing tasks efficiently.\nWork independently with minimal supervision exercising sound judgment in decision-making.\n\n\n\n\nTechnical Skills/Experience:\n\n1 to 3 years of experience in ETL development with proficiency in SQL queries and database management.\nHands-on experience with any ETL tool for at least 1 year.\nFamiliarity with Reltio MDM.\nProficient in Oracle PL/SQL with the ability to write and optimize queries.\nKnowledge of REST API and JSON is a plus.\nExperience with Python and/or Java is beneficial enhancing integration capabilities.\n\n\n\n\nAdditional Information:\n\nShift: General shift\nWork Mode: Hybrid with locations in Bangalore/Kochi/Pune\nCandidates should be willing to work from the office twice a week.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4270252510": {
    "job_url": "https://www.linkedin.com/jobs/view/4270252510",
    "job_summary": "Software Engineer\nSoftware Engineer with verification\nSquarepoint\nBangalore Urban, Karnataka, India (Hybrid)\nCompany review time is typically 1 week\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nPosition Overview:\n\nManage delivery of strategic initiatives in Order entry and Drop copy flows, owning projects from start to finish.\nWork closely with developers and stakeholders on business and technical scoping of new projects.\nGather and refine requirement for venue onboarding both from internal and external stakeholders, coordinate and deliver implementation from front to back.\nWrite and review technical documentation such as exchange specifications, migration plans.\nOwn migrations such as hardware changes or moving our applications from classic to new generation platforms.\nClearly identifying and resolving blockers for our development teams from external dependencies.\nProvide regular progress status reporting to stakeholders,\nManage communication with external vendors, exchanges, and providers to push forward the interests of the firm\nIdentify efficiency gaps on the team and work diligently to resolve them\n\n\n\n\nRequired Qualifications:\n\nBachelors degree in Computer Science, Engineering, or related subject\nAtleast 2 years of relevant experience as systems integrator and exposure to Exchange Connectivity.\nProficiency in Linux OS\nProficiency in FIX protocol\nGood understanding of Trade Life Cycle.\nExperience with Business-Driven Software integration, Application Lifecycle Management, Change and Release management.\nGreat communication skills, both verbal and written.\nAbility to clearly articular concepts in both a technical and non-technical manner\nHighly organized with excellent attention to detail\nExperience with Jira and Confluence\n\n\n\n\nNice to have:\n\nProject management / technical business analyst experience\nProficiency in C++ or Python\nFamiliarity with CI/CD pipelines\nFinancial knowledge across various asset classes .",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4268488545": {
    "job_url": "https://www.linkedin.com/jobs/view/4268488545",
    "job_summary": "Quant Developer\nQuant Developer\nOptimusPrime Securities and Research LLP\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob Description: Quant Developer\n\n\n\n\nJob Summary\n\n\n\n\nAs a Quant Developer at OptimusPrime Research, you will work closely with quantitative researchers and traders to design, implement, and optimize high-performance trading algorithms and analytical tools. You will play a key role in bridging the gap between research and production, ensuring that our strategies are robust, scalable, and efficient.\n\n\n\n\nKey Responsibilities\n\n\n\n\n Collaborate with quantitative researchers to implement and optimize trading strategies and models.\n\n Develop and maintain high-performance, low-latency trading systems and infrastructure.\n\n Design and implement tools for data analysis, back testing, and simulation of trading strategies.\n\n Work with large datasets to build and improve data pipelines for research and production.\n\n Ensure code quality, reliability, and scalability through rigorous testing and code reviews.\n\n Stay up-to-date with the latest technologies and methodologies in quantitative finance and software development.\n\n Troubleshoot and resolve issues in real-time trading environments.\n\n\n\n\nQualifications\n\n\n\n\no Bachelors, Masters, or PhD in Computer Science, Mathematics, Physics, Engineering, or a related field.\n\no 2+ years of experience in software development\n\no Strong programming skills in C++. Experience with Python libraries (e.g., NumPy, pandas, scikit-learn) is a plus.\n\no Experience with high-performance computing, parallel processing, and low-latency systems.\n\no Familiarity with financial markets, trading concepts, and quantitative finance.\n\no Strong problem-solving and analytical skills.\n\no Excellent communication and collaboration abilities.\n\no Ability to work in a fast-paced, dynamic environment.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4267746084": {
    "job_url": "https://www.linkedin.com/jobs/view/4267746084",
    "job_summary": "Python Developer\nPython Developer with verification\nCAST\nGreater Bengaluru Area (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout CAST\n\nBusinesses move faster using CAST technology to understand, improve, and transform their software. Through semantic analysis of source code, CAST produces 3D maps and dashboards to navigate inside individual applications and across entire portfolios. This intelligence empowers executives and technology leaders to steer, speed, and report on initiatives such as technical debt, GenAI, modernization, and cloud. As the pioneer of the software intelligence field, CAST is trusted by the worlds leading companies and governments, their consultancies and cloud providers. See it all castsoftware.com.\n\n\n\n\nRole Expectations: \n\nThe successful candidate will be an intelligent, highly energetic self-starter with excellent communication, technical skills with a solid technical background in the application development world. Experience of working in Automation, DevOps, scripting is mandatory. \n\nPrior experience in working with SQL Queries would be a big plus. \n\nAnd you love and understand complex technologies, and always seek out engaging technical discussions and has the appetite to work in a fast-paced consulting environment.\n\n\n\n\nResponsibilities: \n\nYou will help address AIP (CASTs product) integration with various customers DevOps pipeline, proposing solutions to optimize their onboarding and rescans, writing scripts to automate client manual activities and handling infrastructure activities in order to automate as much as possible. You will achieve this by working closely with our Managed Services team in our Bangalore office (which is our internal client). \n\nYou will leverage the tools & expertise from our corporate Information Technology team located in France and in Bangalore.\n\n\n\n\nRole combines a thorough understanding of the product and recommending the CAST solutions. \n\n\n\n\nSolution Oriented Mindset\n\nLead project in all technical aspects of tooling and DevOps\nProactively lead tools new versions release cycle and documentation\nProactively identify risks related to application /deliverables and propose a mitigation plan\nProvide custom solutions as per customer requirements\n\n\n\n\nAutonomy & Problem Solving Mindset\n\nWork in complete autonomy to deliver project deliverables, for advanced technical deliverables, with required level of quality\nMust have troubleshooting skills \n\n\n\n\nAgile Mindset\n\nContribute to improvement of internal process, tooling, and quality process\nDesign, build and collect technical materials as part of project executions in a spirit of reusability for future engagements and maintain knowledge on best practices, tools, and reusable components for CAST analysis\n\n\n\n\nExperience of the AD world, excellent problem solving & solution-oriented skills, communication skills and a very strong drive are key characteristics for success. \n\n\n\n\nQualifications:\n\nBachelors Degree (or equivalent) in a technical discipline.\nMinimum of 2+ years of strong hands-on knowledge of Python 3.\nStrong hands-on experience in relational DB using PostgreSQL/ MySQL/ MSSQL/ Oracle etc.\nKnowledge of GIT / GitHub or any SCM tool is essential.\nKnowledge of Atlassian tools like Jira, Confluence is an added advantage.\nUnderstanding of CI/CD (Jenkins / TeamCity / Bamboo / Gitlab pipelines).\nSome exposure to J2EE/.Net technologies will be an added advantage.\nShould be able to research and learn new technologies rapidly.\nExcellent communication skills (oral and written) including an ability to communicate effectively at senior levels within client organizations.\nStrong knowledge of the Application Development world is mandatory.\nAbility to work independently toward stated business goals.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4262801170": {
    "job_url": "https://www.linkedin.com/jobs/view/4262801170",
    "job_summary": "Software Development Engineer II (BFSI)\nSoftware Development Engineer II (BFSI) with verification\nRupeek\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nApplied",
    "job_details": "About the job\n\nAbout Rupeek:\n\nRupeek, established in 2015 and headquartered in Bangalore, stands as India's leading asset-backed digital lending fintech platform. Committed to making credit accessible to Indians in a fair and convenient manner, Rupeek pioneers innovative financial products focused on monetizing India's $2 trillion gold market. Leveraging state-of-the-art technology and an automated asset-light supply chain, Rupeek is transforming the gold loan disbursal landscape across 40+ cities in India. With a customer base exceeding 5,00,000+, the company's strategic partnerships with top banks and financial institutions underscore its commitment to building gold-backed assets through low-risk, low-touch, and friction-free processes. Rupeek's impressive journey is supported by key investors such as Sequoia Capital, Accel Partners, Bertelsmann, and GGV Capital. Join us in redefining the future of finance through innovation, technology, and a commitment to financial incivility.\n\n\n\n\nJob Title: Software Development Engineer - II\n\nEducation: B.Tech / Dual Degree with Computer Science as a major discipline, MCA.\n\nExperience: 4.5-7 Years\n\nLocation: Bangalore\n\n\n\n\nMust Have: \n\n Understanding of algorithms and data structures\n\n Should have worked with MVC frameworks, web / client-based server architecture, and structured and unstructured databases.\n\n Ability to translate product spec to engineering actionable\n\n Ability to navigate and structure code bases\n\n Rudimentary skills around service hosting and infrastructure. Should understand the end-to-end deployment cycle\n\n Experience with Java / Spring-boot Or Node.JS is required.\n\n\n\n\nRole: \n\nA typical SDE2 is expected to take up the following responsibilities:\n\n\n\n\n Work closely with Team Leads and Product Managers to gather data and estimate project timelines.\n\n Should be able to understand product specifications and come up with optimal scalable solutions.\n\n Should be aware of the Agile working model and follow JIRA hygiene\n\n Complete ownership of features worked upon should be able to perform RCAs and provide quick resolution of relevant issues/production bugs while training Tech Support Engineers to offload recurring chunks of work.\n\n Should be a full-time mentor for SDE1s and be able to assist all other SDE1s as and when required.\n\n Be part of the lateral hiring process and allocate fixed bandwidth for interviewing processes.\n\n Should strive to follow best coding practices throughout designing, development, and testing.\n\n Should have great communication skills over email and in-person discussions.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": true,
    "easy_apply": false
  },
  "https://www.linkedin.com/jobs/view/4269012104": {
    "job_url": "https://www.linkedin.com/jobs/view/4269012104",
    "job_summary": "Software Engineer\nSoftware Engineer with verification\nPublicis Sapient\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\n4+ years of strong development skills in Java with JDK 1. 8 & above version & Microservices with Spring boot/ Spring. Should have strong acumen in Data Structures, Algorithms, problem-solving and Logical/Analytical skills. Thorough understanding ofOOPS concepts, Design principles and implementation of different type of Design patterns. Soundunderstandingof concepts likeExceptionalhandling,Serialization/Deserialization and Immutability concepts, etc. Good fundamental knowledge in Enums, Collections,Annotations, Generics,Auto boxing, etc. Experience with Multithreading, Concurrent Package and Concurrent APIs Basic understanding of Java Memory Management (JMM) including garbage collections concepts. Experience in RDBMS or NO SQL databases and writing SQL queries (Joins, group by, aggregate functions, etc.) Experience with at-least one NoSQL (Any of Cassandra/Couch base/Hadoop), Hands-on experience with JMS Hands-on experience in creating RESTful webservices and consuming webservices \n\n\n\n\nramya.n@publicissapient.com",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4267171077": {
    "job_url": "https://www.linkedin.com/jobs/view/4267171077",
    "job_summary": "SDE-II (Backend)\nSDE-II (Backend)\n1% Club\nBengaluru, Karnataka, India (On-site)\nViewed\nEasy Apply",
    "job_details": "About the job\n\nAbout 1% Club\n\n1% Club is on a mission to make Financial Independence a reality.\n\nIn under two years, weve built multiple large, profitable businesses under one brand  from financial education and SEBI-registered investment advisory to insurance and credit card services.\n\nBacked by Nikhil Kamath (Zerodha) and a 10 crore fundraise, we also grew an organic distribution of 80 lakh+ followers among Indias English-speaking middle class.\n\nNow, were using this strong foundation to build a tech-first, AI-driven wealth management platform  solving everything money in one seamless app.\n\nAt 1% Club, youll take products from zero to scale, solve deeply technical, user-first problems, and build for millions. If you want to shape the future of how India manages its wealth  this is the place.\n\nWhat will you do?\n\nYoull be working on the core systems behind a platform that's redefining how millions of Indians manage their money, with real-time applications, AI copilots, and blazing-fast apps.\n\nYoull have end-to-end ownership of features, working directly with the CTO and founding team to take ideas from whiteboard to production.\n\nWe care less about what stack youve used and more about how you think. You should be fluid across tech, know the why behind every decision, and treat speed and stability like religion. If you can write clean code, debug production like a ninja, and nerd out on system-level optimization, wed love to have you.\n\nKey Responsibilities\n\n\nDesign, develop, and maintain robust microservices in GoLang, with clean abstractions, high reliability, and readiness for scale. \nMentor junior engineers, review code, and help maintain a high bar for technical excellence. \nWork closely with Product Managers, Designers & Backend Engineers to deliver seamless user experiences. \nBreak down complex user problems into simple, scalable backend solutions. \nOwn entire features end to end, taking responsibility for coding, unit testing, bug fixing & documentation. \nParticipate in architectural discussions, contribute to the tech roadmap, and drive technical strategy. \n\n\nYoull be a great fit if you have\n\n\n24 years of experience in a Backend SDE role, preferably in a fintech company. \nStrong proficiency in GoLang and experience with other programming languages such as JavaScript, TypeScript. \nFamiliarity with DevOps tools and practices such as CI/CD pipelines, familiarity with AWS. \nOwnership and obsession with the product. \nWillingness to learn and adapt to new technologies and tools. \n\n\nBonus points\n\n\nYou can use AI to automate grunt work and 10x your output \nYou have a good eye for details \nYou think like a product owner, not just an engineer \nYou have worked at a FinTech before \n\n\nPerks and Benefits\n\n\nBYOS (Build Your Own Setup): Mac/Windows/Linux, iPad, Monitors - anything you need to work comfortably. \nWork hard, Party harder: Company offsite, team lunch/dinner, game nights, and day outings are a few of the many things youll experience if you work out of the Bengaluru office. \nHighly competitive salary: We offer above-market salary & equity packages. \n\n\nHiring Process\n\nYou can check out our hiring process from here.\n\nApply now to join our team!\n\nSkills: aws,debugging,ci,go (golang),microservices,code,javascript,ci/cd,cd,typescript,system-level optimization,golang",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4268702677": {
    "job_url": "https://www.linkedin.com/jobs/view/4268702677",
    "job_summary": "Software Engineer ( Data Platform )\nSoftware Engineer ( Data Platform )\nSundial\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout Sundial\n\nSundial is a top VC-backed early-stage startup headquartered at San Francisco Bay Area, US with a second office in Bengaluru, India. We have raised $23M to build the analytics platform for the AI era. Our founders are industry veterans Chandra Narayanan, previously Chief Data Scientist at Sequoia Capital, and Julie Zhuo, previously VP, Design and Research at Facebook, author of a bestselling management book. We are a small team of top talent, high caliber Engineers, Data Scientists, Designers and PM (currently 49 in India, 5 in US) and rapidly growing.\n\n\n\n\nWe are on a mission to help builders make meaningful use of data to fulfill their vision. Sundial automatically diagnoses a product's data to explain the \"what\" and the \"why\" to enable faster and better decision making.\n\n\n\n\nNow Pull up a chair! We're excited to tell you more about our vision for Sundial! By now, you've probably visited our website and maybe our LinkedIn page and browsed around the profiles of our team members. If you haven't yet, please take a moment to do so. We'll wait \n\n\n\n\nOkay, now you know at a high level that we are focused on data storytelling. The data space has over $100B in market opportunity ahead of it, and modern Business Intelligence tools are growing at over 15% year over year.We've seen this evolution firsthand. Our co-founders Chandra Narayanan and Julie Zhuo cut their teeth scaling Facebook from a few million college students to billions of people.\n\n\n\n\nTo make the best decisions possible, companies are investing more and more into understanding their data. And yet, demand far outpaces supply for Data Scientists and Data Platform Engineers who can construct useful narratives out of the growing firehose of raw data, tables and charts. Currently most data-centric organizations have a large Data Platform and Data Science team that builds Big Data Platforms, Insights Data stores to bring data into dashboards and manually generates reports to communicate the product story broadly. But a large part of this process can be easily productised.\n\n\n\n\nAt Sundial, we're building a Sundials Insights Data Platform. This platform converts raw data in large Data Warehouses into a universe of deep product insights that product teamsincluding PMs, data scientists, executives and engineersconsume easily. This involves Highly Scalable, Robust Distributed Data Platform which can consistently, repeatably run complex Data Science and Transformation algorithms at Cloud Scale.\n\n\n\n\nWe envision a future where every organization becomes a data-informed organization through our work of:\n\nProductising the diagnostic analysis of yesterday so teams can focus on the strategic bets for tomorrow.\nMaking data understanding easy and accessible to everyone, not just data scientists.\nSurfacing opportunities of improvement in growth across segments\n\nWe believe better usage of data leads to better products, and better products lead to better experiences for people.\n\n\n\n\nResponsibilities:\n\nSundials Big Data Ingestion and Processing System and Sundials Datalakehouse which stores the Metric, Entity and Event Stores.\nYou will work on Big Data technologies like Spark, Athena, Delta Lake, Cloud Data Warehouses etc.\nBuilding out Sundials Petabyte Scale Data Processing systems, No-Code / Low-Code Transformation systems etc.\nBuilding the Analytics-as-a-Platform engine that runs novel algorithms and frameworks through transforming clients data to Sundial Data Models.\nBuilding out Sundials SaaS Data Platform in Public Cloud.\nWork with customers and data scientists to understand the data gaps and expand the Analytics Model\nDesigning and building systems and features from scratch at rapid pace and high quality.\n\n\n\n\nRequirements:\n\nStrong Software Engineering fundamentals, Computer Science fundamentals, coding and design capabilities. Minimum 3-5 years of experience working in Data Platform.\nExperience building Data Platforms, Data Engineering and Distributed Systems / Products for Analytics and Data-Science products.\nFamiliarity with big data processing engines like Spark, Athena, and popular Cloud Datawarehouses and Datalakes.\nFamiliarity with building backend systems and services for SaaS products in the Cloud using Cloud services. We use EMR, EKS, RDS, Opensearch, etc.\nExperience working with various languages like Python, Golang, Pyspark, SQL etc.\nA Bachelors or Masters in Computer Science or work experience in related field.\nHave prior experience working in a fast pace start up environment.\n\n\n\n\nYou will probably like working with us if:\n\nYou like the ownership, camaraderie and chaos of a start-up environment - Start-ups are not right for everyone. Things move quickly and change frequently. Start-ups haven't \"made it\" yet. We have to convince customers we are valuable enough to them. We must be scrappy and flexible. Everyone will wear lots of hats. But: if you have future aspirations of being an entrepreneur or leader, you'll find few better learning grounds. You'll learn by doing. You'll be given a ton of trust and responsibility. You'll see very transparently how we operate and make decisions. Your work will absolutely matter to the success of our company.\nYou value learning and have a growth mindset - Sundial is founded on the idea that slope is far more important than intercept. We are a learning environment, and all of us have something to teach and learn from each other. We invest heavily in learning sessions, sharing insights, and reflecting on our growth.\nYou're interested in understanding how companies grow, and how data plays a role - Unlocking the secrets of data is our bread and butter. How do successful companies grow? How do different types of businesses create value for users in an economically scalable way? If you find this area to be as fascinating as we do, that's awesome, because you're going to become an expert in this domain. :)\n\n\n\n\nBenefits: \n\n Competitive salary & options packageA rewarding compensation structure that includes competitive pay and equity, ensuring your contributions are valued.\n\n Global culture  Collaborate with diverse teams across San Francisco and Bangalore, gaining exposure to international perspectives.\n\n Unlimited vacation daysA trust-based policy encouraging you to recharge and return at your best.\n\n Food in the Office  Enjoy daily lunch at the office, with the freedom to choose what you want to eat.\n\n\n\n\nInterested? Wed love to hear from youapply now!\n\n\n\n\n\n",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4251473009": {
    "job_url": "https://www.linkedin.com/jobs/view/4251473009",
    "job_summary": "Backend Software Engineer\nBackend Software Engineer with verification\nDoxel\nBengaluru, Karnataka, India (Remote)\nActively reviewing applicants\nApplied",
    "job_details": "About the job\n\nConstruction is the 2nd largest industry in the world (4x the size of SaaS!). But unlike software (with observability platforms such as AppDynamics and Datadog), construction teams lack automated feedback loops to help projects stay on schedule and on budget. Without this observability, construction wastes a whopping $3T per year because glitches arent detected fast enough to recover.\n\nDoxel AI exists to bring computer vision to construction, so the industry can deliver what society needs to thrive. From hospitals to data centers, from foreman to VPs of construction, teams use Doxel to make better decisions everyday. In fact, Doxel has contributed to the construction of the facilities that provide many of the products and services you use everyday.\n\nWe have classic computer vision, deep learning ML object detection, a low-latency 3D three.js web app, a complex data pipeline powering it all in the background. Were building out new workflows, analytics dashboards, and forecasting engines.\n\nWere at an exciting stage of scale as we build upon our growing market momentum. Our software is trusted by Shell Oil, Genentech, HCA healthcare, Kaiser, Turner, Layton and several others. Join us in bringing AI to construction!\n\nThe Role:\n\nAs a Backend Engineer, your mission is to architect and build the resilient and scalable systems that power the intelligence behind Doxels AI-driven construction platform. You'll tackle complex infrastructure and data engineering challenges, shaping how terabytes of real-time jobsite data are processed, stored, and served. Your work will enable smarter decision-making for some of the worlds largest construction projects. Youll collaborate closely with our product, frontend, computer vision, and 3D teams to design seamless end-to-end solutionsfrom field data capture to actionable insights. If you love solving real-world problems at scale and thrive in a fast-paced, mission-driven teamthis role is for you.\n\nWho You Are:\n\nYoure a backend engineer with deep curiosity and a strong grasp of building distributed systems. You care about clean, efficient code, resilient infrastructure, and scalable architectures. Youre hungry to solve tough technical problems and improve systems that directly impact the real worldespecially in industries like construction where every decision counts.\n\nBonus: youve worked on data-heavy platforms or have experience integrating machine learning/computer vision pipelines into production.\n\nWhat Youll Do:\n\n\n\nDesign, build, and scale robust backend systems and pipelines for data ingestion, processing, and analytics\nDevelop high-performance APIs that power real-time 3D visualizations, dashboards, and mobile tools\nBuild and optimize data pipelines that support models and business logic at scale\nCollaborate across CV/ML, frontend, design, and product teams to deliver end-to-end features\nEnsure system reliability, observability, monitoring, and graceful degradation for mission-critical tools\nLeverage, AI tools, cloud infrastructure, containerization, and CI/CD best practices\nperform thoughtful code reviews, and drive backend engineering best practices\n\n\n\n\nWhat You Bring to Doxel:\n\n\n\n4+ years of professional experience as a backend or systems engineer\nStrong proficiency in modern backend languages like Python, Go, or Node.js\nHave a test driven development approach. You are someone who believes testing is not an afterthoughtit's the foundation. You write tests before code, care deeply about code quality, and value software you can trust\nExperience designing and maintaining scalable APIs and microservices\nExperience of working with Computer vision algos at scale is a Plus\nProven track record of building and maintaining data pipelines, ideally with real-world complexity\nDeep knowledge of distributed systems, asynchronous processing, and message queues \nExperience working with cloud platforms (AWS/GCP/Azure) and containerized environments (Docker, Kubernetes)\nComfortable with CI/CD, monitoring, testing, and automation\nExcellent debugging, profiling, and system design skills\nGreat communicator and collaborator; able to break down complex problems clearly\nBonus: experience working with computer vision models, 3D data, or unstructured media pipelines\n\n\n\n\nPerks & Benefits:\n\n\n\nComprehensive health, dental, and vision insurance for you and your family\nUnlimited PTO + flexible work environment\nGenerous parental leave\nOpportunity to work at the cutting edge of AI and real-world impact\nA culture that values autonomy, ownership, and meaningful engineering\n\n\n\n\nDoxel is an equal opportunity employer and actively seeks diversity across our team. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": true,
    "easy_apply": false
  },
  "https://www.linkedin.com/jobs/view/4251110549": {
    "job_url": "https://www.linkedin.com/jobs/view/4251110549",
    "job_summary": "Python Developer\nPython Developer with verification\nL&T Technology Services\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob Title: Senior Engineer\n\nLocation: Bangalore, LTTS India\n\n\n\n\nL&T Technology Services is seeking a Senior Engineer (Experience range - 6+ years) of experience, proficient in:\n\n\n\n\nGood Hands-on Python programming\nHands on experience in Python with knowledge of at least one Python framework.\nExperience using OOP in Python\nGood experience with Unit testing and mocking frameworks like Pytest and TDD is must.\nHands on with REST JSON API development\nDatabase experience in MySQL.\nWorking experience in Azure IOT & Cloud services\nExperience in GIT, Jenkins, or such build automation tools.\nWorked with IDE Pycharm.\nGood exposure to Agile/Scrum methodology\nExperience of working in Agile Development Team\nEXPERTISE AND QUALIFICATIONS\nPython IOT, Azure\n\n\n\n\n\n\n\n#AzureFunctions, #Azure, #AzureAppService, #AzureStorage, #AzureIOT, #AzureDataFactory\n\n#AzureServices, #Python, #AzureSDK",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4268270484": {
    "job_url": "https://www.linkedin.com/jobs/view/4268270484",
    "job_summary": "Sr Backend Developer (Python)\nSr Backend Developer (Python)\nZetexa Global\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout Zetexa:\n\nZetexa Global Private Limited is a fast-growing startup led by visionary leaders from IIT and IIM. We are transforming Travel Tech, Consumer IoT, and M2M applications, focusing on B2B and B2C domains. Join our team to innovate and redefine digital experiences in a global marketplace.\n\n\n\n\nRole Overview:\n\nWe are looking for a Senior Backend Developer (Python) who will play a key role in building scalable, high-performance backend systems. The ideal candidate should have expertise in Python, Django, and cloud platforms (AWS, Azure, GCP) with strong experience in distributed systems, microservices, Docker, Kubernetes, and automation testing.\n\n\n\n\nKey Responsibilities:\n\nDevelop and maintain critical backend modules with well-exposed interfaces.\nEnsure seamless integration of distributed systems and microservices.\nImplement best practices in multi-threading, thread synchronization, and message bus systems.\nWrite clean, scalable, and bug-free code in Python and Django.\nDesign and execute unit tests, integration tests, and automation tests for regression testing.\nSet up and manage CI/CD pipelines using GitLab or Jenkins for continuous integration and deployment.\nDeploy, manage, and scale applications using Docker and Kubernetes.\nEnsure high availability, resiliency, and geographic redundancy in system architecture.\nCollaborate with cross-functional teams to enhance system performance and security.\n\n\n\n\nMust-Have Skills:\n\nProgramming Languages: Python\nWeb Frameworks: Django, OpenAPI/Swagger\nDatabases: PostgreSQL, MySQL\nCloud Platforms: AWS, Azure, GCP\nHands-on experience with distributed systems and microservices\nStrong knowledge of multi-threading, message buses, and thread synchronization\nExperience in test automation, including unit and integration testing\nProficiency in CI/CD pipelines setup and management\nContainerization & Orchestration: Docker, Kubernetes\n\n\n\n\nNote: Only relevant skills and experienced canididates are encouraged to apply.\n\n\n",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4268752348": {
    "job_url": "https://www.linkedin.com/jobs/view/4268752348",
    "job_summary": "Data Engineer\nData Engineer\nXiaomi India\nBengaluru, Karnataka, India (On-site)\n3 school alumni work here\n3 Indian Institute of Technology (Banaras Hindu University), Varanasi school alumni work here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob Description:\n\nAs a Data Engineer, you will be responsible for designing, implementing, and maintaining our data infrastructure to support our rapidly growing business needs. \nThe ideal candidate will have expertise in Apache Iceberg, Apache Hive, Apache Hadoop, SparkSQL, YARN, HDFS, MySQL, Data Modeling, Data Warehousing, Spark Architecture, and SQL Query Optimization.\n Experience with Apache Flink, PySpark, Automated Data Quality testing & Data Migration is considered a plus. \nAlso, it's mandatory to know any one cloud stack (AWS or Azure) for Data Engineering to Create Data Jobs and Workflows and Scheduler it later for Automation\n\n\n\n\nJob Responsibilities & Requirements:\n\nBachelor's degree in computer science, Information Technology, or a related field. Master's degree preferred.\n4-5 years of experience working as a Data Engineer\nMandatory experience in PySpark Development for Big data processing\nStrong proficiency in Apache Iceberg, Apache Hive, Apache Hadoop, SparkSQL, YARN, HDFS, Data Modeling, and Data Warehousing.\nCore PySpark Development and Optimizing SQL queries and performance tuning to ensure optimal data retrieval and processing.\nExperience with Apache Flink, and Automated Data Quality testing is a plus.\nIt's mandatory to know any one cloud stack (AWS or Azure) for Data Engineering to Create Data Jobs and Workflows and Scheduler later for Automation\n\n\n\n\nJoin Xiaomi India Technology and be part of a team that is shaping the future of technology innovation. Apply now and embark on an exciting journey with us!",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4263765980": {
    "job_url": "https://www.linkedin.com/jobs/view/4263765980",
    "job_summary": "Data Engineer\nData Engineer with verification\nBayOne Solutions\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nResponsibilities:\n\nDesign, build, and maintain data pipelines.\nDevelop ETL processes for data integration.\nBuild and optimize data warehouses and lakes.\nEnsure data quality and security.\nCollaborate with data scientists and analysts.\n\n\n\n\nRequirements:\n\nBachelor's degree in CS or related field.\nExperience/Knowledge on ML is required.\nExperience with SQL, Python, and big data technologies.\nProficiency in cloud platforms (AWS, GCP, Azure).\nStrong problem-solving and communication skills.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4259434521": {
    "job_url": "https://www.linkedin.com/jobs/view/4259434521",
    "job_summary": "Back End Developer\nBack End Developer with verification\nIDFC FIRST Bank\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nApplied",
    "job_details": "About the job\n\nRole/Job Title:  Back End Developer\n\nFunction/ Department: Information Technology\n\n\n\n\nJob Purpose:\n\nAs a Backend Developer, you will play a crucial role in designing, developing, and maintaining complex backend systems. You will work closely with cross-functional teams to deliver high-quality software solutions and drive the technical direction of our projects. Your experience and expertise will be vital in ensuring the performance, scalability, and reliability of our applications.\n\n\n\n\nKey Responsibilities:\n\nDesign and Develop: Architect, design, and implement high-performance Java-based backend services and applications.\nCode Quality: Write clean, efficient, and well-documented code following industry best practices and coding standards.\nTechnical Leadership: Provide technical guidance and mentorship to junior developers, promoting best practices and fostering a collaborative environment.\nCollaboration: Work closely with frontend developers, product managers, and other stakeholders to understand requirements and deliver robust solutions.\nPerformance Optimization: Identify and resolve performance bottlenecks and scalability issues.\nTesting: Implement comprehensive testing strategies, including unit tests, integration tests, and end-to-end tests.\nContinuous Improvement: Stay current with the latest industry trends, technologies, and best practices in Java/Golang development, and continuously improve our development processes.\n\n\n\n\nTechnical Skills\n\n3+ Years of professional experience in Java/Golang backend development.\nExpert proficiency in Java/Golang and related frameworks (e.g., Spring, Spring Boot).\nExtensive experience with RESTful API design and development.\nStrong knowledge of database technologies, including SQL, MySQL, PostgreSQL, or NoSQL databases.\nDeep understanding of object-oriented programming principles and design patterns.\nExperience with version control systems (e.g., Git).\nFamiliarity with microservices architecture and cloud platforms (e.g., AWS, Azure, Google Cloud).\nExperience with GraphQL\nExperience with CI/CD pipelines and tools (e.g., Jenkins, Docker)\nExperience with Jaeger for monitoring and tracing.\nProficiency in unit testing frameworks\nExperience with containerization and orchestration tools (e.g., Kubernetes)\nFamiliarity with agile development methodologies.\nKnowledge of security best practices and secure coding principles.\n\n\n\n\nSoft Skills\n\nExcellent problem-solving and analytical skills.\nStrong communication and collaboration abilities.\nLeadership skills with the ability to mentor and guide junior team members.\nAbility to work independently and manage multiple tasks effectively.\n\n\n\n\nEducation Qualification:\n\nGraduation: Bachelor of Science (B.Sc) / Bachelor of Technology (B.Tech) / Bachelor of Computer Applications (BCA)\nPost-Graduation: Master of Science (M.Sc) /Master of Technology (M.Tech) / Master of Computer Applications (MCA).",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": true,
    "easy_apply": false
  },
  "https://www.linkedin.com/jobs/view/4255340129": {
    "job_url": "https://www.linkedin.com/jobs/view/4255340129",
    "job_summary": "Software Engineer II (C, Java, ETL)\nSoftware Engineer II (C, Java, ETL) with verification\nPrecisely\nIndia (Remote)\n1 connection works here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nPrecisely is the leader in data integrity. We empower businesses to make more confident decisions based on trusted data through a unique combination of software, data enrichment products and strategic services. What does this mean to you? For starters, it means joining a company focused on delivering outstanding innovation and support that helps customers increase revenue, lower costs and reduce risk. In fact, Precisely powers better decisions for more than 12,000 global organizations, including 93 of the Fortune 100. Precisely's 2500 employees are unified by four company core values that are central to who we are and how we operate: Openness, Determination, Individuality, and Collaboration. We are committed to career development for our employees and offer opportunities for growth, learning and building community. With a \"work from anywhere\" culture, we celebrate diversity in a distributed environment with a presence in 30 countries as well as 20 offices in over 5 continents. Learn more about why it's an exciting time to join Precisely!\n\nOverview\n\nAs a Software Engineer, you will be part of the team that designs and develops ETL applications on the Data Integration Team. You will be deeply involved in the development and unit testing of Connect ETL. You will collaborate with architects, UX experts, product managers and other software developers for developing solutions. Strong problem-solving skills, communication, and the ability to develop creative solutions are a must.\n\nWhat You Will Do\n\n\nDevelop and test new features or product changes. \nWork in a collaborative team environment following Agile development methodologies.\nAddress and resolve issues quickly and effectively to ensure customer satisfaction.\nInvestigate, analyze, debug and solve complex problems.\nReplicate customer issues in house and work closely with QA and Support teams to resolve problems when required.\nDebug issues and implement resolutions in multiple product areas across a variety of environments.\nImplement product functionality to meet customer requirements.\nAdequately document and describe product changes or features.\nContinuously learn new technology, tools, systems, and sharing knowledge within the team.\n\n\nWhat We Are Looking For\n\n\nBachelors or Masters degree in Computer Science or equivalent work experience.\n+2 years of developing Enterprise software.\nStrong object-oriented design and programming experience (C, Java).\nGood knowledge of CI/CD processes and knowledge of JIRA, Jenkins, GIT and Artifactory.\nKnowledge of Git, Gradle and Maven.\nExperience working with ETL/ELT products.\nExperience with big data  Hadoop/Cloudera.\nExperience with SQL databases (at least one of Oracle, DB2, SQL Server).\n\n\nThe personal data that you provide as a part of this job application will be handled in accordance with relevant laws. For more information about how Precisely handles the personal data of job applicants, please see the Precisely Global Applicant and Candidate Privacy Notice.\n\n",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4268781379": {
    "job_url": "https://www.linkedin.com/jobs/view/4268781379",
    "job_summary": "Software Development Engineer- 2 (B2B SaaS)\nSoftware Development Engineer- 2 (B2B SaaS)\nWisemonk\nBengaluru, Karnataka, India (On-site)\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob Title: Software Engineer  Systems & Infra\n\nLocation: In Office - Bangalore\n\nExperience: 23 years\n\nType: Full-time\n\n\n\n\nAbout Wisemonk\n\nWisemonk is building the most trusted infrastructure to hire, pay, and support remote talent in India. We enable global companies to onboard top Indian professionals without setting up local entities or dealing with compliance chaos.\n\nWere a tight, high-caliber team from leading global enterprises and startups. With strong early traction, were scaling rapidly and building a product-led, operationally excellent company.\n\nThis is a chance to work at the intersection of global employment, fintech, and automation  with real ownership and real impact.\n\n\n\n\nWhat You'll Do\n\n-Build foundational systems that power cross-border payments, contract workflows, and tax automation\n\n-Write high-performance, low-latency code that handles compliance-critical operations\n\n-Optimize systems for reliability, observability, and scale across regions and entities\n\n-Collaborate closely with founders, product managers, and ops to ship impactful features fast\n\n-Own your code end-to-end  from architecture to deployment to monitoring\n\n-Contribute to technical architecture decisions and lay the groundwork for scale\n\n\n\n\nYou Should Apply If You Have\n\n-23 years of experience building backend systems or infrastructure tooling\n\n-Design reliable, performance-sensitive systems using low-level tools while also owning automation workflows with no-code platforms.\n\n-Strong debugging and systems design skills; you know your way around memory and logs\n\n-Prior experience in a Series A start-up or early-stage company  you're comfortable with ambiguity and velocity\n\n-Exposure to fintech or compliance-heavy systems (bonus: worked on payroll, tax, or payment rails)\n\n\n\n\nWhy Join Wisemonk?\n\n-Build at the intersection of fintech, compliance, and global employment\n\n-High ownership, zero bureaucracy  ship fast, learn fast\n\n-Work with founders and a team that cares deeply about product and craft",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4256442780": {
    "job_url": "https://www.linkedin.com/jobs/view/4256442780",
    "job_summary": "Data Engineer\nData Engineer with verification\nEXL\nIndia (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout Role:\n\nPlease find below the requirements -\n\n\n\n\nOur expertise in transformation, data science, and change management helps make your business more efficient and effective, improve customer relationships and enhance revenue growth. Instead of focusing on multi-year, resource- and time-intensive platform designs or migrations, we look deeper at your entire value chain to integrate strategies with impact.\n\n\n\n\nKey Delivery: To build out a centralized data mart for Very Media Group for accessing data for insight and data modelling.\n\n\n\n\nSkillsets Required :\n\n\n\n\nSQL and Query Optimization\n\nPython (Assuming that the data mart would eventually be managed within Data Science and not Data Engineering)\n\nSAS (Desirable - A lot of the CRM processes are in SAS, but assuming we wouldn't build the process in SAS so not essential)\n\nAWS experience\n\nData Management and Analytical skills\n\nExpertise in ETL Development and Data Integration\n\nCollaboration and Communication\n\n\n\n\n\n\n\nMandate Experience \n\nRDS\n\nDynamoDB\n\nRedshift\n\nAthena\n\nQuickSight\n\nSagemaker",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4259988821": {
    "job_url": "https://www.linkedin.com/jobs/view/4259988821",
    "job_summary": "Software Engineer E4 (Backend)\nSoftware Engineer E4 (Backend) with verification\nWhatfix\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nApplied",
    "job_details": "About the job\n\nWho are we ?\n\nFounded in 2014 by Khadim Batti and Vara Kumar, Whatfix is a leading global B2B SaaS provider and the largest pure-play enterprise digital adoption platform (DAP). Whatfix empowers companies to maximize the ROI of their digital investments across the application lifecycle, from ideation to training to the deployment of software. Driving user productivity, ensuring process compliance, and improving user experience of internal and customer-facing applications.\n\nSpearheading the category with serial innovation and unmatched customer-centricity, Whatfix is the only DAP innovating beyond the category, positioning itself as a comprehensive suite for GenAI-powered digital adoption, analytics, and application simulation. Whatfix product suite consists of 3 products - DAP, Product Analytics, and Mirror. This product suite helps businesses accelerate ROI on digital investments by streamlining application deployment across its lifecycle.\n\nWhatfix has seven offices across the US, India, UK, Germany, Singapore, and Australia and a presence across 40+ countries.\n\nCustomers: 700+ enterprise customers, including over 80 Fortune 500 companies such as Shell, Microsoft, Schneider Electric, and UPS Supply Chain Solutions. \n\nInvestors: Raised a total of ~$270 million. Most recently Series E round of $125 Million led by Warburg Pincus with participation from existing investor SoftBank Vision Fund 2. Other investors include Cisco Investments, Eight Roads Ventures (A division of Fidelity Investments), Dragoneer Investments, Peak XV Partners, and Stellaris Venture Partners.\n\n\n\n\nWith over 45% YoY sustainable annual recurring revenue (ARR) growth, Whatfix is among the Top 50 Indian Software Companies as per G2 Best Software Awards. \nRecognized as a Leader in the digital adoption platforms (DAP) category for the past 4+ years by leading analyst firms like Gartner, Forrester, IDC, and Everest Group.\nThe only vendor recognized as a Customers Choice in the 2024 Gartner Voice of the Customer for Digital Adoption Platforms has once again earned the Customers Choice distinction in 2025. We also boast a star rating of 4.6 on G2 Crowd, 4.5 on Gartner Peer Insights, and a high CSAT of 99.8%\nHighest-Ranking DAP on 2023 Deloitte Technology Fast 500 North America for Fourth Consecutive Year\nWon the Silver for Stevie's Employer of the Year 2023  Computer Software category and also recognized as Great Place to Work 2022-2023 \nOnly DAP to be among the top 35% companies worldwide in sustainability excellence with EcoVadis Bronze Medal\nOn the G2 peer review platform, Whatfix has received 77 Leader badges across all market segments, including Small, Medium, and Enterprise, in 2024, among numerous other industry recognitions.\n\nRoles and Responsibilities\n\nDesign, develop, test, ship, and maintain backend features independently, adhering to high engineering standards.\nBreak down features into executable tasks, ensuring timely delivery within sprint cycles \nWrite clear, concise, and well-tested code using Java and Spring Boot, aligned with platform capabilities.\nEnsure end-to-end ownership of features, including design documentation, testing, deployment, monitoring, and post-release improvements.\nMonitor production behavior of owned features and proactively address issues with appropriate automation and runbooks.\nParticipate in and conduct code reviews that are constructive, standards-compliant, and improve team code quality.\nCollaborate closely with customer-facing teams to debug production issues and improve overall system stability.\nAlign with other teams on design and integration points when touching external codebases.\nLeverage generative AI tools to improve productivity and accelerate development tasks.\nActively contribute to sprint demos and team discussions, sharing progress and insights.\n\nRequirements:\n\n47 years of professional backend development experience, ideally in product-based internet companies or startups.\nStrong hands-on experience with Java, Spring Boot, and web services.\nProven expertise with relational and/or NoSQL databases such as SQL, MongoDB, or Cassandra.\nExperience designing and developing scalable, distributed, and high-availability systems.\nSolid understanding of backend design principles and ability to apply them effectively.\nStrong debugging, problem-solving, and code optimization skills with a focus on performance.\nFamiliarity with CI/CD, monitoring, and alerting practices for production systems.\nExposure to or active use of generative AI tools for coding tasks.\nFast learner with a self-starter attitude, and a strong focus on code quality and customer impact.\nExcellent written and verbal communication skills, with the ability to collaborate effectively in a team environment.\n\nNote: \n\nWe strive to live and breathe our Cultural Principles and encourage employees to demonstrate some of these core values - Customer First; Empathy; Transparency; Fail Fast and scale Fast; No Hierarchies for Communication; Deep Dive and innovate; Trust, Do it as you own it; \nWe are an equal opportunity employer and value diverse people because of and not in spite of the differences. We do not discriminate on the basis of race, religion, color, national origin, ethnicity, gender, sexual orientation, age, marital status, veteran status, or disability status",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": true,
    "easy_apply": false
  },
  "https://www.linkedin.com/jobs/view/4264117843": {
    "job_url": "https://www.linkedin.com/jobs/view/4264117843",
    "job_summary": "Data Engineer\nData Engineer\nAkkodis\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nProven knowledge of coding in Python\nAdvanced knowledge of regression & linear optimization (Python based, relevant libraries: pandas, numpy, scikit-learn, or-tools)\n3+years of working experience in data analytics with proven project/solution track record \nExperience as Operations Research analyst or similar: worked with optimisation models (e.g. Integer and Linear Programming) in the past \nSkills in data analysis & visualization (Python based, relevant libraries: pandas, numpy, plotly)",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4256916827": {
    "job_url": "https://www.linkedin.com/jobs/view/4256916827",
    "job_summary": "Python Developer\nPython Developer with verification\nHCLTech\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob Title - Ansible with Python developer.\n\nLocation - Bangalore.\n\nExperience - 4+ yrs.\n\nNotice Period - Immediate to 10 days.\n\n\n\n\nMandatory Skills:\n\nPython \nAnsible\nNetworking\n\n\n\n\nRoles and Responsibilities:\n\nDesign and implement network automation solutions using Python and Ansible.\nCollaborate with cross-functional teams to identify automation opportunities within network operations.\nDevelop scalable scripts and tools to automate routine network tasks and configurations.\nMonitor and optimize network performance and automation processes to ensure high availability.\nTroubleshoot and resolve network automation issues promptly.\nDocument automation processes and provide training to relevant stakeholders.\nStay updated with emerging trends and technologies in network automation.\n\n\n\n\nSkill Requirements:\n\nBachelor's degree in Computer Science, Information Technology, or a related field.\nProficiency in Python programming and scripting.\nExtensive experience with Ansible for network automation.\nStrong understanding of network protocols and configurations.\nExperience with network automation tools and frameworks.\nExcellent problem-solving skills and attention to detail.\nAbility to work collaboratively in a fast-paced environment.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4254722984": {
    "job_url": "https://www.linkedin.com/jobs/view/4254722984",
    "job_summary": "Python Developer\nPython Developer with verification\nAccolite\nMumbai Metropolitan Region (Hybrid)\nActively reviewing applicants\nApplied",
    "job_details": "About the job\n\nAbout Bounteous x Accolite\n\nBounteous, a digital innovation partner of the world's most ambitious brands and Accolite Digital, a leading digital engineering, cloud, data & AI services provider, have announced their merger, creating a new end-to-end digital transformation services consultancy that partners with leading brands around the globe to co-innovate and drive exceptional client outcomes.\n\nIt was Founded in 2003 in Chicago, Bounteous is a leading digital experience consultancy that co-innovates with the world's most ambitious brands to create transformative digital experiences. With services in Strategy, Experience Design, Technology, Analytics and Insight, and Marketing, Bounteous elevates brand experiences and drives superior client outcomes. For more information, please visit www.bounteous.com.\n\n\n\n\nJob Description:\n\nLooking for 5+ years of experience and the location is Bangalore, Hyderabad, Chennai and Gurgaon. \n\nWilling to work in US Shift timings, candidates who does not prefer working in US shift timings will not be shortlised for screening level. \n\n\n\n\nBachelor's/masters degree in computer science or a related field\nProven experience working as a Python Developer with knowledge of DBMS\nStrong knowledge of Python frameworks like Django, Flask, or Pyramid\nExperience with database integration and optimization\nFamiliarity with front-end technologies such as JavaScript, HTML5, and CSS3\nUnderstanding of server-side templating languages",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": true,
    "easy_apply": false
  },
  "https://www.linkedin.com/jobs/view/4266889528": {
    "job_url": "https://www.linkedin.com/jobs/view/4266889528",
    "job_summary": "Python Developer\nPython Developer with verification\nDexian\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nEasy Apply",
    "job_details": "About the job\n\nWe are looking for a Python Developer\n\n\n\n\nMust Have skills:\n\n\n\n\n5+ Years of experience into python development\nProficiency in SQL or OracleSQL\n\n\n\n\nGood to have skills:\n\nLinux or Unix Experience\nCloud technologies like AWS, Azure or GCP (Google Cloud)",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4267120567": {
    "job_url": "https://www.linkedin.com/jobs/view/4267120567",
    "job_summary": "Python Developer\nPython Developer with verification\nValueLabs\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nRole: Senior Python Developer \n\nExperience: 7+ Years\n\nNotice Period: Less than 30 Days or Serving Notice period \n\nLocation: Bangalore\n\nMust have Skills\n\n\n\n\n1. Python, (Django/Flask) , API, Microservices\n\n2.Familiarity/Usage of tools (Kubernetes, Docker, CI/CD pipelines)\n\n3. Database: MongoDB, PostgreSQL",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4269456097": {
    "job_url": "https://www.linkedin.com/jobs/view/4269456097",
    "job_summary": "Software Development Engineer -II (Backend)\nSoftware Development Engineer -II (Backend)\nZET\nBengaluru, Karnataka, India (On-site)\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout ZET: \n\n\n\n\nAt ZET, we believe that passion fuels those who shape the world. Our team is on a mission to make a real impact by driving financial inclusion and accessibility across Bharat. With over 500 million online users in underserved regions, we are building an ecosystem that connects consumers to trusted financial solutions that were once out of reach. Empowered by technology and trust, we are making financial services more affordable and within reach for the next billion Indians.\n\nThrough our ZET platform (B2C), we focus on empowering individuals, especially those new to credit (NTC) or with low credit scores, to build and improve their CIBIL scores. One of our key offerings is the Magnet FD Credit Card, co-branded with SBM. The Magnet card plays a pivotal role in helping users from Tier 2, 3, and 4 cities boost their credit scores. By providing insights & solutions into their creditworthiness, consumers are empowered to make informed financial decisions, unlocking opportunities for loans, mortgages and greater financial stability.\n\nOn our ZET Partner (B2B) platform, we connect communities in Tier 3 and 4 cities to a wide network of financial brands and credit products. By leveraging a trusted network of agents, we bridge the gap between consumers and top banks, making financial services more accessible and tailored to the specific needs of these underserved markets. \n\nRaising $13M in our series A funding in March 2022, we are proud to be backed by General Catalyst, Nexus, Sequoia Surge, Waterbridge and other leading Angel Investors. Starting with only two in 2019, we are now a workforce of high spirited people diligently striving to enable fintech for Bharat.\n\n\n\n\n\n\n\nProblems we are solving\n\n\n\n\nLack of Awareness: Many consumers, especially those in Tier 3/4 cities, are unaware of how to improve their CIBIL score and the credit solutions available for the same.\nReaching Bharat: Consumers in Tier 3 & 4 cities often struggle to access essential financial services and opportunities due to limited reach and availability from financial institutions and banks.\nTrust: The trust deficit in rural areas hinders the adoption of modern fintech solutions, creating barriers to financial inclusion.\n\n\n\n\n\n\n\nThe rise of ZET\n\n\n\n\nApril 2019, Founded by Manish Shara & Yash Desai\nAugust, 2020, Raised Seed Funding led by Waterbridge Ventures\nJuly 2021, Raised $5 M led by Sequoias Surge, Nexus Venture Partners & renowned Angel investors.\nMarch 2022, Raised $13M in Series A round led by General Catalyst & renowned Angel investors.\n\n\n\n\n\n\n\nAngel Investors who trust our mission\n\n\n\n\nKunal Shah - Co Founder, CRED\nKalyan Krishnamurthy- CEO Flipkart\nHarshil Mathur - Co Founder, Razorpay\nVidit Aatrey - Founder & CEO, Meesho\nSujeet Kumar - Co Founder, Udaan\nLalit Keshre - CEO, GROWW\nGaurav Munjal - Co-founder & CEO, Unacademy\nAakrit Vaish - Co-founder & CEO, Haptik\nJitendra Gupta - Founder, Jupiter\nAmrish Rau - CEO PineLabs\nGokul Rajaram - Product & Business, Doordash\n\n\n\n\n\n\n\nWhy ZET\n\n\n\n\nHigh-end Technology\nMake in India\nAccelerated Growth\nBuild for next Billion users\nFast pace & Innovation\nOpportunity to Thrive\n\n\n\n\nSoftware Development Engineer -II (Backend) \n\n\n\n\nResponsibilities:\n\nYou will own the entire application lifecycle including research, design, development, along with continuous deployment and delivery\nYou will act as a mentor through both your technical knowledge and bring in continuous improvements and implement best practices.\nYou will apply the latest technology thinking from our tech radar, adopt best design practices to solve complex problems and ensure our product is the best in usability.\nYou will work directly with the cross functional product teams, align on the needs of the products and operations.\nYou will analyze business, technology challenges and suggest solutions\n\n\n\n\nThis opportunity is for you if,\n\nYou have 3+ years of work experience in building highly-interactive applications using object oriented programming languages like Java, Spring Boot along with MySQL and AWS.\nYou have experience in working with Restful web services.\nYou have strong knowledge and understanding of design patterns and domain driven design.\nYou understand fundamental design principles behind building scalable, resilient, and maintainable applications.\nYou have a knack for writing clean, readable, re-usable code.\nYou have good knowledge on TDD and CI/CD practices.\nYou have penchant for learning\nYou are a great analytical & logical thinker and someone who loves solving problems\nYou are passionate, energetic, enthusiastic and a go-getter\nYou are  FUN @ Work ",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4268759000": {
    "job_url": "https://www.linkedin.com/jobs/view/4268759000",
    "job_summary": "Senior Software Engineer\nSenior Software Engineer with verification\nCimpress India\nIndia (Remote)\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nPosition: Senior Software Engineer (PR2 Level)\n\nLooking for Immediate to 30 days joiner.\n\n\n\n\nAbout Cimpress:\n\nLed by founder and CEO Robert Keane, Cimpress invests in and helps build\n\ncustomer-focused, entrepreneurial mass customization businesses. Through the\n\npersonalized physical (and digital) products these companies create,we\n\nempower over 17 million global customers to make an impression. Last year,\n\nCimpress generated $3.5B in revenue through customized print products,\n\nsignage, apparel, packaging and more. The Cimpress family includes a dynamic,\n\ninternational group of businesses and central teams, all working to solve\n\nproblems, build businesses, innovate and improve.\n\n\n\n\nBusiness Unit: Boxup\n\nBoxUp was founded by Curt Stephens and Ward Hubbard in Terre Haute,\n\nIndiana in 2016. The company was formed to supply high-quality custom-printed boxes in small\n\norder quantities with quick lead times and reasonable prices. BoxUp manufactures and sells corrugated shipping containers. BoxUp's primary customers are small to medium-sized e-commerce businesses that ship their products by parcel post - UPS or FedEx.\n\n\n\n\nResponsibilities:\n\n High proficiency with Full Stack Application development in NodeJS along with react.js or any other JavaScript technology.\n\n Good working experience with Data Structures, Algorithms, Low-Level Design, Object-Oriented Design\n\n An entrepreneurial spirit and enjoys moving quickly on new, green/brownfield products.\n\n The ability to stitch together many different services and processes even if they have not worked with them before.\n\n Ability to think about systems and services and write high-quality code. We work mostly with NextJs and Node however, frameworks can be learned: we care much more about your general engineering skill than your knowledge of a particular framework.\n\n Participate in design meetings and code reviews\n\n Work with your team and other technology teams in a cooperative environment to understand what stakeholders need and iterate on solutions, adapting to feedback from customer\n\n\n\n\nWhat's in store for you?\n\nGrow the online retail business with a new and improved front-end experience\n\nSell to other Cimpress businesses and expand BoxUp products by accessing other Cimpress business products.\n\n\n\n\nRemote First-Culture:\n\nIn 2020, Cimpress adopted a Remote-First operating model and culture. We heard from our team members that having the freedom, autonomy and trust in each other to work from home and, the ability to operate when they are most productive, empowers everyone to be their best and most brilliant self. Cimpress also provides collaboration spaces for team members to work physically\n\ntogether when it's safe to do so or believe in oce working will deliver the best results. Currently we are enabled to hire remote team members in over 20 US States as well as several countries in Europe: Spain, Germany, UK, Czech Republic, the Netherlands and Switzerland.\n\nMore information about the organization can be found in the below link:\n\nhttps://cimpress.com\n\nhttps://www.linkedin.com/company/cimpress/\n\nhttps://twitter.com/Cimpress\n\nWant to explore more about our brands?\n\nPlease visit: https://cimpress.com/brands/explore-our-brands/",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4265936318": {
    "job_url": "https://www.linkedin.com/jobs/view/4265936318",
    "job_summary": "Backend Engineer - AI Ops\nBackend Engineer - AI Ops with verification\nSolarWinds\nBengaluru, Karnataka, India\nViewed\nEasy Apply",
    "job_details": "About the job\n\nAt SolarWinds, were a people-first company. Our purpose is to enrich the lives of the people we serveincluding our employees, customers, shareholders, Partners, and communities. Join us in our mission to help customers accelerate business transformation with simple, powerful, and secure solutions.\n\nThe ideal candidate thrives in an innovative, fast-paced environment and is collaborative, accountable, ready, and empathetic. Were looking for individuals who believe they can accomplish more as a team and create lasting growth for themselves and others. We hire based on attitude, competency, and commitment. Solarians are ready to advance our world-class solutions in a fast-paced environment and accept the challenge to lead with purpose. If youre looking to build your career with an exceptional team, youve come to the right place. Join SolarWinds and grow with us!\n\n \n\nYour Role:\n\nWe seek a talented and motivated Software Engineer to join our Observability Platform team. In this role, youll contribute to developing scalable, resilient, and real-time observability solutions that help companies monitor and optimize their distributed systems. Youll work with cutting-edge cloud infrastructure, distributed systems, and high-scale data processing, collaborating closely with cross-functional teams to deliver impactful solutions.\n\nYour Impact:\n\nSystem Development: Design, develop, and maintain components of our observability platform using Kotlin and/or Java. \nDistributed Systems: Implement high-volume telemetry data processing systems, ensuring scalability, performance, and reliability. \nCode Quality & Best Practices: Write clean, efficient, and maintainable code, adhering to industry best practices and participating in code reviews. \nCollaboration: Work closely with product managers, and senior engineers to deliver features aligned with business goals and technical requirements. \nTroubleshooting & Optimization: Identify and resolve performance bottlenecks in distributed systems and improve platform resilience. \nContinuous Improvement: Contribute to technical discussions, architecture decisions, and process improvements within the team. \n\nYour Experience:\n\nExperience: 3+ years of software engineering experience, preferably in distributed systems or observability platforms. \nProgramming Languages: Proficiency in Kotlin and/or Java. Full-stack experience is a plus. \nCloud-Native Expertise: Familiarity with cloud platforms (AWS, GCP, or Azure) and cloud-native technologies (Kubernetes, Docker, etc.). \nData Systems: Experience with SQL/NoSQL databases and real-time data processing. \nSystem Design: Understanding of scalable system design and microservices architecture. \nProblem-solving: Strong troubleshooting skills and the ability to optimize performance in complex systems. \nCollaboration: Excellent teamwork and communication skills, with a proactive mindset. \n\nPreferred Qualifications\n\nFamiliarity with observability concepts (metrics, logging, tracing). \nExperience with frontend frameworks or modern frontend development is a plus. \nContributions to open-source projects or community involvement. \n \n\nSolarWinds is an Equal Employment Opportunity Employer. SolarWinds will consider all qualified applicants for employment without regard to race, color, religion, sex, age, national origin, sexual orientation, gender identity, marital status, disability, veteran status or any other characteristic protected by law.\n\nAll applications are treated in accordance with the SolarWinds Privacy Notice: https://www.solarwinds.com/applicant-privacy-notice",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4270287656": {
    "job_url": "https://www.linkedin.com/jobs/view/4270287656",
    "job_summary": "Python Developer + Generative AI\nPython Developer + Generative AI\nProgramming.com\nBengaluru, Karnataka, India (On-site)\nCompany review time is typically 1 week\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob Title: Python Developer  Generative AI\n\nLocation: Bangalore (Night Shift)\n\nExperience: 3+ Years\n\nShift: Night Shift\n\nEmployment Type: Full-Time\n\nAbout the Role\n\nWe are seeking an experienced and innovative Python Developer with expertise in Generative AI to work in a night shift capacity. You will design, develop, and deploy intelligent AI-powered systems using cutting-edge LLMs and generative models. The ideal candidate thrives in fast-paced environments and is passionate about leveraging AI to solve real-world problems.\n\nKey Responsibilities\n\nBuild and maintain Python-based APIs and backends integrated with Generative AI models.\n\nWork with large language models (e.g., GPT, Claude, LLaMA) and image/audio generation tools (e.g., DALLE, Stable Diffusion).\n\nImplement prompt engineering, fine-tuning, and model deployment pipelines.\n\nCollaborate with global teams during night shift hours to develop scalable AI features.\n\nDeploy models using FastAPI, Flask, Docker, or cloud platforms.\n\nOptimize model performance for latency, accuracy, and scalability.\n\nEnsure testing, monitoring, and documentation of AI integrations.\n\nRequired Skills\n\n4+ years of Python development experience.\n\n1+ years of hands-on experience with Generative AI tools and models.\n\nStrong knowledge of PyTorch, TensorFlow, Hugging Face, LangChain, or OpenAI API.\n\nExperience with deployment (Docker, FastAPI), and model inference in production.\n\nFamiliarity with vector databases (FAISS, Pinecone, Weaviate).\n\nPreferred Skills\n\nExperience with GPU-based training or inference.\n\nExposure to MLOps tools like MLflow, Airflow, or Kubeflow.\n\nUnderstanding of AI ethics, model safety, and bias mitigation.\n\nContributions to open-source GenAI or ML projects.\n\nJob Types: Full-time, Permanent\n\nBenefits:\n\nHealth insurance\n\nProvident Fund\n\nSchedule:\n\nNight shift",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4192204510": {
    "job_url": "https://www.linkedin.com/jobs/view/4192204510",
    "job_summary": "Backend Engineer\nBackend Engineer\nStockGro\nBengaluru, Karnataka, India (On-site)\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nCompany Vision\n\n\n\n\nStockGro is Indias leading stock market education platform with a community of over 2.5 crore market enthusiasts. StockGro equips users with trading and investing knowledge to succeed in the stock market. Whether user is a beginner or a seasoned trader, he can learn strategies from top investment managers, practice with platform currency, and study portfolios of experts & peers. By combining experiential learning with guidance from SEBl-registered experts, StockGro has become the go-to platform for trading & investing education\n\n\n\n\n.About StockGro\n\n\n\n\nFounded in January 2020 by former venture capitalist Ajay Lakhotia, were well-funded. We are backed by some of the respected investors  General Catalyst, BITKRAFT, Roots Ventures, and the likes of Kunal Shah, Vivekananda Hallekere, Rahul Garg as Angels. We have some brilliant minds with us, working on a mission to make 400 million Indian millennials investment-ready, with Senior Executives from Sequoia, Swiggy, Glance, Airtel, Uber, and institutions like ISB, NITs, and IIMs.\n\n\n\n\nThe opportunity : \n\n\n\n\nWe are looking for a backend engineer and developer who can:\n\n\n\n\nWork closely with product, design and business teams to understand product ideas and business needs and help deliver series of ultra fast experiments\nArchitect and implement backend services with high reliability and scalability\nComplete ownership of design/architect/develop/deploy phases while collaborating with technical and nontechnical stakeholders on all elements of the development process.\nSetup best practices for development and advocate their adoption\nWrite quality documentation and handle conflicts well to build consensus\nContinuously discover, evaluate, and implement new technologies and frameworks to maximize development efficiency\nMentor young minds around you and foster team spirit\n\n\n\n\nRequirements :\n\n\n\n\n4+ years of strong programming expertise in Golang and databases like PostgreSQL / MySQL / MongoDB\nBuild highly scalable REST APIs that align with StockGros needs\nStrong knowledge of databases such as MySQL, PostgreSQL, or MongoDB\nYou have experience building scalable customer-facing applications that are high-performance, highly-available, highly transactional, low latency and massively distributed.\nStrong knowledge of data structures, algorithms, and designing for performance, scalability, and availability.\nExperience in designing and developing service-oriented architecture\nExperience with cache-store / message broker like Redis / RabbitMQ / Kafka\nHaving an understanding of GCP, Kubernetes, Docker will be beneficial\nInterest in learning new languages/frameworks as needed\nWorked in a startup environment with high levels of ownership and commitment\n\n\n\n\nWhat are we looking for?\n\n\n\n\nSomeone who will be a quick learner and be able to work independently.\nHe/she should be able to operate in a very fast paced environment where time to ship product is super critical.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4266128137": {
    "job_url": "https://www.linkedin.com/jobs/view/4266128137",
    "job_summary": "Senior Data Engineer\nSenior Data Engineer with verification\nGameskraft\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout Gameskraft -\n\nEstablished in 2017, Gameskraft has become one of Indias fastest-growing companies. We are building the world's most-loved online gaming ecosystem - one game at a time. Started by a group of passionate gamers, we have grown from a small team of five members to a large family of 600+ Krafters, working out of our office in Prestige Tech Park, Bangalore.\n\n\n\n\nOur short-term success lies in the fact that we strive to focus on building a safe, secure,and responsible gaming environment for everyone. Our vision is to create unmatched experiences every day, everywhere. We set the highest benchmarks in the industry in terms of design, technology, and intuitiveness. We are also the industrys only ISO 27001and ISO 9001 certified gaming company.\n\n\n\n\nAbout the role -\n\nWe are hiring a Senior Data Engineer at Gameskraft, one of India's fastest-growing gaming companies, to build and scale a robust data platform. The role involves designing and optimizing data pipelines, developing scalable infrastructure, and ensuring seamless data accessibility for business insights.\n\n\n\n\nKey Responsibilities:\n\nBuilding and optimizing big data pipelines, architectures, and datasets to handle large-scale data.\nEnhancing infrastructure for scalability, automation, and data delivery improvements.\nDeveloping real-time and batch processing solutions using Kafka, Spark, and Airflow.\nEnsuring data governance, security compliance, and high availability.\nCollaborating with product, business, and analytics teams to support data needs.\n\n\n\n\nTech Stack:\n\n\n\n\nBig Data Tools: Spark, Kafka, Databricks (Delta Tables), ScyllaDB, Redshift\nData Pipelines & Workflow: Airflow, EMR, Glue, Athena\nProgramming: Java, Scala, Python\nCloud & Storage: AWS\nDatabases: SQL, NoSQL (ScyllaDB, OpenSearch)\nBackend: Spring Boot\n\n\n\n\nWhat we expect you will bring to the table:\n\n\n\n\n1. Cutting-Edge Technology & Scale\n\nAt Gameskraft, you will be working on some of the most advanced big data technologies, including Databricks Delta Tables, ScyllaDB, Spark, Kafka, Airflow, and Spring Boot. Our systems handle billions of data points daily, ensuring real-time analytics and high-scale performance. If youre passionate about big data, real-time streaming, and cloud computing, this role offers the perfect challenge.\n\n\n\n\n2. Ownership & Impact\n\nUnlike rigid corporate structures, Gameskraft gives engineers complete freedom and ownership to design, build, and optimize large-scale data pipelines. Your work directly impacts business decisions, game fairness, and player experience, ensuring data is actionable and insightful.\n\n\n\n\n3. High-Growth, Fast-Paced Environment\n\nWe are one of Indias fastest-growing gaming companies, scaling rapidly since 2017. You will be part of a dynamic team that moves fast, innovates continuously, and disrupts the industry with cutting-edge solutions.\n\n\n\n\n4. Strong Engineering Culture\n\nWe value technical excellence, continuous learning, and deep problem-solving. We encourage engineers to experiment, contribute, and grow, making this an ideal place for those who love tackling complex data engineering challenges.\n\n\n\n\nWhy Join Gameskraft?\n\n\n\n\nWork on high-scale, real-time data processing challenges.\nOwn end-to-end design and implementation of data pipelines.\nCollaborate with top-tier engineers and data scientists.\nEnjoy a fast-growing and financially stable company.\nFreedom to innovate and contribute at all levels.\n\n \n\nWork Culture\n\nA true startup culture - young, fast paced, where you are driven by personal ownership of solving challenges that help you grow fast\nFocus on innovation, data orientation, being results driven, taking on big goals, and adapting fast\nA high performance, meritocratic environment, where we share ideas, debate and grow together with each new product\nMassive and direct impact on the work you do. Growth through solving dynamic challenges\nLeveraging technology & analytics to solve large scale challenges\nWorking with cross functional teams to create great product and take them to market\nRub shoulders with some of the brightest & most passionate people in the gaming & consumer internet industry\n\n\n\n\nCompensation & Benefits\n\n\n\n\nAttractive compensation and ESOP packages\nINR 5 Lakh medical insurance cover for yourself and your family\nFair & transparent performance appraisals\nAn attractive Car Lease policy\nRelocation benefits \nA vibrant office space with fully stocked pantries. And your lunch is on us!",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4266937850": {
    "job_url": "https://www.linkedin.com/jobs/view/4266937850",
    "job_summary": "Staff Software Engineer\nStaff Software Engineer with verification\nZepto\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nOur Story\n\nZepto is one of the fastest growing startups in India today. Just 6 months after launching, we've raised $160million from marquee investors in Silicon Valley and India. Our Founders, Aadit Palicha and Kaivalya Vohra, dropped out of Stanford University to build Zepto in India.\n\nTogether, theyve created an incredibly strong team, with Senior Executives from Uber, Flipkart,Dream11,Pepperfry, and Pharmeasy. The magic of Zepto is our ability to consistently deliver 3,000+ products in 10 minutes flat. It's the core of whatwe do, and the reason why weve been able to grow so fast with phenomenal customer love. Our mission issimple: to make 10-minute delivery the new normal.\n\n\n\n\nEngineering @ Zepto\n\nBuilding for scale, rapid iterative development, and customer-centric product thinking at each step define every day for a Zepto engineer. If building technology that impacts millions, brainstorming with some of the best minds in the country, executing at lightning speed, product-driven thinking, and owning your work from start to finish excites you, then Zepto is the right place for you.\n\n\n\n\nPrimary Responsibilities\n\n Write maintainable/scalable/efficient code.\n\n Design and architect technical solutions for the business problems of a very large e-commerce portal.\n\n Work in cross-functional team, collaborating with peers during entire SDLC.\n\n Follow coding standards, unit-testing, code reviews etc\n\n Follow release cycles and commitment to deadlines.\n\n\n\n\nWhat Are We Looking For?\n\n 6+ years of experience in building large scale applications or products.\n\n A Bring It On attitude; bias for action; self-driven, end-to-end ownership; entrepreneurial\n\n approach; focus on operational excellence; ability to work with ambiguity.\n\n Strong in problem solving skills, data structures and algorithms.\n\n Very good understanding of one or more of RDBMS/NoSQL/ Messaging/ Caching technologies.\n\n Excellent understanding of and coding skills in following technologies: Java\n\n B Tech/BE in Computer Science or equivalent from a reputed institution.\n\n\n\n\nWhy Join Us?\n\n Zepto is on a blitzscaling path unlike any other startup today.\n\n The opportunity to join Indias next Unicorn is rare. Given our very high hiring bar, we offer a very\n\ncompetitive salary and substantial equity to create everlasting wealth for our early believers as the\n\ncompany grows.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4256744191": {
    "job_url": "https://www.linkedin.com/jobs/view/4256744191",
    "job_summary": "Python Developer (ML)\nPython Developer (ML)\nMResult\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nEasy Apply",
    "job_details": "About the job\n\nJob Role: Python Developer - ML \n\nLocation: Bangalore/Mangalore - Hybrid \n\nType: Full-Time\n\n\n\n\nWhy MResult?\n\nFounded in 2004, MResult is a global digital solutions partner trusted by leading Fortune 500 companies in industries such as pharma & healthcare, retail, and BFSI. MResults expertise in data and analytics, data engineering, machine learning, AI, and automation help companies streamline operations and unlock business value. As part of our team, you will collaborate with top minds in the industry to deliver cutting-edge solutions that solve real-world challenges.\n\n\n\n\nWebsite: https://mresult.com/ \n\n\n\n\nWhat We Offer:\n\nAt MResult, you can leave your mark on projects at the worlds most recognized brands, access opportunities to grow and upskill, and do your best work with the flexibility of hybrid work models. Great work is rewarded, and leaders are nurtured from within. Our values  Agility, Collaboration, Client Focus, Innovation, and Integrity  are woven into our culture, guiding every decision.\n\n\n\n\nWhat This Role Requires \n\nWe are looking for a skilled and motivated Python Developer to join our dynamic team. The ideal candidate should have 3-5 years of experience in software development with a strong background in building production-grade Python applications. Additionally, hands-on expertise in Streamlit for developing interactive web applications is crucial. This role also requires a basic understanding of Machine Learning concepts and proficiency in working with Pandas, NumPy, and Scikit-learn. The selected candidate will be responsible for developing, deploying, and maintaining robust, scalable Python solutions with a focus on data-driven applications and interactive dashboards. \n\n\n\n\nHere is what you will do: \n\n Develop, test, deploy, and maintain high-quality Python code for production environments.\n\n Design and build interactive web applications and dashboards using Streamlit. \n\n Perform data manipulation, cleaning, and analysis using Pandas and NumPy. \n\n Implement and work with basic ML models using Scikit-learn for classification, regression, or clustering tasks. \n\n Write efficient, well-documented, and maintainable code. \n\n Participate in code reviews and contribute to a collaborative development environment. \n\n Troubleshoot, debug, and upgrade existing systems as needed. \n\n Hands-on experience with Docker and Kubernetes (AWS EKS) is preferred.\n\n\n\n\nKey Skills to Succeed in This Role: \n\n Strong expertise in Python programming. \n\n Experience with Streamlit for creating interactive applications. \n\n Knowledge of Machine Learning fundamentals. \n\n Proficiency in Pandas, NumPy, and Scikit-learn. \n\n Familiarity with Docker and Kubernetes (AWS EKS) is a plus. \n\n Ability to write clean, efficient, and scalable code. \n\n Strong problem-solving and analytical skills. \n\n Excellent communication and team collaboration skills.\n\n\n\n\nManage, Master, and Maximize with MResult \n\nMResult is an equal-opportunity employer committed to building an inclusive environment free of discrimination and harassment. Take the next step in your career with MResult  where your ideas help shape the future.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4267214158": {
    "job_url": "https://www.linkedin.com/jobs/view/4267214158",
    "job_summary": "Python Full Stack Engineer\nPython Full Stack Engineer with verification\nInfoBeans\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob title - Python Django Full Stack Engineer - Senior Developer \n\nJob location- Indore/ Pune/Chennai/Bangalore ( Hybrid )\n\nExperience Required - 10+ Years \n\n\n\n\nJob Description : \n\nPython Django Developer with React and Azure/AWS Exposure\n\n\n\n\nResponsibilities\n\nDevelop highly scalable applications in Python/Django framework and Azure/AWS experience\n\nCreate and deploy applications in azure environment with various interconnected Azure components.\n\nUnderstand and enhance front-end applications using React JS, HTML5 and CSS3.\n\nIdentify and fix bottlenecks that may arise from inefficient code.\n\nKnowledge of user authentication and authorization between multiple systems, servers and environments.\n\nEnsure that programs are written to the highest standards (e.g., Unit Tests) and technical specifications.\n\nDocumentation of the key aspects of the project.\n\nAbility to collaborate on projects and work independently when required.\n\n\n\n\nQualifications\n\n7+ years of prior experience as a developer in the required technologies\n\nSolid organizational skills, ability to multi-task across different projects\n\nExperience with Agile methodologies\n\nSkilled at independently researching topics using all means available to discover relevant information\n\nAbility to work in a team environment\n\nExcellent verbal and written communication skills\n\nSelf-starter with ability to multi-task and to maintain momentum\n\n\n\n\nShare your updated resume at sanjana.thakur@infobeans.com",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4257972383": {
    "job_url": "https://www.linkedin.com/jobs/view/4257972383",
    "job_summary": "Software Engineer Backend (SDE 2)\nSoftware Engineer Backend (SDE 2)\nArcana\nBangalore Urban, Karnataka, India (On-site)\n3 school alumni work here\n3 Indian Institute of Technology (Banaras Hindu University), Varanasi school alumni work here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJoin our dynamic team at the forefront of cutting-edge technology as we seek a seasoned Senior Backend Engineer. Embark on a journey where your deep-rooted expertise in computer science fundamentals, alongside an intricate understanding of data structures, algorithms, and system design, becomes the cornerstone of innovative solutions. This pivotal role not only demands your proficiency in developing and elevating compute and I/O-intensive applications but also ensures their peak performance and unwavering reliability.\n\n\n\n\nResponsibilities:\n\nArchitect, refine, and escalate the capabilities of complex backend systems using Python, with a laser focus on efficiency, durability, and scale.\nElevate application performance, optimizing for speed, scalability, and resource allocation.\nForge robust methodologies to manage high concurrency and vast data volumes, setting new industry benchmarks.\nCollaborate intimately with engineering and product peers to crystallize requirements into resilient, scalable architectures.\nDemonstrate proficiency with advanced storage solutions and databases like Redis, PostgreSQL, and ClickHouse, enhancing system integrity.\nChampion coding excellence, testing rigor, and deployment precision, driving best practices across the development lifecycle.\n\nRequirements:\n\nBachelor's or Master's degree in Computer Science, Engineering, or a related field.\nMinimum of 2 years of experience in backend development with Python in a production environment.\nProven experience in scaling compute and I/O-intensive applications.\nStrong foundation in computer science, with a deep understanding of data structures, algorithms, and system design principles.\nExperience in handling concurrent requests at scale and optimizing large-scale systems for performance and reliability.\nFamiliarity with database technologies such as Redis, PostgreSQL, and ClickHouse.\nExperience in the financial sector, particularly in developing fintech applications or systems, is a plus.\nSolid understanding of software development life cycle, continuous integration, and continuous delivery (CI/CD) practices.\n\nExcellent problem-solving abilities and strong communication skills.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4267674346": {
    "job_url": "https://www.linkedin.com/jobs/view/4267674346",
    "job_summary": "Data Engineer\nData Engineer with verification\nL&T Technology Services\nBengaluru, Karnataka, India (On-site)\n1 connection works here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob Title: Data Engineer\n\nLocation: Bengaluru\n\n\n\n\nL&T Technology Services is seeking a Data Engineer (Experience range - 9+ years) of experience, proficient in:\n\n\n\n\n\n\n\n9+ years relevant data engineering hands on work experience- data ingestion, processing, exploratory analysis to build solutions that deliver value through data as an asset.\nData engineer build ,test and deploy data pipelines efficiently and reliably move data across systems and should be top of latest architectural trends on AZURE cloud.\nFolks who understand parallel and distributed processing, storage, concurrency, fault tolerant systems.\nFolks who thrive on new technologies, able to adapt and learn easily to meet the needs of next generation engineering challenges.\nTechnical Skills (Must-Have)\nApplied experience with distributed data processing frameworks - Spark , Databricks with Python and SQL\nMust have worked at least 2 end-end data analytics projects with Databricks Configuration , Unity Catalog, Delta Sharing and medallion architecture.\nApplied experience with Azure Data services ADLS , Delta\nRequired Skills: Azure Data Lake Storage (ADLS), Advanced SQL and Python Programming, Databricks Expertise with Medallion Architecture, Data Governance and Security, \n\n\n\n\n\n\n\n#AzureDataEngineer, #AzureCloud, #AzureDatabricks, #AzureDataLake, #AzureSynapse, #AzureDataFactory, #AzureSQL, #Databricks, #DataEngineering, #Python, #Flask",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4262885794": {
    "job_url": "https://www.linkedin.com/jobs/view/4262885794",
    "job_summary": "Software Engineer (Backend / AI)\nSoftware Engineer (Backend / AI)\nRaven\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout Us\n\nRaven is a YC-backed startup (S22) building AI assistants for manufacturing plants. Were taking decades of manufacturing expertise and combining it with AI to solve real operational problems. Backed by top VCs, were a small, focused team working to make industrial operations safer, smarter, and more efficient. Were based in Bangalore, building for teams that work in some of the toughest environments.\n\n\n\n\nWhat Youll Work On\n\nThis is a core technical role focused on building AI-native applications and agents for manufacturing workflows. Youll:\n\nBuild Python/Go backend services that integrate tightly with AI systems.\nHelp improve multi-modal pipeline infrastructure that handle P&IDs, SOPs, sensor data, and technical documents.\nBuild agent memory systems using knowledge graphs and event timelines.\nArchitect AI orchestration layers for decision making workflows from structured/unstructured plant data.\nRapidly prototype new AI workflows and deploy in real-world plant environments.\n\n\n\n\nWho Were Looking For\n\n24+ years experience building production systems.\nStrong Python/Go skills, familiar with LLMs, embeddings, vector stores.\nInterest in owning problems and figuring out solutions\nDeep interest in owning problems end-to-endfrom exploring the solution space to deploying working systems in production.\nComfortable working in ambiguity, iterating fast, and shipping real-world value.\n\nBonus: Youve worked in a startup before and are comfortable wearing multiple hats.\n\n\n\n\nWhy Join Us \n\nWere not just building one-off toolswere building core systems that empower plant teams to make faster, safer decisions. This is about creating systems that process complex, scattered information and make it accessible in seconds.\n\n\n\n\nHeres what we offer:\n\nImpact: Be one of the first hires and shape the product, culture, and direction of the company. Ownership: Were offering 0.1-1% equity because this should feel like your company too.\n\nFocus: This is a chance to work on deep, meaningful problems that directly affect real-world outcomes in safety and efficiency.\n\n\n\n\nWe believe in working together in person, especially at this stage of the company. Fast iteration and collaboration matter, and being in the room together makes a difference.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4266935972": {
    "job_url": "https://www.linkedin.com/jobs/view/4266935972",
    "job_summary": "Software Dev Engineer I\nSoftware Dev Engineer I\nTekWissen India\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nOverview: \n\nTekWissen is a global workforce management provider that offers strategic talent solutions to our clients throughout India and world-wide. Our client is a company operating a marketplace for consumers, sellers, and content creators. It offers merchandise and content purchased for resale from vendors and those offered by thirdparty sellers. \n\n\n\n\nJob Title: Software Dev Engineer I\n\nLocation: Bengaluru\n\nJob Type: Contract \n\nWork Type: Remote\n\n\n\n\nJob Description: \n\nThe Top Responsibilities:\n\nCritically analyze and evaluate code responses generated by our LLMs across various programming languages and paradigms\nExercise expert judgment to select the most appropriate and efficient code solutions from multiple LLM-generated options\nMake informed decisions on behalf of our customers, ensuring that selected code meets industry standards, best practices, and specific client needs\nDevelop and write coding demonstrations to illustrate \"what good looks like\" in AI-generated code, setting benchmarks for quality and efficiency\nProvide detailed feedback and explanations for your evaluations, helping to refine and improve the LLM's understanding and output\nCollaborate with the AI research team to identify areas for improvement in the LLM's coding capabilities\nStay abreast of the latest developments in software engineering, coding standards, and AI to ensure our evaluations remain cutting-edge\n\nLeadership Principles:\n\nBias for Action, Deliver Results\n\nMandatory Requirements:\n\nAdvanced degree in Computer Science, Software Engineering, or a related field\nExtensive experience (1+ years) in software development across multiple programming languages and paradigms\nDemonstrated ability to critically evaluate code quality, efficiency, and adherence to best practices\nStrong analytical and decision-making skills, with the ability to make complex judgments under ambiguous circumstances\nExcellent written and verbal communication skills, with the ability to explain technical concepts clearly\nExperience in technical writing, particularly in creating coding examples or tutorials\n\nPreferred skills:\n\nPrevious experience working with or evaluating AI systems, particularly in the context of code generation\nFamiliarity with a wide range of software development methodologies and architectural patterns\nUnderstanding of machine learning concepts, particularly as they apply to natural language processing and code generation\nExperience in creating or contributing to coding standards or style guides\nThis role requires a unique blend of technical expertise, critical thinking, and communication skills.\nYou will be the bridge between advanced AI technology and practical, real-world coding applications.\nYour work will directly influence the development of next-generation AI coding assistants, shaping the future of software development.\nIf you're passionate about code quality, have a keen eye for detail, and are excited about the potential of AI in software engineering, we encourage you to apply for this pivotal role at AGI Data Services.\n\nEducation or Certification:\n\nGraduation in CSE or IT\n\nTekWissen Group is an equal opportunity employer supporting workforce diversity.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4260684006": {
    "job_url": "https://www.linkedin.com/jobs/view/4260684006",
    "job_summary": "Software Engineer\nSoftware Engineer with verification\nGrid Dynamics\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nLocation-Bangalore\n\nTE-4 Years and above\n\nLocation- Bangalore\n\nJob Description:\n\nBachelor's degree in Computer Science, or related technical discipline. With software development experience in building large scale Bigdata platform.\nProficiency in engineering practices and writing high quality code, with expertise in Java (+python), Maven, Jenkins pipeline.\nAny software development experience in database technology (SQL engines) is added advantage.\n\nAbout Us:\n\nGrid Dynamics (Nasdaq:GDYN) is a digital-native technology services provider that accelerates growth and bolsters competitive advantage for Fortune 1000 companies. Grid Dynamics provides digital transformation consulting and implementation services in omnichannel customer experience, big data analytics, search, artificial intelligence, cloud migration, and application modernization. Grid Dynamics achieves high speed-to-market, quality, and efficiency by using technology accelerators, an agile delivery culture, and its pool of global engineering talent. Founded in 2006, Grid Dynamics is headquartered in Silicon Valley with offices across the US, UK, Netherlands, Mexico, India, Central and Eastern Europe.\n\nTo learn more about Grid Dynamics, please visit www.griddynamics.com. Follow us on Facebook, Twitter, and LinkedIn.\n\n--",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4267074232": {
    "job_url": "https://www.linkedin.com/jobs/view/4267074232",
    "job_summary": "Software Engineer\nSoftware Engineer with verification\nCivica\nVadodara, Gujarat, India (Remote)\n\u20b91.2M/yr\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nWe're Civica and we make software that helps deliver critical services for citizens all around the world. From local to state government, to education, to health and care, over 5,000 public bodies across the globe use our software to help provide critical services to over 100 million citizens. \n\nOur aspiration is to be a GovTech champion everywhere we work around the globe, supporting the needs of citizens and those that serve them every day. Building on 21 years of continuous growth and success, we're at a pivotal point on our journey to realise that aspiration. \n\nAs a company, we're passionate about what we do and the citizens we help to serve. If you too would like to help champion the use of technology in public services, to improve outcomes for citizens and public sector organisations, then Civica is the right place for you. We will help you unlock the best version of yourself, achieve growth in your career whilst making a real difference to people and communities. \n\nWhy you will love this opportunity as Software Engineer at Civica \n\nAs a Software Engineer, you'll play a crucial role in designing, writing, and maintaining testing code in line with the exciting roadmap set by our Product Management team. You'll be an essential part of the Engineering Team, participating in lively technical discussions, contributing to in-depth design reviews, and tackling interesting problem-solving challenges.\n\nAs a part of our dynamic engineering team, you will:\n\nAnalyze new requirements and perform detailed impact analysis, contributing to technical design and task breakdown.\nArchitect, design, and implement scalable, high-quality solutions.\nSet up and maintain CI/CD pipelines, ensuring smooth deployment across Dev, Test, and Production environments.\nWrite clean, maintainable code and develop new features in line with business needs.\nClearly communicate technical aspects that impact requirement delivery and product functionality.\nParticipate in iterative development with openness to feedback and continuous improvement.\nProvide third-line application support, including bug fixes aligned with agreed SLAs.\nTroubleshoot, investigate, and resolve technical issues in collaboration with the Engineering Manager.\nReview code, mentor peers, and advocate for Agile principles and modern development best practices.\nPerform thorough unit testing and ensure appropriate test coverage.\nMaintain proper code documentation, version control, and commenting for future-proof development.\n\n\n\nRequirements\n\n\n\nYour keys to thriving in this position:\n\nA minimum of 3 years of relevant experience is essential.\nA solid foundation in .Net development, encompassing .Net Core, C#, and Angular.\nA self-driven professional who excels independently and as a vital team player.\nThe ability to navigate both detailed tasks and high-level concepts.\nA passion for Agile methodologies and fostering a collaborative environment.\nPractical experience with cloud-based applications.\nA proven track record in crafting secure and high-performing software solutions.\nA history of meeting deadlines with exceptional quality.\n\n\n\nSkills We're Looking For:\n\nExperience with .NET and .NET Framework using C# - 3+ years\nExperience with .NET Web API - 3+ years\nProficiency in Databases (SQL Server) - 3+ years\nSkilled in Javascript / Typescript - 3+ years\nFamiliarity with front-end frameworks (VueJs preferred) - 3+ years\nUnit Testing experience (XUnit/NUnit/MSTest) - 2+ years\nKnowledge of Docker and Kubernetes - 1+ year\nExperience with Azure DevOps - Pipelines, Artifacts, Repos - 1+ year\nFamiliarity with Azure services (AppInsights, Storage, KeyVault, etc.) - 1+ year\nExperience in E2E Testing (Playwright preferred) - 1+ year\nProficient with ORM technologies (Entity Framework/Dapper/NHibernate/ADO.Net) - 1+ year\n\n\n\n\nBenefits\n\n\n\n\nWhy you'll love working with us \n\nWe know that when our people are happy, they will work better and have greater work satisfaction. Here's what you can expect: \n\nWe're all different -and we love this about us. \n\nWe provide an inclusive,safe, and welcoming environment to all Civicans - there are heaps of opportunities to enable you to grow and be your best. \n\nGiving culture -we encourage you to \"give back\" with benefits such as our Days of Difference leave where you can volunteer for a charity of your choice. \n\nFlexible Work -Flexible work - we have the technology and tools to support you to work from home and come into our offices now and then to catch up and socialise with colleagues. \n\nApply for this job - Become part of something special Do you see yourself in this role? If so, then we would love to hear from you.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4203767624": {
    "job_url": "https://www.linkedin.com/jobs/view/4203767624",
    "job_summary": "Data Engineer\nData Engineer\nImpetus\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout Impetus\n\n\n\n\nImpetus Technologies is a digital engineering company focused on delivering expert services and products to help enterprises achieve their transformation goals. We solve the analytics, AI, and cloud puzzle, enabling businesses to drive unmatched innovation and growth.\n\nFounded in 1991, we are cloud and data engineering leaders providing solutions to fortune 100 enterprises, headquartered in Los Gatos, California, with development centers in NOIDA, Indore, Gurugram, Bengaluru, Pune, and Hyderabad with over 3000 global team members. We also have offices in Canada and collaborate with a number of established companies, including American Express, Bank of America, Capital One, Toyota, United Airlines, and Verizon.\n\n\n\n\nExperience- 3-8 years\n\n\n\n\nLocation- Gurgaon & Bangalore\n\n\n\n\nJob Description\n\nYou should have extensive production experience in GCP, Other cloud experience would be a strong bonus.\n\n- Strong background in Data engineering 2-3 Years of exp in Big Data technologies including, Hadoop, NoSQL, Spark, Kafka etc.\n\n- Exposure to enterprise application development is a must\n\n\n\n\nRoles & Responsibilities\n\nAble to effectively use GCP managed services e.g. Dataproc, Dataflow, pub/sub, Cloud functions, Big Query, GCS - At least 4 of these Services.\nGood to have knowledge on Cloud Composer, Cloud SQL, Big Table, Cloud Function.\nStrong experience in Big Data technologies  Hadoop, Sqoop, Hive and Spark including DevOPs.\nGood hands on expertise on either Python or Java programming.\nGood Understanding of GCP core services like Google cloud storage, Google compute engine, Cloud SQL, Cloud IAM.\nGood to have knowledge on GCP services like App engine, GKE, Cloud Run, Cloud Built, Anthos.\nAbility to drive the deployment of the customers workloads into GCP and provide guidance, cloud adoption model, service integrations, appropriate recommendations to overcome blockers and technical road-maps for GCP cloud implementations.\nExperience with technical solutions based on industry standards using GCP - IaaS, PaaS and SaaS capabilities.\nExtensive, real-world experience designing technology components for enterprise solutions and defining solution architectures and reference architectures with a focus on cloud technologies.\nAct as a subject-matter expert OR developer around GCP and become a trusted advisor to multiple teams.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4268114523": {
    "job_url": "https://www.linkedin.com/jobs/view/4268114523",
    "job_summary": "GenAI Sofware Engineer\nGenAI Sofware Engineer with verification\nNielsenIQ\nPune/Pimpri-Chinchwad Area (Remote)\n1 connection works here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob Description\n\nAbout the Role Youll be a key contributor on our AI Engineering team, building and maintaining the production-grade microservices and APIs that power our GenAI productschatbots, document pipelines, retrieval endpoints, and embedding search. Your primary focus will be delivering clean, well-tested code; robust API designs; and reliable CI/CD processes.\n\nCore Responsibilities\n\n\n API & Service Development\nDesign and implement RESTful (and optionally gRPC) Python services using FastAPI, Flask, or Django\nDefine clear API contracts (e.g. OpenAPI/Swagger) and maintain semantic versioning\n Production-Grade Code Quality\nApply SOLID principles and clean-code practices to keep services modular and maintainable\nPerform regular refactoring to reduce technical debt and adhere to style guides (flake8, black)\nDrive thorough code reviews, enforcing best practices and design consistency\n Testing & Validation\nAdopt test-driven development: write and maintain unit, integration, and end-to-end tests with pytest\nMock external dependencies (LLM clients, vector stores) to validate error handling and edge cases\nEnsure high test coverage and set up automated quality gates in CI pipelines\n CI/CD & Deployment\nBuild and maintain CI/CD pipelines (GitHub Actions, Jenkins, or GitLab CI) that run tests, linting, security scans, and deployments\nContainerize services with Docker and deploy to Kubernetes (or serverless) environments\nAutomate release/versioning workflows and rollback strategies for low-risk releases\n Collaboration & Documentation\nPartner with MLOps, Data Science, and UX/UI teams to integrate new model capabilities\nMaintain up-to-date design docs, API specs, and getting started guides for engineering peers\nContribute to sprint planning, design reviews, and process improvements\n\n\nRequired Qualifications\n\n\n Experience: 35 years building production Python services\n Frameworks:\nFastAPI, Flask, or Django for API development\nAsynchronous frameworks (AsyncIO, aiohttp) for high-concurrency endpoints\n APIs & Protocols: Strong REST experience; basic gRPC or streaming is a plus\n Testing: Proven TDD with pytest (unit/integration tests and mocks)\n CI/CD: Hands-on with GitHub Actions, Jenkins, GitLab CI, or equivalent\n Containers & Orchestration: Proficiency with Docker; experience deploying to Kubernetes or serverless\n\n\nNice-to-Have & Growth Areas\n\n\n Familiarity with vector stores (Faiss, Pinecone, Weaviate) and embedding search integration\n Experience with WebSockets or SSE for real-time chat\n Exposure to message brokers (Kafka, RabbitMQ) for event-driven architectures\n Knowledge of feature-flagging, A/B testing, or experimentation platforms\n Experience in other languages like Java, C++\n\n\nSoft Skills\n\n\n Problem Solver: Diagnoses and debugs complex issues across code, infra, and external services\n Communicator: Explains design trade-offs clearly to both technical and non-technical audiences\n Collaborator: Works effectively in cross-functional teams and helps peers level up\n Learner: Quickly adopts new tools and practices in the fast-moving GenAI landscape\n\n\nAdditional Information\n\nOur Benefits\n\n\nFlexible working environment\nVolunteer time off\nLinkedIn Learning\nEmployee-Assistance-Program (EAP)\n\n\nAbout NIQ\n\nNIQ is the worlds leading consumer intelligence company, delivering the most complete understanding of consumer buying behavior and revealing new pathways to growth. In 2023, NIQ combined with GfK, bringing together the two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insightsdelivered with advanced analytics through state-of-the-art platformsNIQ delivers the Full View. NIQ is an Advent International portfolio company with operations in 100+ markets, covering more than 90% of the worlds population.\n\nFor more information, visit NIQ.com\n\nWant to keep up with our latest updates?\n\nFollow us on: LinkedIn | Instagram | Twitter | Facebook\n\nOur commitment to Diversity, Equity, and Inclusion\n\nNIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide. Learn more about how we are driving diversity and inclusion in everything we do by visiting the NIQ News Center: https://nielseniq.com/global/en/news-center/diversity-inclusion",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4260688530": {
    "job_url": "https://www.linkedin.com/jobs/view/4260688530",
    "job_summary": "Python Developer\nPython Developer\nDBiz.ai\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nIntroduction:\n\nDigital Biz Solutions Pty Ltd is a digital innovation company trusted by enterprise clients to deliver robust data engineering and AI-driven solutions. We are looking for a Python Data Engineer to join a growing team working on high-impact data transformation and analytics projects across industries.\n\n\n\n\nRole Overview:\n\nAs a Python Data Engineer, you will be responsible for building and maintaining scalable, reliable data pipelines using Python and orchestration tools such as Mage.AI or Airflow. You will contribute to data ingestion, transformation, warehousing, and cloud-based deployment.\n\n\n\n\nLocation: Bengaluru/Kochi\n\n\n\n\nRequired Skills:\n\no Proven experience as a Python Developer with a strong focus on data engineering.\n\no Proficiency in Mage.AI/airflow/any similar data pipeline orchestration and workflow management\n\no Solid understanding of ETL processes and data warehousing concepts and modelling techniques\n\no Experience with connecting to and managing data in data warehouses like PostgreSQL, AWS Redshift, or similar.\n\no Familiarity with data ingestion from various sources (APIs, databases, files).\n\no Strong problem-solving and analytical skills.\n\no Excellent communication and collaboration abilities.\n\no Bachelor's degree in Computer Science, Engineering, or a related field, or equivalent practical experience.\n\n\n\n\nPreferred Qualifications:\n\no Experience with deploying data pipelines in cloud environments (e.g., AWS EMR, Kubernetes).\n\no Hands-on experience with PySpark's machine learning libraries (Spark MLlib).\n\no Knowledge of real-time data processing and stream analytics.\n\no Familiarity with other data engineering tools and technologies.\n\no Contributions to open-source data projects.\n\no experience with PySpark for big data processing, transformation, and analytics.\n\n\n\n\nLife at Dbiz:\n\nCompetitive salary and attractive benefits\nDynamic and innovative work environment\nOpportunities for personal growth and development\nEngaging and collaborative company culture",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4259167708": {
    "job_url": "https://www.linkedin.com/jobs/view/4259167708",
    "job_summary": "Back End Developer\nBack End Developer\nAsymmetric Labs\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nCompany Description\n\n\n\n\nAsymmetric Labs is an AI-first, new-age ed-tech company based in Bengaluru. We focus on outcomes such as ranks, jobs, and career progression. Despite being in stealth mode, we are already backed by some of the industry's best investors and advisors.\n\n\n\n\nRole: Back-end Developer (1.5-4 years of experience)\n\nLocation: Bengaluru(On-site)\n\nType: Full-time\n\n\n\n\nAbout the Role\n\n\n\n\nWere looking for a backend-focused developer whos just starting out but already thinks critically about system design, clean code, and long-term scalability. You'll be part of a lean, fast-moving team, responsible for building and maintaining the APIs and backend services that power our platform.\n\nThis is a high-ownership role ideal for someone who thrives in a fast-paced startup environment and is eager to grow into a world-class engineer.\n\n\n\n\nWhat You'll Do\n\n\n\n\nDevelop and maintain scalable backend services and APIs\nWork with MongoDB and other data stores (NoSQL/SQL)\nOptimize performance and reliability at scale\nContribute to code reviews and system architecture decisions\nCollaborate with the tech team in short feedback loops to ship, learn, and iterate quickly\n\n\n\n\n\n\n\n\n\n\nWhat We're Looking For\n\n\n\n\n1.5- 4 \n\nYears of backend development experience\nProficiency in Python (preferably Django or Flask)\nUnderstanding of API design and backend architecture principles\nFamiliarity with MongoDB or similar databases\nInterest in cloud platforms (AWS), CI/CD workflows, and deployment tooling\nObsession with clean, maintainable code and modular design\nA \"tech purist\" mindset  you enjoy building things the right way, not just the fastest way\nExposure to early-stage startups, open-source contributions, or serious side projects\nBachelors degree in CS/Engineering or equivalent self-taught experience\n\n\n\n\n\n\n\n\n\n\nWhy Join Us\n\n\n\n\nCollaborate closely with a sharp, hands-on founding team\nTackle meaningful problems in learning, careers, and education\nShape critical backend systems from the ground up\nFast growth and high autonomy in a builder-first environment\n\n\n\n\n\n\n\n\n\n\nIf youre serious about systems, love clean architecture, and want to build from first principles, lets talk.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4271175544": {
    "job_url": "https://www.linkedin.com/jobs/view/4271175544",
    "job_summary": "Big Data Developer\nBig Data Developer\nImpetus\nBengaluru, Karnataka, India (On-site)\nCompany review time is typically 1 week\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob Description\n\n** LOOKING FOR IMMEDIATE JOINERS ONLY**\n\nQualification\n\nDegree  Graduates/Postgraduate in CSE or related field\n\n\n\n\nJob Descriptions for Big data or Cloud Engineer\n\n\n\n\nPosition Summary:\n\nWe are looking for candidates with hands on experience in Big Data or Cloud Technologies.\n\n\n\n\n\n\n\nMust have technical Skills\n\n3-6 Years of experience\nExpertize and hands-on experience on Python  Must Have\nExpertize knowledge on SparkQL/Spark Dataframe  Must Have\nGood knowledge of SQL  Good to Have\nGood knowledge of Shell script  Good to Have\nGood Knowledge of one of the Workflow engine like Oozie, Autosys  Good to Have\nGood knowledge of Agile Development Good to Have\nGood knowledge of Cloud- Good to Have\nPassionate about exploring new technologies  Good to Have\nAutomation approach -  Good to Have\n\n\n\n\nRoles & Responsibilities\n\n\n\n\nSelected candidate will work on Data Warehouse modernization projects and will responsible for the following activities.\n\nDevelop programs/scripts in Python/Java + SparkSQL/Spark Dataframe or Python/Java + Cloud native SQL like RedshiftSQL/SnowSQL etc.\nValidation of scripts\nPerformance tuning\nData ingestion from source to target platform\nJob orchestration",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4267436505": {
    "job_url": "https://www.linkedin.com/jobs/view/4267436505",
    "job_summary": "Machine Learning Engineer\nMachine Learning Engineer with verification\nHCLSoftware\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nCompany Description\n\nHCL Software is a division of HCL Technologies (HCL) that operates its primary software\n\nbusiness. It develops, markets, sells, and supports over 20 product families in the areas of\n\nDevOps, Security, Automation, Digital Solutions, Data Management, Marketing and Commerce,\n\nand Mainframes. Its mission is to drive ultimate customer success with their IT investments\n\nthrough relentless innovation of its products.\n\n\n\n\nJob Title: Senior Machine learning engineer /Lead Machine Learning Engineer\n\n\n\n\nLocation: India (Bangalore)\n\n\n\n\nExperience required-\n\n4 to 7 years\n10 to 13 years\n\n\n\n\nResponsibilities:\n\n\n\n\n\n\n\nAbout the Role\n\nWe are seeking a highly skilled and experienced Lead Machine Learning Engineer to join our dynamic team supporting a fast-growing e-commerce platform. In this role, you will lead the development and deployment of intelligent systems that enhance user experience, optimize operations, and drive business growth. You will work closely with cross-functional teams to build scalable ML solutions, leveraging modern agentic frameworks and cloud-native technologies.\n\n\n\n\nWe are seeking an experienced and innovative Lead Machine Learning Engineer to join our team supporting a fast-growing e-commerce platform. In this role, you will lead the design, development, and deployment of machine learning solutions that drive business value. You will collaborate with fellow engineers, cloud architects, and product teams to deliver scalable ML systems in production, mentor team members, and help define best practices for the organization.\n\n\n\n\nKey Responsibilities\n\nLead the end-to-end development and deployment of AI applications, from data exploration and feature engineering to model training, evaluation, and productionization.\nArchitect and implement scalable ML pipelines and infrastructure in cloud and on-prem environments.\nCollaborate with cross-functional teams to understand business requirements and translate them into technical solutions.\nBreak down complex implementations into executable tasks for junior engineers, enabling timely implementation of new platform features.\nGuide and mentor a team of ML engineers, fostering a culture of technical excellence and continuous learning.\nEnsure best practices in code quality, testing, version control, and model monitoring.\nEvaluate and recommend new tools, frameworks, and technologies to improve ML workflows.\nCommunicate technical concepts and project status to stakeholders at all levels.\nStay current with the latest research and advancements in machine learning and AI.\n\n\n\n\nRequired Qualifications\n\nexperience in AI/ML model development and deployment using Python.\nProven experience designing, deploying, and maintaining several AI applications in a production environment.\nProven experience delegating & overseeing task work supporting complex AI implementations.\nProficiency with cloud platforms (AWS, Azure, GCP) and ML services (e.g., SageMaker, Vertex AI, Azure ML).\nExperience deploying production Agentic and/or Gen AI applications on a cloud platform.\nExperience with data engineering, ETL pipelines, and big data tools (e.g., Spark, Hadoop).\nFamiliarity with MLOps practices, CI/CD, and model monitoring.\nExcellent leadership, communication, and collaboration skills.\n\n\n\n\nPreferred Qualifications\n\nExperience with Azure cloud services (e.g., Azure Blob Storage, Cosmos DB)\nExperience with Databricks, Spark, Spark Streaming\nExperience working with ecommerce data\nExperience with traditional Python ML frameworks (e.g. Tensorflow, XGBoost, Scikit, etc.)\nExperience with Orchestration frameworks (e.g. Dagster)\nExperience writing & maintaining cloud deployment pipelines",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4224293270": {
    "job_url": "https://www.linkedin.com/jobs/view/4224293270",
    "job_summary": "Software Engineer- Data Science\nSoftware Engineer- Data Science with verification\nEnergy Exemplar\nBengaluru, Karnataka, India (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout Energy Exemplar\n\nIn an era where the world is rapidly advancing towards a cleaner future through decarbonization, Energy Exemplars mission lies in Empowering Transformative Energy Decisions. Founded in 1999 in Adelaide, Australia, our award-winning software portfolio encompassing the modeling and simulation platform PLEXOS, Aurora, and Adapt2, is trusted by innovative organizations across the globe. Through our technology and people, we strive to enable stakeholders from across the entire energy value chain to revolutionize the energy ecosystem and to collaboratively plan and execute for a sustainable energy future with unprecedented clarity, speed, and innovation. \n\nOur impact is global and is being recognized across the industry. Some of our recent accolades include:\n\nSaaS Company of the Year (2025)  Global Business Tech Awards.\nEnvironmental Impact Award (2025)  E+E Leaders Awards.\nIPPAI (Independent Power Producers Association of India) Power Awards (2025) - Winners\nFinalist: Platts Global Energy Awards (2024)  Grid Edge category\nFinalist: Reuters Global Energy Transition Awards (2024)  Technologies of Change\nTop 50 Marketing Team (2024)  Voted by the public at the ICON Awards.\n\nHow We Work\n\nEnergy Exemplar is growing fast around 30% year on year and, that growth is driven by how we work. We trust our team to deliver great results from wherever they work best, whether thats at home, in the office, or on the move.\n\nWere a global team that values ownership, integrity, and innovation. Youll be supported to balance work and life in a way that works for you, and empowered to take initiative, solve problems, and make an impact, regardless of your background, location, or role.\n\nOur four core values, Customer Success, One Global Team, Integrity & Ownership, and Innovation Excellence arent just words. They show up in how we collaborate, how we solve, and how we grow together.\n\n \n\nAbout Energy Exemplar\n\nIn an era where the world is rapidly advancing towards a cleaner future through decarbonization, stakeholders from across the entire energy value chain are having to navigate the complexities of the energy ecosystem. We seek to enable our customers to do so with confidence. \n\nOur mission: Empowering Transformative Energy Decisions.\n\nFounded in 1999 in Adelaide, Australia, Energy Exemplars award-winning PLEXOS modeling and simulation software is trusted by innovative organizations across the globe. On one unified platform, stakeholders from across the entire energy value chain are revolutionizing the energy ecosystem and seamlessly planning for the future of energy with unprecedented clarity, speed, and innovation.\n\nOur impact is global and is being recognized across the industry:\n\nFinalist for the 2024 Reuters Global Energy Transition Awards in the 'Technologies of Change' category \nFinalist for the 2024 Go:Tech Awards in the 'Most Innovative Use of Technology category\n2022 USEA/USAID Corporate Volunteer of the Year \n2022 Impact Award Winner for our impact on the energy industry and the current energy transition \n\nEnergy Exemplar has grown significantly over the past few years, and we are continuing to do so at around 30% year on year. We dont just celebrate the excellence of our products but champion the quality of our people. They own their outcomes and perform to their best  every day. Thats what makes us who we are and a great place to work. Our core values Customer Success, One Global Team, Integrity and Ownership and Innovation Excellence reflect the way we work and are always at the forefront of everything we do.\n\n \n\n\nCandidate Requirements & Qualifications\n\n \n\n3+ years of professional experience in experiment design and applied machine learning predicting outcomes in large-scale, complex datasets.\nProficiency in Python, Azure ML, or other statistics/ML tools.\nProficiency in Deep Neural Network, Python based frameworks.\nProficiency in Azure DataBricks, Hive, Spark.\nProficiency in deploying models into production (Azure stack).\nModerate coding skills. SQL or similar required. C# or other languages strongly preferred.\nOutstanding communication and collaboration skills. You can learn from and teach others.\nStrong drive for results. You have a proven record of shepherding experiments to create successful shipping products/services.\nUnderstanding of the model development ecosystem across platforms, including development, distribution, and best practices, highly desirable\n\n \n\n \n\nDesired but not required (not needed for every position)\n\nExperience with prediction in adversarial (energy) environments highly desirable.\n\n \n\n \n\n \n\nEnergy Exemplar is an equal opportunities employer and we value your unique identity and perspective. We are fully committed to providing and fostering a workplace that reflects the diversity of society. Bring your authentic self and help us build an inclusive world together! To support you in being the best version of yourself during the application and interview process, please let us know if you have any specific requirements.\n\n \n\nEnergy Exemplar is proud to be an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all team members. We welcome applications from people of all backgrounds, experiences, identities, and abilities. Please let us know if you require accommodations at any stage of the recruitment processwe're here to support you in showcasing your full potential.\n\nEnergy Exemplar respects your privacy and is committed to protecting the personal data you share during the recruitment process. This Candidate Privacy Notice explains how we collect, use, and protect your personal information when you apply for a role with us.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4270099439": {
    "job_url": "https://www.linkedin.com/jobs/view/4270099439",
    "job_summary": "Software Developer - Golang\nSoftware Developer - Golang\nCAW\nBengaluru, Karnataka, India (On-site)\nCompany review time is typically 1 week\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nRoles and Responsibilities: \n\nUnderstand the feature requirements based on the product spec/business requirements document\nUnderstand API specification of Gateways and Banks and close on any clarifications working with Product Manager and Banking solutions \nWork on the technical specification for the feature development Collaborate with multiple teams if the solution spans different services and understand the functionality of different services \nOwn the complete implementation and testing spanning multiple services and implement changes in different services \nWrite extensible code which would help the customization done for a Bank/gateway to be extended to other banks/gateways \nResponsible for adding the necessary tests and alerts needed for the feature developed in the respective service \nBe part of team Oncall and help resolve production issues \n\n\n\n\nMandatory Qualifications: \n\n1-3 years of experience in application/web development \nGood experience in working with any of the programming language - Golang. \nGood understanding of REST APIs and the web in general \nWorking knowledge of AWS and Kubernetes is a plus \nUnderstand end user requirements, formulate use cases and come up with effective solutions \nAbility to build a feature from scratch & drive it to completion \nShould possess good communication and interpersonal skills \n\n\n\n\nLocation: Bangalore ",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4264838977": {
    "job_url": "https://www.linkedin.com/jobs/view/4264838977",
    "job_summary": "Senior Back End Developer\nSenior Back End Developer with verification\nDar\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nCompany Overview:\n\nDar, the founding member of the Sidara group, is an international multidisciplinary consulting organization specializing in engineering, architecture, planning, environment, project management, facilities management, and economics. Sidara operates in 60 countries with 20,500 professionals, Dar connects people, places, and communities through innovative solutions to the world's most complex challenges. We deliver projects from inception through completion, embracing challenges to empower communities worldwide. Learn more at www.dar.com.\n\n\n\n\n\n\n\nJob Summary:\n\nWe're looking for an experienced Senior Back-End Developer to join our tech team at Dar.\n\n\n\n\nIn this role, youll work on big challenges with data integration, processing, and automation. Your main goal will be to help teams use data effectively to support various business needs.\n\n\n\n\nOur Vision and Values:\n\nWe aspire to be the chosen home of those with a gift for crafting solutions that empower people and an unwavering passion for learning and innovation. Our core values shape our culture and guide our decision-making. We are committed to:\n\n\n\n\nExcellence\nResponsibility\nEmpowerment\nConnectivity\nCourage\n\n\n\n\nJob Description:\n\nResponsibilities include:\n\nDefine and implement strategies and technology that provide optimized data storage, high availability of data, along with failover mechanisms avoiding data loss or disconnection.\nContribute to architectural design and decisions\nImprove product by developing new or improving functionalities\nManage and improve CI procedures\nIdentify and implement improvements that reduce technical debt and enable the team to iterate faster\nCollaborate with cross-functional teams to implement the needful to serve the devised use cases.\nIdentifying and addressing performance and scalability issues. Able to take ownership on complex requirements and decompose them into a proposal of small deliverables.\nMentor your coworkers through code review, pair programming, team collaboration, and training to help improve our collective knowledge and best practices.\nConduct code reviews and mentor junior developers, fostering a culture of excellence\nParticipate in Agile development cycles and SCRUM meetings\nAbility to understand the technology landscape at different sites and develop proposals for the integration of value-added software solutions\nWriting secure, scalable, testable code using modern best practices and technologies\nBuild reusable code and libraries for future use and to comply with multiple clients or projects\nCompile and analyze data, processes, and codes to troubleshoot problems and identify areas for improvement\nAbility to perform the needed tests to ensure backend applications are optimized\nAdvise on methods to enhance the performance & architecture of existing databases\nAdvise on best practices and procedures for database management, storage, maintenance, backup, archive, & cleanup\nStay up-to-date with industry trends and best practices, advocating for innovation and driving technical excellence within the team\nCollaborate with junior backend developers, provide technical guidance, and participate in code reviews to ensure code quality and adherence to coding standards\nCreate and maintain a positive and collaborative team environment, fostering a culture of learning and continuous improvement\nCollaborate with cross-functional teams, including designers, product managers, and other developers, to deliver high-quality software solutions.\nWork within agile development methodologies, participating in code reviews, and providing feedback\n\nRequired Knowledge and Skills:\n\nProgramming languages: Python, JavaScript, .NET language (C#, VB.Net, etc.), JAVA is a plus\nDatabases: SQL, PostgreSQL, TimescaleDB (Time series database), NoSQL (like MongoDB), Graph databases (like GraphDB)\nReporting: Power BI, Grfana\nKnowledge of REST, SOAP APIs\nKnowledge of Bigdata platforms is a plus\nKnowledge of Message Queueing platforms is a plus\nKnowledge of GitHub and Jira is a plus\nDevOps experience is a plus\nCloud IoT platforms like Microsoft Azure or Thingsboard are a plus\n\n\n\n\nQualifications:\n\nBachelors degree in Computer Science or Engineering\nAt least 7 years of experience \n\n\n\n\n* While we carefully review all applications, only candidates meeting the specified requirements will be contacted for further consideration. We appreciate your understanding and thank all applicants for their interest.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4267257645": {
    "job_url": "https://www.linkedin.com/jobs/view/4267257645",
    "job_summary": "Software Engineer\nSoftware Engineer with verification\nAmbient.ai\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nApplied",
    "job_details": "About the job\n\nWho We Are\n\nAmbient.ai is a unified, AI-powered physical security platform helping the worlds leading enterprises reduce risk, improve operational efficiency, and gain critical insights. Seven of the top 10 U.S. technology companies, along with multiple Fortune 500 organizations, rely on Ambient.ai to modernize their physical security infrastructure.\n\nOur platform uses advanced AI and computer vision to seamlessly integrate with existing camera and sensor systems, enabling real-time monitoring and proactive threat detection. By reducing false alarms by over 95%, Ambient.ai allows security teams to focus on real threats and prevent incidents before they occur.\n\nFounded in 2017 and backed by Andreessen Horowitz, Y Combinator, and Allegion Ventures, Ambient.ai is a Series B company on a mission to make every security incident preventable.\n\nWeve found that in-person time meaningfully supports collaboration, creativity, and team alignment. Our engineering, product, design, and marketing teams work from our Redwood City office 3 days per week. All other Bay Area employees join on Fridays to stay connected and close out the week together.\n\nReady to learn more? Connect with us on LinkedIn and  YouTube\n\nPosition Overview\n\nAs a Product Backend Engineer, you will design, develop, and optimize backend systems that directly impact user-facing web applications. You will collaborate closely with front-end engineers, product managers, and designers to ensure seamless integration and a stellar user experience. Your expertise in Python and backend technologies will help shape scalable, reliable, and efficient systems that meet business needs and user demands.\n\nKey Responsibilities\n\nDesign, build, and maintain backend APIs, services, and systems to support user-facing features.\nCollaborate with cross-functional teams to gather requirements and translate them into technical specifications.\nEnsure backend systems are scalable, secure, and performant under high-traffic conditions.\nDebug, diagnose, and resolve technical issues across the backend stack.\nWrite clean, maintainable, and well-documented code, adhering to best practices.\nImplement robust monitoring, logging, and alerting solutions to ensure high system reliability.\nContribute to architectural discussions and decisions to drive product innovation.\nParticipate in code reviews, providing constructive feedback to peers and fostering a culture of excellence.\n\nThe Impact Youll Make\n\nYou will play a pivotal role in designing, developing, and optimizing backend systems that drive our AI-first, user-facing product.\nYou will take ownership of a key product area, contributing to groundbreaking 0-1 features and scaling them to meet user and business demands.\nYour work will involve close collaboration with front-end engineers, product managers, and designers, ensuring seamless integration and delivering an exceptional user experience.\nLeveraging your expertise in Python and backend technologies, youll help build scalable, reliable, and efficient systems that power the core of our product.\nYour contributions will directly shape the future of our platform and its impact on our users.\n\nSkills\n\nThe amazing skills you bring to Ambient.ai:\n\n3+ years of experience as a backend engineer working on user-facing web products.\nProficiency in Python and frameworks like Flask, Django, or FastAPI.\nExperience with RESTful APIs, GraphQL APIs, gRPC, and working with real-time communication technologies.\nStrong understanding of databases (SQL and NoSQL) and efficient data modeling.\nFamiliarity with cloud platforms (e.g., AWS, GCP, Azure).\nAbility to troubleshoot, debug, and optimize backend performance.\nExposure to front-end technologies (e.g., React, Angular, or Vue.js) to understand end-to-end workflows.\n\nWhy Join Us\n\nWe are creating an entirely new category within a 120+ billion-dollar physical security industry and looking for team members who are also passionate about our mission to prevent every security incident possible\nWe have an impressive customer roster of F500 companies, including Adobe, VMware, and SentinelOne\nRegular Full-time employees receive stock options for the opportunity to share ownership in the success of our company\nWe offer flexible time off to rest and recharge, including Winter Break (time off between Christmas and New Years for most roles depending on customer demand)\nThe latest tech and awesome swag will be delivered to your door\nEnjoy a full range of opportunities to connect with your awesome co-workers\nWe love to hike, are foodies, and love music! Check out our most recent ambient Spotify Playlist\n\nAmbient.ai is proud to be an Equal Opportunity Employer. Ambient does not unlawfully discriminate on the basis of race, color, religion, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), gender identity, gender expression, national origin, ancestry citizenship, age, physical or mental disability, legally protected medical condition, family care status, military or veteran status, marital status, registered domestic partner status, sexual orientation, genetic information, or any other basis protected by local, state, or federal laws. Ambient is an E-Verify participant.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": true,
    "easy_apply": false
  },
  "https://www.linkedin.com/jobs/view/4270629102": {
    "job_url": "https://www.linkedin.com/jobs/view/4270629102",
    "job_summary": "Software Development Engineer [T500-19290]\nSoftware Development Engineer [T500-19290] with verification\nDelta Air Lines\nBengaluru, Karnataka, India (On-site)\n3 company alumni work here\n3 Walmart Global Tech India company alumni work here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout Delta Tech Hub:\n\nDelta Air Lines (NYSE: DAL) is the U.S. global airline leader in safety, innovation, reliability and customer experience. Powered by our employees around the world, Delta has for a decade led the airline industry in operational excellence while maintaining our reputation for award-winning customer service. With our mission of connecting the people and cultures of the globe, Delta strives to foster understanding across a diverse world and serve as a force for social good. Delta has fast emerged as a customer-oriented, innovation-led, technology-driven business. The Delta Technology Hub will contribute directly to these objectives. It will sustain our long-term aspirations of delivering niche, IP-intensive, high-value, and innovative solutions. It supports various teams and functions across Delta and is an integral part of our transformation agenda, working seamlessly with a global team to create memorable experiences for customers.\n\n\n\n\nResponsibilities include, but are not limited to:\n\nDeveloping, Designing and demonstrating new features and components of back-end to users to ensure compliance with requirements\nAssisting in the design, implementation and optimization of related approaches, tools and workflows.\nCollaborate with the technical teams, business teams, and product managers to ensure that the code that is developed meets their vision.\nDevelop the solutions to meet functional and technical requirements.\nAlign to Security/Compliance frameworks and controls requirements.\nOwn quality posture. Write automated tests, ideally before writing code.\nWrite well designed, non-complex, testable, efficient code.\nDevelop Continuous Integration & Continuous Deployment pipelines and automated deployment scripts.\nConfigure services, such as databases and monitoring.\nImplement Service Reliability Engineering.\nFix problems from the development phase through the production phase, which requires being on call for production support.\n\n\n\n\nWhat you need to succeed (minimum qualifications):\n\n2+ years of hands-on experience on Software Development in Java, Microservices, Rest-Apis, Monitoring, AWS, Relational & NoSql Databases.\nExpert in Functional Programming approaches, mostly in Java 21.\nExperience working with containerization technologies.\nIn-depth working knowledge of Lambda, CloudFormation, IAM etc.\nKnowledge of Authentication and Authorization protocols like oAuth2.0 and OpenID Connect etc.\nExperience in Spring Framework / Spring boot / or similar Java Based framework for microservices development.\nExcellent judgment and problem-solving skills; individuals should be able to resolve problems in a calm and quick manner and display a high degree of initiative and drive.\nProfessional experience working with Agile Methodologies is required.\nExperience working with DevOps principles, practices and tools in an enterprise technology environment is required.\nExperience of engineering software within an Amazon Web Services (AWS) cloud infrastructure or other prominent enterprise cloud provider is required.\nWorking knowledge of the full Software Development Lifecycle, building CI/CD pipelines and practicing Test Driven Development is a requirement.\nExperience with source control, build tools and GIT (GitHub, Bitbucket or other) is required.\nEmbraces diverse people, thinking and styles.\nConsistently makes safety and security, of self and others, the priority.\nHigh School diploma, GED or High School Equivalency.\n\n\n\n\nWhat will give you a competitive edge (preferred qualifications):\n\nBachelors degree in computer science, Information Systems or related technical field is preferred.\nExperience in AWS Cloud Platform is required.\nExperience working in an airline technology environment is an added advantage.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4086218743": {
    "job_url": "https://www.linkedin.com/jobs/view/4086218743",
    "job_summary": "Staff Software Engineer\nStaff Software Engineer with verification\nSpotOn\nBengaluru, Karnataka, India (On-site)\nCompany review time is typically 1 week\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAt SpotOn, were helping restaurants and small businesses compete and win with flexible payment and software technologybacked by real people who really care. From seamless point-of-sale systems to integrated restaurant management solutions, every SpotOn tool is designed to help local businesses increase profits and create better experiences for their customers and employees. \n\n\n\n\nRecently, SpotOn was:\n\n\n\n\n\nNamed one of Fast Companys Most Innovative Companies of 2024\n\n\nAwarded Great Places to Work and Built Ins Best Workplaces for the third year in a row\n\n\nSelected as the Best Overall Restaurant POS by NerdWallet \n\n\nRated the top-rated point-of-sale (POS) for restaurants, bars, retail, and small businesses by Capterra users\n\n\n\n\n\nWere committed to caring hard and moving fast so that we can continue to grow and make a positive impact together. \n\n\n\n\nThats where you come in. \n\n \n\nOur Payments & Acquiring group is focused on building world-class payment processing solutions. We strive to provide seamless and secure payment experiences for our customers. You will work on building and supporting high availability, real-time systems that are the backbone of our payment processing services.\n\n\n\n\nQualifications: \n\n\n\n\nResearch shows that women and members of underrepresented groups tend to apply to roles only when they check every box on a job description. We encourage you to apply if you meet the majority of qualifications and if this role is aligned with your career trajectory.\n\n\n\n\n\nA strong technical background in software engineering and architecture, with experience in modern programming language\n\n\nAbility to work independently with very little direction, taking full ownership of projects.\n\n\nIdentifying blind spots, anticipate challenges, and prioritize work effectively\n\n\nExceptional communication and organizational skills.\n\n\nA Bachelor's degree in Computer Science, Engineering, or equivalent experience.\n\n\n8+ years of relevant experience preferred\n\n\nProficiency using Python, Kafka, Kubernetes, and AWS\n\n\nExperience with Distributed Task Queues such as Celery and RabbitMQ is preferred.\n\n\nExperience with RDBMS/SQL is also preferred.\n\n\n\n\n\nResponsibilities:\n\n\n\n\n\nDesign, develop, and implement high-quality software solutions for payment processing.\n\n\nMaintain a regular release cadence and manage the product backlog.\n\n\nEnsure timely and lossless communication across teams.\n\n\nUphold engineering values and best practices.\n\n\nCollaborate with international teams to ensure successful product development and delivery.\n\n\n\n\n\n \n\n \n\n\nSpotOn is an equal employment opportunity employer. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law.\n\n\n\n\nSpotOn is an e-verify company.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4268174950": {
    "job_url": "https://www.linkedin.com/jobs/view/4268174950",
    "job_summary": "Fullstack Engineer with AI/ML\nFullstack Engineer with AI/ML\nRakuten India\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nWe are seeking a talented and experienced Senior Fullstack Engineer to join our team. In this role, you will be responsible for designing, developing, and maintaining robust and scalable AI-powered web applications with a strong focus on frontend development (60-70%) while maintaining solid backend capabilities. You will work closely with product managers, designers, and other engineers to build next-generation AI experiences including chat interfaces, LLM integrations, and intelligent user interactions. The ideal candidate will have deep JavaScript expertise, strong React ecosystem knowledge, experience with AI/LLM technologies, and a passion for building high-quality, maintainable solutions that effectively integrate cutting-edge AI capabilities.\n\n\n\n\nResponsibilities\n\nAI Application Development: Build AI-powered chat applications, conversational interfaces, and intelligent user experiences\nMulti-Agent Systems: Design and implement complex AI workflows using, for example, LangGraph and multi-agentic architectures\nLLM Observability: Implement monitoring, logging, and performance tracking for AI/LLM integrations\nFrontend Development: Design, develop, and maintain responsive web applications using React, Next.js, and TypeScript with deep JavaScript expertise\nSystem Architecture: Make strategic technical decisions about AI application structure, data flow patterns, and scalability solutions\nPerformance Engineering: Optimize Core Web Vitals, bundle analysis, rendering performance, and AI response times for complex applications\nAPI Integration: Develop and consume RESTful APIs, GraphQL services, and LLM APIs with proper error handling and state management\nTechnical Leadership: Conduct code reviews, mentor junior developers, and establish frontend development standards\nBusiness Translation: Work with stakeholders to translate business requirements into technical solutions and feasibility assessments\nTest Automation: Develop comprehensive automated unit, integration, and end-to-end tests\nProduction Support: Debug complex production issues, memory leaks, race conditions, and cross-browser inconsistencies\nSecurity Implementation: Implement authentication flows, XSS prevention, data privacy and AI safety measures\nBackend Development: Build and maintain Node.js/Express.js APIs, database integrations, and AI service orchestration\n\n\n\n\nRequirements - Experience & Education:\n\nBachelor's degree in Computer Science, Engineering, or related field\n5-8 years of experience in fullstack development with frontend focus\nProven experience building chat applications and conversational interfaces\nExperience integrating with AI/ML APIs and LLM frameworks\nStrong analytical, problem-solving, and technical communication skills\nExcellent collaboration abilities and experience working in cross-functional teams\n\n\n\n\n\n\n\nCore Technical Expertise \n\nFrontend Technologies \n\nAdvanced JavaScript (ES6+, closures, prototypes, async patterns, event loop, browser APIs)\nReact.js with hooks, context, and modern patterns\nNext.js including SSR, SSG, and App Router\nTypeScript with deep understanding of type system\nComponent libraries (Ant Design or Material-UI)\nState management solutions (Redux, React Query)\n\n\n\n\nBackend & Data\n\nNode.js & Express.js for API development\nDatabase technologies (PostgreSQL, MongoDB, or MySQL)\nRESTful APIs and GraphQL services\n\n\n\n\nAI/LLM Integration\n\nOpenAI APIs, LangChain, or similar frameworks\nStreaming AI responses and error handling\nPerformance optimization for AI applications\nMulti-agent system implementation\n\n\n\n\nDevelopment Practices & Tools\n\nModern testing frameworks (Jest, React Testing Library, Cypress)\nPerformance monitoring and debugging tools\nGit version control and collaborative workflows\nCI/CD pipelines and deployment automation\nSystem architecture patterns and scalable application design\nSecurity best practices including authentication flows and XSS prevention\n\n\n\n\nPerformance & Optimization\n\nCore Web Vitals optimization\nBundle analysis and rendering performance\nMemory management and browser-specific optimizations\nCross-browser compatibility and debugging\n\n\n\n\n\n\n\nOther Mandatory Requirements:\n\nExperience in a product company, with a focus on enterprise products that have significant business impact or user base.\nExpertise in Python or JavaScript (Frontend or Backend).\nCandidates must be based in Bangalore\n\n\n\n\n\n\n\nRakuten is committed to cultivating and preserving a culture of inclusion and connectedness. We are able to grow and learn better together with a diverse team and inclusive workforce. The collective sum of the individual differences, life experiences, knowledge, innovation, self-expression, and talent that our employees invest in their work represents not only part of our culture, but our reputation and Rakutens achievement as well. In recruiting for our team, we welcome the unique contributions that you can bring in terms of their education, opinions, culture, ethnicity, race, sex, gender identity and expression, nation of origin, age, languages spoken, veterans status, color, religion, disability, sexual orientation, and beliefs.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4267999904": {
    "job_url": "https://www.linkedin.com/jobs/view/4267999904",
    "job_summary": "Data Engineer\nData Engineer\nRevX\nIndia (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nData Engineer \n\n\n\n\nAbout RevX\n\n\n\n\nRevX helps app businesses acquire and reengage users via programmatic to retain, monetize, and accelerate revenue. We're all about taking your app businesses to a new growth level. We rely on data science, innovative technology, and AI, and a skilled team, to create and deliver seamless ad experiences to delight your app users. Thats why RevX is the ideal partner for app marketers that demand trustworthy insights, a hands-on team, and a commitment to growth. We help you build sound mobile strategies, combining programmatic UA, app re engagement, and performance branding to drive real and verifiable results so you can scale your business: with real users, high retention, and incremental revenue.\n\n\n\n\nAbout the Role\n\n\n\n\nWe are seeking a forward-thinking Data Engineer who can bridge the gap between traditional data pipelines and modern Generative AI (GenAI)-enabled analytics tools. You'll design intelligent internal analytics systems using SQL, automation platforms like n8n, BI tools like Looker, and GenAI interfaces such as ChatGPT, Gemini, or LangChain.\n\nThis is a unique opportunity to innovate at the intersection of data engineering, AI, and product analytics.\n\n\n\n\nKey Responsibilities\n\n\n\n\nDesign, build, and maintain analytics workflows/tools leveraging GenAI platforms (e.g., ChatGPT, Gemini etc.) and automation tools (e.g., n8n, Looker etc.).\nCollaborate with product, marketing, and engineering teams to identify and deliver data-driven insights.\nUse SQL to query data from data warehouses (BigQuery, Redshift, Snowflake, etc.) and transform it for analysis or reporting.\nBuild automated reporting and insight generation systems using visual dashboards and GenAI-based interfaces.\nEvaluate GenAI tools and APIs for applicability in data analytics workflows.\nExplore use cases where GenAI can assist in natural language querying, automated summarization, and explanatory analytics.\nWork closely with business teams to enable self-service analytics via intuitive GenAI-powered interfaces.\nDesign and maintain robust data pipelines to ensure timely and accurate ingestion, transformation, and availability of data across systems.\nImplement best practices in data modeling, testing, and monitoring to ensure data quality and reliability in analytics workflows.\n\n\n\n\nRequirements\n\n\n\n\n3+ years of experience in data analysis or a related field.\nStrong proficiency in SQL with the ability to work across large datasets.\nHands-on experience building data tools/workflows using any of the following: n8n, Looker/LookML, ChatGPT API, Gemini, LangChain, or similar.\nFamiliarity with GenAI concepts, LLMs, prompt engineering, and their practical application in data querying and summarization.\nExcellent problem-solving skills and a mindset to automate and optimize wherever possible.\nStrong communication skills with the ability to translate complex data into actionable insights for non-technical stakeholders.\n\n\n\n\nNice to Have\n\n\n\n\nPrior experience in AdTech (ad operations, performance marketing, attribution, audience insights, etc.).\nExperience with Python, Jupyter Notebooks, or scripting for data manipulation.\nFamiliarity with cloud platforms like Google Cloud Platform (GCP) or AWS.\nKnowledge of data visualization tools like Tableau, Power BI, or Looker etc.\n\n\n\n\nWhy Join Us?\n\n\n\n\nWork on the cutting edge of GenAI and data analytics innovation.\nContribute to building scalable analytics tools that empower entire teams.\nBe part of a fast-moving, experimentation-driven culture where your ideas matter.\n\n\n\n\n\n\n\nFor more information visit www.revx.io",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4268300896": {
    "job_url": "https://www.linkedin.com/jobs/view/4268300896",
    "job_summary": "Python Backend Developer (Immediate joiner)\nPython Backend Developer (Immediate joiner)\nOrigins AI: Helping you build and scale\nIndia (Remote)\nCompany review time is typically 1 week\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout Us\n\nWe are a tech-first company solving real-world problems with clean code, thoughtful design, and fast iterations. Our team is lean, product-driven, and obsessed with delivering value through scalable web applications.\n\n\n\n\nWhat Youll Be Doing\n\nDevelop full-stack web applications using Python (FastAPI) on the backend \nDesign APIs and integrate third-party services\nWork closely with design, product, and other engineers to ship features fast\nOptimize performance, reliability, and scalability of the application\nWrite clean, maintainable, and testable code\n\n\n\n\nMust-Have Skills\n\nStrong experience with Python (FastAPI)\nSolid understanding of REST APIs, databases (PostgreSQL/MySQL), and ORMs\n\n\n\n\nGood to Have\n\nExperience with WebSockets, or async Python\nUnderstanding of DevOps principles and infrastructure-as-code\nFamiliarity with authentication systems (OAuth2, JWT, etc.)\nExposure to testing frameworks like Pytest, Jest",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4269082310": {
    "job_url": "https://www.linkedin.com/jobs/view/4269082310",
    "job_summary": "Staff Engineer, Python(Django)\nStaff Engineer, Python(Django) with verification\nNagarro\nIndia (Remote)\n1 connection works here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nCompany Description\n\nWe're Nagarro.\n\nWe are a Digital Product Engineering company that is scaling in a big way! We build products, services, and experiences that inspire, excite, and delight. We work at scale across all devices and digital mediums, and our people exist everywhere in the world (18000 experts across 38 countries, to be exact). Our work culture is dynamic and non-hierarchical. We are looking for great new colleagues. That is where you come in!\n\nJob Description\n\nREQUIREMENTS:\n\n\nTotal experience 7 +years. \nStrong hands-on experience with Python and proficiency in at least one Python framework such as Django\nStrong experience with Restapi. \nIn-depth understanding of design patterns and distributed architecture. \nProven experience in designing, deploying, implementing, and maintaining software solutions. \nFamiliarity with cloud platforms, such as Azure or AWS, with hands-on experience in cloud-based solutions\nExpertise in infrastructure tools and solutions, including Docker and Kubernetes (K8s). \nUp-to-date knowledge of the latest technology trends and best practices in software development. \nFamiliarity with CI/CD setup and tools to enable efficient deployment processes. \nStrong analytical and problem-solving skills to address complex technical challenges. \nExcellent communication and collaboration abilities to provide technical guidance and work effectively within a team. \n\n\nRESPONSIBILITIES:\n\n\nDesign, deploy, implement, and maintain scalable and efficient software solutions. \nProvide technical guidance and mentorship to the team, ensuring adherence to best practices and high-quality code standards. \nDevelop backend solutions using Python and frameworks like Django\nLeverage cloud platforms such as Azure or AWS to implement cloud-based architectures. \nUtilize infrastructure tools like Docker and Kubernetes to build and maintain robust deployment environments. \nStay informed about the latest technology trends and incorporate them into software development practices. \nSet up and maintain CI/CD pipelines for seamless integration and deployment. \nCollaborate with cross-functional teams to deliver innovative and reliable solutions. \nAnalyze and solve complex technical problems efficiently, ensuring stability and performance of the applications. \n\n\nQualifications\n\nBachelors or masters degree in computer science, Information Technology, or a related field",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4260901336": {
    "job_url": "https://www.linkedin.com/jobs/view/4260901336",
    "job_summary": "Senior Python Developer\nSenior Python Developer\nGyanSys Inc.\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nApplied",
    "job_details": "About the job\n\nRole: Senior Python Developer\n\nLocation: Bangalore (Working from OFFICE) \n\n\n\n\nJob Description: \n\nCore Python Knowledge\n\nPython Framework like FastAPI, Flask\n\nGood Backend Development Experience (Unit testcases, Branching strategy, CI/CD)\n\nDatabase integration with Python services and SQL programming, ORM and Alembic knowledge is good.\n\nCloud Knowledge (AWS or AZURE)\n\nAble to Understanding Business requirements and design the backend system for those features.\n\nMentoring the junior developer in the team.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": true,
    "easy_apply": false
  },
  "https://www.linkedin.com/jobs/view/4266335006": {
    "job_url": "https://www.linkedin.com/jobs/view/4266335006",
    "job_summary": "Software Development Engineer [T500-19160]\nSoftware Development Engineer [T500-19160] with verification\nDelta Air Lines\nBengaluru, Karnataka, India (On-site)\n3 company alumni work here\n3 Walmart Global Tech India company alumni work here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout Delta Tech Hub:\n\nDelta Air Lines (NYSE: DAL) is the U.S. global airline leader in safety, innovation, reliability and customer experience. Powered by our employees around the world, Delta has for a decade led the airline industry in operational excellence while maintaining our reputation for award-winning customer service. With our mission of connecting the people and cultures of the globe, Delta strives to foster understanding across a diverse world and serve as a force for social good. Delta has fast emerged as a customer-oriented, innovation-led, technology-driven business. The Delta Technology Hub will contribute directly to these objectives. It will sustain our long-term aspirations of delivering niche, IP-intensive, high-value, and innovative solutions. It supports various teams and functions across Delta and is an integral part of our transformation agenda, working seamlessly with a global team to create memorable experiences for customers.\n\n\n\n\nKEY RESPONSIBILITIES: \n\nBuild and maintain serverless applications using AWS services such as Lambda, Step Functions, API Gateway, and EventBridge.\nDevelop and manage RESTful and GraphQL APIs to support aviation data services and integrations.\nWrite efficient, reusable, and well-documented Python code for backend services and automation.\nUse AWS CDK to define and deploy infrastructure as code.\nImplement and manage CI/CD pipelines using GitLab for automated testing and deployment.\nEnsure infrastructure is scalable, secure, and cost-optimized.\nSet up and maintain monitoring, logging, and alerting using Amazon CloudWatch.\nTroubleshoot and resolve issues in production and development environments.\nWork closely with cross-functional teams including developers, DevOps, QA, and product managers.\nParticipate in Agile ceremonies and contribute to sprint planning, reviews, and retrospectives.\nStay up to date with the latest AWS services and features.\nProactively explore and recommend new tools, frameworks, and best practices to improve system performance and developer productivity.\nStrong analytical and problem-solving abilities.\nExcellent communication skills, both written and verbal.\nAbility to work effectively in cross-functional teams and Agile environments.\nDemonstrated eagerness to learn and adapt to new technologies and tools.\nHigh level of ownership and accountability in delivering quality solutions.\n\n\n\n\nWHAT YOU NEED TO SUCCEED (MINIMUM QUALIFICATIONS):\n\nBachelors degree in computer science, Information Technology, or a related field is required\n23 years of hands-on experience in cloud engineering with a focus on AWS.\nProficiency in Python for backend development, scripting, and automation.\nExperience with following AWS services Lambda, S3, DynamoDB, Step Functions, API Gateway, EventBridge, SNS, SQS, IAM, CDK\nGood understanding of RESTful and GraphQL API development and integration.\nFamiliarity with GitLab for version control and CI/CD pipeline management.\nExperience with Amazon CloudWatch for monitoring and logging.\nKnowledge of Infrastructure as Code (IaC) principles and tools.\n\n\n\n\nWHAT WILL GIVE YOU A COMPETITIVE EDGE (PREFERRED QUALIFICATIONS):\n\nAWS Certifications is a plus.\nGood understanding of REST / GraphQL API.\nFamiliarity with DevOps practices and integrating security into CI/CD pipelines.\nContributions to open-source projects or active participation in developer communities.\nExperience in aviation, aerospace, or transportation industry.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4187407035": {
    "job_url": "https://www.linkedin.com/jobs/view/4187407035",
    "job_summary": "Software Engineer - Backend\nSoftware Engineer - Backend with verification\nAcceldata\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAcceldata is reimagining the way companies observe their Data! \n\nAcceldata is the pioneer and leader in data observability, revolutionizing how enterprises manage and observe data by offering comprehensive insights into various key aspects of data, data pipelines and data infrastructure across various environments. Our platform empowers data teams to manage products effectively by ensuring data quality, preventing failures, and controlling costs.\n\nAs a Software Engineer\n\nYoull be responsible for building, scaling and maintaining the core features and capabilities of our Data Observability suite. Youll work closely with the frontend and product teams to create a reliable and scalable platform.\n\nA day in the life of Software Engineer\n\n\n Designing, building and improving the capabilities of some of the key features of the product.\n Investigating software-related complaints and making necessary adjustments to ensure optimal software\n\n\nperformance.\n\n\n Diving deep into open-source data engines and work on optimising their performance.\n Designing, building and maintaining low-latency APIs\n Developing services that will be consumed by the frontend and solution engineers\n Regularly attending team meetings to discuss projects, brainstorm ideas, and put forward solutions to any issues.\n\n\nYou are a great fit for this role if you have\n\n\n 2-4 years of experience in JVM (Java, Scala, Kotlin)\n Strong data structure, algorithm design, and problem-solving skills.\n Experience with database systems, RDBMS, Mongo, and Elastic Search.\n Experience in cloud technologies\n Knowledge of distributed systems, experience in enterprise software and SQL.\n\n\nBonus Points for\n\n\n Experience in Spark / Kafka.\n Experience in Big Data Systems or Hadoop components.\n\n\n We care for our team \n\n\nMentorship & Growth\nESOPs\nMedical and Life Insurance\nPaid Maternity & Parental Leave\nCorporate Uber Program\nLearning & Development Support\n\n\n Acceldata for All \n\nWe are a fast-growing company, solving complex data problems at scale. We are driven by strong work ethics, high standards of excellence, and a spirit of collaboration. We promote innovation, commitment, and accountability. Our goal is to cultivate a healthy work environment that fosters a sense of belonging, encourages teamwork, and brings out the best in every individual.\n\n Why Acceldata? \n\nAcceldata is redefining data observability for enterprise data systems. Founded by experts who recognized the need for innovative monitoring and management solutions in a cloud-first, AI-driven environment, our platform empowers data teams to effectively manage data products. We address common challenges such as scaling and performance issues, cost overruns, and data quality problems by providing operational visibility, proactive alerts, and monitoring reliability across the various environments. \n\nDelivered as a SaaS product, Acceldata's solutions have been embraced by global customers, such as HPE, HSBC, Visa, Freddie Mac, Manulife, Workday, Zoominfo, GSK, Oracle, PubMatic, PhonePe (Walmart), Hersheys, Dun & Bradstreet, and many more. Acceldata is a Series-C funded company and its investors include Insight Partners, March Capital, Lightspeed, Sorenson Ventures, Industry Ventures, and Emergent Ventures.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4269528783": {
    "job_url": "https://www.linkedin.com/jobs/view/4269528783",
    "job_summary": "Software Developer, Algorithmic Trading (Low-Latency, C++)\nSoftware Developer, Algorithmic Trading (Low-Latency, C++)\nBestEx Research\nBengaluru, Karnataka, India (On-site)\nViewed\nEasy Apply",
    "job_details": "About the job\n\nAbout BestEx Research\n\nBestEx Research is a financial technology and research firm specializing in building sophisticated execution algorithms and transaction cost modeling tools servicing multiple asset classes. The firm provides high-performance algorithmic execution services to hedge funds, CTAs, asset managers, and banks through a traditional electronic broker and in a broker-neutral Software as a Service (SaaS) model.\n\nIts cloud-based platform, Algo Management System (AMS), is the first end-to-end algorithmic trading solution for equities and futures that delivers an entire ecosystem around execution algorithms, including transaction cost analysis (TCA), an algorithm customization tool called Strategy Studio, a trading dashboard, and pre-trade analytics in a single platform. The platform is currently live for U.S., Europe, and Canadian equities and global futures trading.\n\nBestEx Research is disrupting a $100 billion industry by challenging the status quo of stale, black-box solutions from banks and offering next-generation execution algorithms that combine performance improvement with transparency and customization. BestEx Research uses leading-edge technology to support its low-latency, highly scalable research and trading systems, with its backend in C++, research libraries in C++/Python and R, and web-based technologies for delivering its front-end platforms.\n\nBestEx Research's mission is to become the leader in automation and measurement of execution across asset classes globally and significantly reduce transaction costs for our clients.\n\nVisit bestexresearch.com for more information about our mission, products, research, and services.\n\nWhy Join Us?\n\nBestEx Research's Bangalore office is not an \"offshore center.\" It's a core engineering and research hubworking on the exact same problems and projects as our U.S. team. You'll be part of the global brain trust, solving some of the hardest problems in trading, systems, and data science.\n\nWhat You'll Love:\n\n\n Zero bureaucracy, zero silosengineers directly collaborate with traders, researchers, and the management team\n Direct ownership of subsystems\n Daily opportunity to learn from pioneers in HFT, low-latency systems, and algo trading\n A high-trust environment, where performance speaks louder than hierarchy. \n Competitive compensation in India, including equity and cash bonuses\n Ability to transition between various teams and projects, whether related to trading systems, algorithmic trading or system tooling\n 5-week structured training program:\n Market microstructure and trading mechanics\n Algorithmic execution and strategy design\n Exchange simulators and performance testing\n Market data systems and real-time analytics\n Hands-on exercises using production research data\n Continuous professional development, with refresher courses, advanced sessions, and on-demand training tailored to your growth\n Global exposure: Opportunities to collaborate with, visit, or relocate to our U.S., Singapore, or London offices, based on performance and business needs\n\n\nYour Role: Build What Most Engineers Never Get to Touch\n\nYou'll be part of a lean, focused team building ultra-low-latency trading systems, real-time exchange simulators, execution algorithms, and alpha forecasting models. Our engineers own the stackfrom C++ nanosecond-sensitive infrastructure to Python-based research platforms.\n\nThis role is ideal for someone who thrives at the intersection of research and engineeringcomfortable building systems, testing hypotheses, and working directly with data that moves markets.\n\nWhat You'll Work On\n\nDesigning and developing system architecture:\n\n\n Core trading systems and algorithmic trading frameworks\n High-performance execution algorithms for global markets\n Exchange simulators and tick-level backtesting frameworks\n Market data adaptors and exchange connectivity adaptors\n\n\nBuilding from scratch:\n\n\n Trading systems for new asset classes and execution algorithms\n Performance optimizations for low-latency, high-throughput systems\n\n\nEnhancing existing systems:\n\n\n Add support for new features and improve scalability and reliability\n\n\nCollaborating closely with:\n\n\n A global team of quants, traders, and senior engineers to design cutting-edge solutions\n\n\nAnalyzing and optimizing system performance:\n\n\n Across application, OS, and hardware layers to achieve industry-leading performance\n Work primarily with C++17 in a high-impact, low-bureaucracy environment\n\n\nRequirements\n\nYou Should Have: \n\n\n Bachelor's or Master's from a top-tier CS or Engineering program (IIT/NIT/BITS preferred but not required)\n At least 1+ years software development experience with C++\n Expert-level knowledge of C++ and excellent software design skills\n Expert-level knowledge of TCP/IP and multithreading\n Excellent problem solving and analytical skills\n Excellent communication skills and ability to articulate ideas\n An attitude of constant curiosity and growth, as well as the ability and desire to mentor others\n While domain experience is a plus, we welcome strong engineers from other industries\n\n\nBonus Points For \n\n\n Database optimization and experience with research or market data pipelines\n Prior work on trading platforms, FIX engines, or exchange protocols\n Contributions to open-source C++/Python performance tools, ability to work with large datasets\n Prior experience developing trading systems or execution algorithms\n Knowledge of relational databases, database optimizations, and SQL\n Experience with Python/R",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4264834358": {
    "job_url": "https://www.linkedin.com/jobs/view/4264834358",
    "job_summary": "Backend Engineer [T500-18265]\nBackend Engineer [T500-18265] with verification\nANSR\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nANSR is hiring for one of its clients.\n\nAbout 4flow:\n\nHeadquartered in Berlin, Germany, 4flow provides consulting, software and services for logistics and supply chain management. More than 1300 team members leverage their supply chain expertise and IT know-how to best serve their customers at 20+ locations around the world.\n\n4flow develops and implements lean, agile and sustainable supply chain strategies that enhance operational efficiency and drive cost savings for businesses worldwide. Their clients span across multiple high-impact industries including vehicle manufacturers and suppliers, consumer goods and retail, industrial machinery manufacturers, medical technology, basic materials, spare parts, renewable energy, high-tech and telecommunications, and logistics service providers (LSP).\n\n\n\n\nAs a BackEnd Engineer, you will contribute to the development of robust and scalable backend services. Youll work with modern technologies and collaborate with cross-functional teams to deliver high-quality software solutions.\n\n \n\nTasks:\n\nDesign and develop backend components using Java and Spring Boot \nImplement and maintain RESTful APIs following best practices in API design \nParticipate in the full software development lifecycle, including testing and deployment \nCollaborate with frontend, DevOps, and QA teams to ensure seamless integration \nWrite clean, maintainable, and efficient code \nContribute to code reviews and continuous improvement initiatives \n\n\n\n\nProfessional Requirements and Expertise:\n\n2+ years of experience in backend development \nBachelors degree in computer science, Software Engineering, or a related field. \nProficiency in Java, Spring Boot, and API design \n\nGood to have: Experience with Docker, AWS, SQL/NoSQL, DDD (Domain-Driven Design), CI/CD, AI/ML integration, Python, and microservices \n\n\n\n\nPersonal Skills:\n\nEager to learn and grow in backend development \nStrong problem-solving and communication skills \nCollaborative and quality-focused mindset \nAbility to work independently and collaboratively within cross-functional teams \nGenuine motivation to contribute to 4flows success and alignment with company culture and values",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4267254677": {
    "job_url": "https://www.linkedin.com/jobs/view/4267254677",
    "job_summary": "Backend and Data Pipeline Engineer\nBackend and Data Pipeline Engineer with verification\nJRD Systems\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob Role: Backend and Data Pipeline Engineer - Python\n\nLocation: Hyderabad/Bangalore(Hybrid)\n\nJob Type : Fulltime\n\n** Only Immediate Joiners **\n\n\n\n\nJob Summary:\n\nThe Team:\n\nWere investing in technology to develop new products that help our customers drive their growth and transformation agenda. These include new data integration, advanced analytics, and modern applications that address new customer needs and are highly visible and strategic within the organization. Do you love building products on platforms at scale while leveraging cutting edge technology? Do you want to deliver innovative solutions to complex problems? If so, be part of our mighty team of engineers and play a key role in driving our business strategies.\n\n\n\n\nThe Impact:\n\nWe stand at cross-roads of innovation through Data Products to bring a competitive advantage to our business through the delivery of automotive forecasting solutions. Your work will contribute to the growth and success of our organization and provide valuable insights to our clients.\n\n\n\n\nWhats in it for you:\n\nWe are looking for an innovative and mission-driven software\\data engineer to make a significant impact by designing and developing AWS cloud native solutions that enables analysts to forecast long and short-term trends in the automotive industry. This role requires cutting edge data and cloud native technical expertise as well as the ability to work independently in a fast-paced, collaborative, and dynamic work environment.\n\n\n\n\nResponsibilities:\n\nDesign, develop, and maintain scalable data pipelines including complex algorithms\nBuild and maintain UI backend services using Python or C# or similar, ensuring responsiveness and high performance\nEnsure data quality and integrity through robust validation processes\nStrong understanding of data integration and data modeling concepts\nLead data integration projects and mentor junior engineers\nCollaborate with cross-functional teams to gather data requirements\nCollaborate with data scientists and analysts to optimize data flow and storage for advanced analytics\nTake ownership of the modules you work on, deliver on time and with quality, ensure software development best practices\nUtilize Redis for caching and data storage solutions to enhance application performance.\n\n\n\n\nWhat Were Looking For:\n\nBachelors degree in computer science, or a related field\nStrong analytical and problem-solving skills\n7+ years of experience in Data Engineering/Advanced Analytics\nProficiency in Python and experience with Flask for backend development.\nStrong knowledge of object-oriented programming.\nAWS Proficiency is a big plus: ECR, Containers",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4077197626": {
    "job_url": "https://www.linkedin.com/jobs/view/4077197626",
    "job_summary": "Data Engineer-II\nData Engineer-II\nTMRW House of Brands\nBengaluru, Karnataka, India (On-site)\n4 school alumni work here\n4 Indian Institute of Technology (Banaras Hindu University), Varanasi school alumni work here\nApplied",
    "job_details": "About the job\n\nResponsibilities\n\nCreate, implement and operate the strategy for robust and scalable data pipelines for business intelligence and machine learning.\nDevelop and maintain core data framework and key infrastructures\nCreate and support the ETL pipeline to get the data flowing correctly from the existing and new sources to our data warehouse.\nData Warehouse design and data modeling for efficient and cost-effective reporting\nCollaborate with data analysts, data scientists, and other data consumers within the business to manage the data warehouse table structure and optimize it for reporting.\nConstantly striving to improve software development process and team productivity\nDefine and implement Data Governance processes related to data discovery, lineage, access control and quality assurance\nPerform code reviews and QA data imported by various processes\nQualifications\n3-5 years of experience.\nAt least 2+ years of experience in data engineering and data infrastructure space on any of the big data technologies: Hive, Spark, Pyspark(Batch and Streaming), Airflow, Redshift and Delta Lake.\nExperience in product-based companies or startups.\nStrong understanding of data warehousing concepts and the data ecosystem.\nStrong Design/Architecture experience architecting, developing, and maintaining solutions in AWS.\nExperience building data pipelines and managing the pipelines after theyre deployed.\nExperience with building data pipelines from business applications using APIs.\nPrevious experience in Databricks is a big plus.\nUnderstanding of Dev Ops would be preferable though not a must\nWorking knowledge of BI Tools like Metabase, and Power BI is a plus\nExperience of architecting systems for data access is a major plus.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": true,
    "easy_apply": false
  },
  "https://www.linkedin.com/jobs/view/4266620244": {
    "job_url": "https://www.linkedin.com/jobs/view/4266620244",
    "job_summary": "Fullstack- Backend Engineer | Abu Dhabi | On-Site | Ai Startup\nFullstack- Backend Engineer | Abu Dhabi | On-Site | Ai Startup\nMetaMorph\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nFull Stack- Backend Engineer| Abu Dhabi | On-Site | Ai Startup \n\n\n\n\nA fast-scaling AI infrastructure startup backed by strong revenue, developer traction, and global growth is expanding into Abu Dhabi. They're building next-generation agent and require a dynamic Backend Engineer to lead engineering efforts in the region from Day One.\n\n\n\n\nWhat Youll Do:\n\nBuild scalable APIs and services for agent-based applications\nDevelop RAG pipelines using LangChain,or custom tools\nWork with distributed systems and databases\n(Optional) Contribute to UI development with React\nOwn features end-to-end and collaborate with global teams\n\n\n\n\nWhat Were Looking For:\n\nStrong Python skills (or similar backend language)\nExperience Range: 6-8 years\nExperience with distributed systems, APIs, and databases\nFamiliarity with LLMs, RAG, and agent frameworks\nBonus: Frontend experience with React\nIndependent, ownership-driven mindset\n\n\n\n\nTech Environment:\n\nBackend: Python, FastAPI\nInfra: AWS, Docker, Kubernetes\nAI Stack: LangChain, Pinecone/Weaviate, OpenAI, Anthropic\nDevOps: GitHub Actions, CI/CD pipelines\nFocus: Developer tools, AI agents, real-time search APIs\n\n\n\n\nWhy This Role?\n\nWork with a well-funded startup delivering real-world impactwith $3M+ ARR, 200K+ users, and 5M+ downloads\nBuild solutions across AI, search, and distributed infrastructure\nLead from the trenches and shape development strategy in a global team\nBe based in Abu Dhabi, part of a thriving tech and innovation ecosystem",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4269003865": {
    "job_url": "https://www.linkedin.com/jobs/view/4269003865",
    "job_summary": "Python Developer - Telecom Domain\nPython Developer - Telecom Domain\nSynez Technologies\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nWere Hiring: Python Developer  OSS/Telco Backend Focus\n\nLocation: Bangalore | Hybrid (3 days/week from client site)\n\nExperience: 6+ years\n\nDomain: Telecom / OSS Systems\n\n\n\n\nImmediate Joiner Only\n\n\n\n\nAre you a Python backend developer with a passion for scalable solutions and experience in the telecom domain? Were building a top-tier engineering team for a leading global telecom project, and this role offers exposure to complex OSS systems and real-time data environments.\n\n\n\n\nMust-Have Skills:\n\n\n\n\nStrong backend development in Python.\nExperience in OSS/BSS systems within telecom\nWorking knowledge of API integrations and data orchestration\nExperience with CI/CD, Git, and containerized environments (Docker/Kubernetes)\n\n\n\n\nWhy Join Us?\n\n\n\n\nCollaborate with a global team on high-impact telecom projects\nWork in a hybrid model that promotes flexibility and structure\nSharpen your backend development skills while learning from domain experts\n\n\n\n\n\n",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4259818999": {
    "job_url": "https://www.linkedin.com/jobs/view/4259818999",
    "job_summary": "Python Full Stack Developer\nPython Full Stack Developer\nZettaMine Labs Pvt. Ltd.\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nEasy Apply",
    "job_details": "About the job\n\nJob Title: Full Stack Developer / Full Stack Engineer (Python, React or MS Forms)\n\nLocation: Bangalore\n\nAvailability: Immediate Joiners Preferred\n\nExperience Level: 5 to 8 Years\n\nEmployment Type: Full-time\n\n\n\n\nJob Description\n\nWe are actively seeking strong and motivated Full Stack Developers to join our team immediately. The ideal candidates will have solid experience in Python development and proficiency in front-end technologies, with flexibility based on skill and interest.\n\nDepending on their strengths, candidates will be considered for one of the following roles:\n\n\n\n\n1. Full Stack Developer (Python, React, AWS)\n\nKey Responsibilities:\n\nDesign and develop scalable web applications using Python and React.\nIntegrate and deploy applications on AWS.\nCollaborate with cross-functional teams to define, design, and ship new features.\nOptimize applications for performance and scalability.\nWrite clean, maintainable, and efficient code.\n\nRequirements:\n\nStrong proficiency in Python.\nHands-on experience with React.js for front-end development.\nExperience working with AWS cloud services.\nFamiliarity with RESTful APIs and microservices architecture.\nGood problem-solving skills and ability to work independently.\n\n\n\n\n2. Full Stack Engineer (Python, MS Forms Automation)(who are open to learn MS forms also can apply)\n\nKey Responsibilities:\n\nDevelop backend logic and services using Python.\nAutomate business workflows using Microsoft Forms and related Microsoft 365 tools.\nCollaborate with teams to understand requirements and implement efficient automation solutions.\nEnsure code quality and best practices in automation scripts.\n\nRequirements:\n\nStrong Python development experience.\nWillingness to learn and work with Microsoft Forms Automation.\nFamiliarity with Office 365 ecosystem is a plus.\nStrong communication and collaboration skills.\n\nPreferred Qualifications:\n\nExperience with CI/CD, Git, and Agile methodologies.\nUnderstanding of databases (SQL/NoSQL).\nAbility to learn and adapt to new technologies quickly.\n\n\n\n\nHow to Apply:\n\n\n\n\n Send your updated resume to: swetha.p@zettamine.com",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4259281258": {
    "job_url": "https://www.linkedin.com/jobs/view/4259281258",
    "job_summary": "Python Developer\nPython Developer\nAppsForBharat\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nRole: Senior Software Developer (Python)\n\n\n\n\nFunction: Technology\n\nLocation: HSR Layout, Bangalore\n\nRole Type: Full-time\n\nReporting: VP Engineering\n\n\n\n\nAbout AppsForBharat (Sri Mandir App)\n\n\n\n\nAppsForBharat, a series B-funded faith-tech startup, is backed by Indias best venture capital investors including Fundamentum, Susquehanna Asia VC, Peak XV partners (prev. Sequoia Capital), Elevation Capital, & BEENEXT. Our highly ambitious and audacious team comprises alumni from prestigious institutions like IITs & IIMs, with extensive experience in scaling high-growth startups. We're dedicated to developing mobile and web apps catering to the devotional and spiritual needs of 100s of millions of users across the globe.\n\nOur flagship product, Sri Mandir, launched in November 2020, is the worlds largest app for Hindu devotees. It serves as a digital sanctuary for millions of devotees worldwide. Our mission is to enrich individuals' spiritual lives through innovative technology, offering seamless access to sacred pilgrims & rituals, divine teachings, and a vibrant community. The overwhelming user love motivates us as we aim to serve 100s of millions more in the coming years.\n\nThe devotion market is a $44B opportunity in India (growing at 10% CAGR), which is primarily offline and unorganised. Of the $44B, the temples drive GMV of ~$27B in temple offerings, services, and commerce. There are 2M+ temples in India - about 10k of these temples have a strong historical and cultural significance. Tourism to these religious places is a $10B opportunity. The Sri Mandir app is the worlds largest app for Hindu devotees and growing 20-25% month-on-month.\n\n\n\n\nLearn more about AppsForBharat: Business World Article, Indian Silicon Valley Podcast, YourStory Article\n\nTry the Sri Mandir app: Android / iOS Backed by the best Indian Venture Capital Investors\n\n\n\n\nRole Overview:\n\n\n\n\nWe are looking for a senior software developer (Python) with a strong background in backend technologies to join our high-performing engineering team. You will play a key role in designing, building, and maintaining mission-critical services that scale to millions of users.\n\n\n\n\nKey Responsibility:\n\nDevelop and maintain robust, scalable backend systems using Python, Golang.\nDesign efficient data models and queries for PostgreSQL and MongoDB.\nBuild secure and performant APIs for mobile and web applications.\nDrive cloud-native development and infrastructure setup on AWS.\nCollaborate with cross-functional teams, including product, mobile, and DevOps.\nOptimize systems for performance, reliability, and scalability.\nConduct code reviews, write unit tests, and improve development processes.\nTroubleshoot, debug, and resolve production-level issues.\n\nRequirements:\n\nBackend development experience with Python, or Golang.\nStrong command over relational (PostgreSQL) and document (MongoDB) databases.\nPractical experience deploying applications on AWS (EC2, ECS, Lambda, RDS, S3).\nProficiency in designing RESTful APIs and working in service-oriented architectures.\nFamiliarity with Docker, Git, CI/CD tools, and cloud monitoring practices.\nAbility to write clean, testable, and maintainable code.\nStrong analytical and debugging skills with a performance-first mindset.\n\n\n\n\nAdditional Perks:\n\nOur oce is located in the green and leafy streets of HSR Layout, Bangalore, and is designed to feel like a mindfulness zone with the sound of falling water, greenery, great books to read, great coffee/tea, and a great team alongside you to build with.\nAs a company, we believe in autonomous small teams for maximum impact. We strive for organisational growth to align with your growth as an individual. We sincerely work towards building an inclusive culture where we celebrate your individuality and ideas are encouraged by everyone. We seek people who naturally demonstrate our values, who understand India, the challenge ahead of us, but can also solve this for the rest of the world. In addition, we also have:\nA competitive salary.\nEquity in a high growth & great potential company.\nPeaceful & pet-friendly oce at the heart of HSR Layout.\nMedical cover for you and your loved ones.\n\n\n\n\nIf you're passionate about backend systems, cloud architecture, and scaling solutions for millions, come build the future of spiritual tech with us.\n\nApply now and be part of the Sri Mandir revolution",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4256727801": {
    "job_url": "https://www.linkedin.com/jobs/view/4256727801",
    "job_summary": "AI/ML Engineer\nAI/ML Engineer\nSustainability Economics.ai\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nLocation: Bengaluru, Karnataka\n\n\n\n\nAbout the Company:\n\nSustainability Economics is a global organisation targeting the markets of US, Japan, EU, UK, Canada and Singapore. As a pioneer, our focus is on the Lifecycle Management of E2E Net-Zero transitions while leveraging our automation-first approach. We offer our collaborative services at an international level and counsel our clients on transition solutions and decarbonisation strategies. With our team of professionals who have extensive domain and technical knowledge, we are committed to making long-term efforts to fulfil this vision through our technical innovation, client services, expertise, and capability expansion.\n\n\n\n\nRole Summary:\n\nWe are seeking a highly skilled Generative AI and Machine Learning Engineer to join our innovative team. This role blends the frontier of generative AI with robust machine learning and deep learning engineering. You will be responsible for designing, developing, optimizing, and deploying cutting-edge AI systems that power intelligent, scalable, and agent-driven workflows.\n\n\n\n\nKey Tasks and Accountability:\n\nStrong Foundations on the conceptual & implementation aspects of machine & deep learning models.\nExperience on using the LLMs, Hugging Face, LangChain, API Design, RAG, Vector Databases, OpenAI APIs, Gemini APIs.\nExperience in using optimization algorithms for ML and FastAPI\nKeep abreast of the latest advancements in NLP and ML and other deep Learning Models to ensure our solutions remain at the forefront of technology.\nExperience with time series models (ARIMA, SARIMA, LSTM, Transformer models, etc.)\nProficiency in machine learning techniques such as Random Forest, XGBoost\nProgramming Language Experience in Python.\nWork closely with domain experts to understand the latest research findings and incorporate them into models.\nCollaborate with software developers to create user-friendly interfaces and tools that can be used to visualize and analyze as per the business requirements.\n\n\n\n\nEducational & Experience:\n\nBachelor's or master's degree in a relevant field, such as engineering, statistics, or Mathematics.\n2-3 years of related experience in ML and LLM.\nStrong background in AI/ML, with experience developing and implementing models in Python or similar languages\nExperience working with large text based datasets and data processing tools\nExcellent communication skills, with the ability to explain complex technical concepts to non-technical audiences\nStrong problem-solving skills, with the ability to work independently and as part of a team\nPassion for environmental sustainability and the ability to work in a fast-paced, dynamic environment\n\n\n\n\nSkills:\n\nProficient in Large Language Models (LLMs), CrewAI, and other advanced AI models.\nStrong expertise in Python, with a solid understanding of object-oriented programming (OOP) principles.\nExperience designing scalable system architectures and developing RESTful APIs.\nFamiliar with web frameworks such as Flask and Django.\nProven ability to build and scale AI/ML products from the ground up.\nBackground in data analysis, machine learning, deep learning, and natural language processing (NLP).\n\n\n\n\nPersonal Attributes:\n\nA team player with good interpersonal skills and problem-solving abilities.\nA self-motivator and a collaborative team player.\nShows strong leadership by guiding and motivating the team\nExcellent time management skills and the ability to assume leadership roles when necessary.\nAgile, action oriented and a quick learner.\nOut of box thinker.\n\n\n\n\nBenefits at Sustainability Economics:\n\nA flat hierarchy.\nESOPs.\nGroup Medical Coverage.\n30 days of Leave.\nA gender-neutral parental, marriage, and compassionate leave policy.\n\n\n\n\nAnd above all, if you have a passion to work, join us in our pursuit for sustainability",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4266742504": {
    "job_url": "https://www.linkedin.com/jobs/view/4266742504",
    "job_summary": "Data Engineer I\nData Engineer I\n7-Eleven Global Solution Center \u2013 India\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nWhy Join 7-Eleven Global Solution Center?\n\n\n\n\nWhen you join us, you'll embrace ownership as teams within specific product areas take responsibility for end-to-end solution delivery, supporting local teams and integrating new digital assets. Challenge yourself by contributing to products deployed across our extensive network of convenience stores, processing over a billion transactions annually. Build solutions for scale, addressing the diverse needs of our 84,000+ stores in 19 countries. Experience growth through cross-functional learning, encouraged and applauded at 7-Eleven GSC. With our size, stability, and resources, you can navigate a rewarding career. Embody leadership and service as 7-Eleven GSC remains dedicated to meeting the needs of customers and communities.\n\n\n\n\nWhy We Exist, Our Purpose and Our Transformation?\n\n\n\n\n7-Eleven is dedicated to being a customer-centric, digitally empowered organization that seamlessly integrates our physical stores with digital offerings. Our goal is to redefine convenience by consistently providing top-notch customer experiences and solutions in a rapidly evolving consumer landscape. Anticipating customer preferences, we create and implement platforms that empower customers to shop, pay, and access products and services according to their preferences. To achieve success, we are driving a cultural shift anchored in leadership principles, supported by the realignment of organizational resources and processes.\n\n\n\n\nAt 7-Eleven we are guided by our Leadership Principles. Each principle has a defined set of behaviours which help guide the 7-Eleven GSC team to Serve Customers and Support Stores.\n\n\n\n\nBe Customer Obsessed\nBe Courageous with Your Point of View\nChallenge the Status Quo\nAct Like an Entrepreneur\nHave an It Can Be Done Attitude\nDo the Right Thing\nBe Accountable\n\n\n\n\nResponsibilities:\n\n\n\n\n3-5 years of combined experience in Azure Data Engineering projects\nProficient with Spark topics: pyspark, Databricks, Synapse Notebooks\nProficient with Azure Data services (like Azure Synapse, Azure Data Factory, Azure security model, Azure Data Lake, )\nStrong SQL DW knowledge.\nMust have 1+ years of development experience with spark framework.\nExposure to streaming technologies and messaging bus like Kafka/rabbit MQ.\nProficient with creating pipelines and activities using both Azure and On-Prem data stores for full and incremental data loads into a Cloud DW\nProficient in data topics: management, processing, cleaning, transforming, aggregating, security, and modeling using AAS/PBI\nWorking knowledge of creating Power BI reports and dashboards\nMust have strong programming skills in altleast one programming language like Python/Java.\nStrong sql and data analysis skills.\nExperience working within a distributed team, following an Agile methodology with a DevOps approach using GIT or TFS\nBachelor in computer science or related, Master degree considered as a plus\n\n\n\n\n7-Eleven Global Solution Center is an Equal Opportunity Employer committed to diversity in the workplace. Our strategy focuses on three core pillars  workplace culture, diverse talent and how we show up in the communities we serve. As the recognized leader in convenience, the 7-Eleven family of brands embraces diversity, equity and inclusion (DE+I). Its not only the right thing to do for customers, Franchisees and employeesits a business imperative.\n\n\n\n\nPrivileges & Perquisites:\n\n\n\n\n7-Eleven Global Solution Center offers a comprehensive benefits plan tailored to meet the needs and improve the overall experience of our employees, aiding in the management of both their professional and personal aspects.\n\n\n\n\nWork-Life Balance: Encouraging employees to unwind, recharge, and find balance, we offer flexible and hybrid work schedules along with diverse leave options. Supplementary allowances and compensatory days off are provided for specific work demands.\n\n\n\n\nWell-Being & Family Protection: Comprehensive medical coverage for spouses, children, and parents/in-laws, with voluntary top-up plans, OPD coverage, day care services, and access to health coaches. Additionally, an Employee Assistance Program with free, unbiased and confidential expert consultations for personal and professional issues.\n\nTop of Form\n\n\n\n\nWheels and Meals: Free transportation and cafeteria facilities with diverse menu options including breakfast, lunch, snacks, and beverages, customizable and health-conscious choices.\n\n\n\n\nCertification & Training Program: Sponsored training for specialized certifications. Investment in employee development through labs and learning platforms.\n\n\n\n\nHassel free Relocation: Support and reimbursement for newly hired employees relocating to Bangalore, India.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4268344636": {
    "job_url": "https://www.linkedin.com/jobs/view/4268344636",
    "job_summary": "Software Engineer\nSoftware Engineer with verification\nSynechron\nBengaluru, Karnataka, India (Hybrid)\nCompany review time is typically 1 week\nViewed\nEasy Apply",
    "job_details": "About the job\n\nGood-day,\n\nWe have immediate opportunity for Typescript Developer.\n\nJob Role: Typescript Developer.\n\nJob Location: Synechron ( Bengaluru)\n\nExperience- 7 to 12 years\n\nNotice : upto 15 Days .\n\nAbout Company:\n\nAt Synechron, we believe in the power of digital to transform businesses for the better. Our global consulting firm combines creativity and innovative technology to deliver industry-leading digital solutions. Synechrons progressive technologies and optimization strategies span end-to-end Artificial Intelligence, Consulting, Digital, Cloud & DevOps, Data, and Software Engineering, servicing an array of noteworthy financial services and technology firms. Through research and development initiatives in our FinLabs we develop solutions for modernization, from Artificial Intelligence and Blockchain to Data Science models, Digital Underwriting, mobile-first applications and more. Over the last 20+ years, our company has been honoured with multiple employer awards, recognizing our commitment to our talented teams. With top clients to boast about, Synechron has a global workforce of 13,950+, and has 52 offices in 20 countries within key global markets. For more information on the company, please visit our website or LinkedIn community.\n\n\n\n\nDiversity, Equity, and Inclusion\n\nDiversity & Inclusion are fundamental to our culture, and Synechron is proud to be an equal opportunity workplace and an affirmative-action employer. Our Diversity, Equity, and Inclusion (DEI) initiative Same Difference is committed to fostering an inclusive culture  promoting equality, diversity and an environment that is respectful to all. We strongly believe that a diverse workforce helps build stronger, successful businesses as a global company. We encourage applicants from across diverse backgrounds, race, ethnicities, religion, age, marital status, gender, sexual orientations, or disabilities to apply. We empower our global workforce by offering flexible workplace arrangements, mentoring, internal mobility, learning and development programs, and more.\n\nAll employment decisions at Synechron are based on business needs, job requirements and individual qualifications, without regard to the applicants gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law.\n\n\n\n\nExp - 6 to 9 \n\n\n\n\n\n\n\nRequired Skills & Qualifications:\n\nHaving experience of 6-9 years in development\nStrong hands-on experience with Node.js and TypeScript.\nDeep understanding of serverless architecture and AWS Lambda.\nExperience with API Gateway, DynamoDB, S3, CloudWatch, and IAM.\nFamiliarity with CI/CD pipelines, infrastructure as code (e.g., AWS SAM, Serverless Framework, or Terraform).\nSolid understanding of asynchronous programming, event-driven systems, and microservices.\nExperience with unit testing, integration testing, and monitoring tools.\nStrong problem-solving skills and a proactive, ownership-driven mindset.\n\n\n\n\nKey Responsibilities:\n\nDesign and develop RESTful and event-driven APIs using Node.js and TypeScript.\nBuild and deploy serverless applications using AWS Lambda, API Gateway, DynamoDB, SQS, SNS, and other AWS services.\nCollaborate with frontend developers, DevOps, and product teams to deliver high-quality solutions.\nWrite clean, maintainable, and well-tested code following best practices.\nOptimize performance and scalability of backend services.\nParticipate in code reviews, architecture discussions, and technical planning.\nMonitor, troubleshoot, and improve backend systems in production environments.\nMentor junior developers and contribute to team knowledge sharing.\n\nTo expedite the application process, I would appreciate it if you could provide the following information at your earliest convenience:\n\nTentative Date to Join (if selected):\nCurrent Location:\nPreferred Location:\nCurrent Salary:\nExpected Salary:\nReason for Change:\nTotal Experience:\nRelevant Experience:\nShare official email confirmation of Notice Period or Last Working Day :\nPrimary Skills (Hands-on):\nSecondary Skills:\n\nPlease send your updated resume to my email at amol.upade@synechron.com or reach out to me via WhatsApp at 9322922764.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4189703014": {
    "job_url": "https://www.linkedin.com/jobs/view/4189703014",
    "job_summary": "Software Engineer -Data Engineer (Geo)\nSoftware Engineer -Data Engineer (Geo) with verification\nGroundTruth\nIndia (Remote)\nViewed\nEasy Apply",
    "job_details": "About the job\n\n\n\nGroundTruth is an advertising platform that turns real-world behavior into marketing that drives in-store visits and other real business results. We use observed real-world consumer behavior, including location and purchase data, to create targeted advertising campaigns across all screens, measure how consumers respond, and uncover unique insights to help optimize ongoing and future marketing efforts.\n\nWith this focus on media, measurement, and insights, we provide marketers with tools to deliver media campaigns that drive measurable impact, such as in-store visits, sales, and more.\n\nLearn more at groundtruth.com.\n\nWe believe that innovative technology starts with the best talent and have been ranked one of Ad Ages Best Places to Work in 2021, 2022, 2023 & 2025! Learn more about the perks of joining our team here.\n\nRole: Software Engineer- geo\n\nLocation: Remote, India\n\nA Bit About You\n\nGroundTruth seeks a Software Engineer to join our Geo team. The Geo Team is responsible for ingesting Geo data. The Geo Team builds and develops APIs, manage POI data and provide processed data to integrate with our Ads Manager, Location Manager and Blueprint Manager platform which feed into how GroundTruths advertising creates Real Business Results.We take pride in building an Engineering Team composed of strong communicators who collaborate with multiple business and engineering stakeholders to find compromises and solutions. Our engineers are organized and detail-oriented team players who are problem solvers with a maker mindset. As a Software Engineer (SE) on our Geo Team, you will build solutions that add new capabilities to our platform.\n\nYou Will\n\n\nCreate and maintain various ingestion pipelines for the GroundTruth platform.\nBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, GIS and AWS big data technologies.\nWork with stakeholders including the Product, Analytics and Client Services teams to assist with data-related technical issues and support their data infrastructure needs.\nPrepare detailed specifications and low-level design.\nParticipate in code reviews.\nTest the product in controlled, real situations before going live.\nMaintain the application once it is live.\nContribute ideas to improve the location platform.\n\n\nYou Have\n\n\nTech./B.E./M.Tech./MCA or equivalent in computer science\n3-4 years of experience in Software Engineering\nExperience with GIS, POI/Location data ingestion pipeline.\nExperience with AWS Stack used for Data engineering EC2, S3, EMR, ECS, Lambda, and Step functions\nHands on experience with Python/Java for orchestration of data pipelines\nExperience in writing analytical queries using SQL\nExperience in Airflow\nExperience in Docker\nProficient in Git\n\n\nHow You Can Impress Us\n\n\nKnowledge of Rest APIs and front end\nAny experience with big data technologies like Hadoop, Map Reduce, Pig is a plus\nKnowledge of shell scripting\nExperience with BI tools like Looker and Tableau\nExperience with DB maintenance\nExperience with Amazon Web Services and Dockers\nConfiguration management and QA practices\n\n\nWhat We Offer\n\nAt GroundTruth, we want our employees to be comfortable with their benefits so they can focus on doing the work they love.\n\n\nParental leave- Maternity and Paternity\nFlexible Time Offs (Earned Leaves,Sick Leaves,Birthday leave,Bereavement leave & Company Holidays) \nIn Office Daily Catered Breakfast,Lunch, Snacks and Beverages\nHealth cover for any hospitalization.Covers both nuclear family and parents\nTele-med for free doctor consultation,discounts on health checkups and medicines\nWellness/Gym Reimbursement\nPet Expense Reimbursement\nChildcare Expenses and reimbursements\nEmployee referral program\nEducation reimbursement program\nSkill development program\nCell phone reimbursement (Mobile Subsidy program).\nInternet reimbursement/Postpaid cell phone bill/or both.\nBirthday treat reimbursement\nEmployee Provident Fund Scheme offering different tax saving options such as Voluntary Provident Fund and employee and employer contribution up to 12% Basic\nCreche reimbursement\nCo-working space reimbursement\nNational Pension System employer match\nMeal card for tax benefit\nSpecial benefits on salary account\n\n\nWe are an equal opportunity employer and value diversity, inclusion and equity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\n\nTo ensure your application is properly reviewed, we kindly ask that you submit your resume and optional cover letter through the designated application portal. Applications submitted via the \"Contact Us\" form on our website will not be considered.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4269861081": {
    "job_url": "https://www.linkedin.com/jobs/view/4269861081",
    "job_summary": "Senior Backend Engineer\nSenior Backend Engineer with verification\nWeekday (YC W21)\nBengaluru, Karnataka, India (On-site)\n\u20b9300K/yr - \u20b91M/yr\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nThis role is for one of our clients\n\nIndustry: Technology, Information and Media\n\nSeniority level: Mid-Senior level\n\nMin Experience: 4 years\n\nLocation: Gurgaon, Bengaluru\n\nJobType: full-time\n\nWe are in search of a Senior Backend Engineer who thrives in architecting robust, scalable systems and takes pride in writing clean, high-performance code. If you're passionate about solving real-world problems using technology, working on product-first platforms, and contributing meaningfully to business outcomes  we want to hear from you.\n\nWhat You'll Be Doing\nOwn the Backend: Design, build, and maintain backend services and APIs that are secure, scalable, and high-performing.\n\nArchitect with Purpose: Break down complex business problems into simple, extensible technical solutions using modern design principles and architecture patterns.\n\nCollaborate Across Teams: Work closely with Product Managers, Designers, and Frontend Engineers to shape feature development and ensure seamless integration.\n\nChampion Quality: Lead code reviews, enforce testing standards, and ensure continuous improvement in code quality and system performance.\n\nDrive Innovation: Stay updated with emerging technologies and evaluate them for inclusion in the stack, where appropriate.\n\nWhat You Bring\n4+ years of experience in backend development using Java (preferably versions 8, 11, or 17).\n\nSolid experience with Spring Boot, Microservices, and RESTful APIs.\n\nStrong grasp of software architecture, modular design, and scalable systems.\n\nProficiency with both relational (PostgreSQL, MySQL) and NoSQL (MongoDB, Redis) databases.\n\nFamiliarity with cloud infrastructure (AWS or Azure), Docker, and CI/CD pipelines.\n\nExposure to distributed systems and tuning for performance and reliability.\n\nDeep understanding of software design principles like SOLID, DRY, and Clean Code.\n\nNice to Have\nExperience In Fintech, SaaS, Or Other Product-based Platforms.\nKnowledge of Kafka, GraphQL, Kubernetes, or event-driven architecture.\n\nA track record of leading engineering pods or mentoring team members.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4270260552": {
    "job_url": "https://www.linkedin.com/jobs/view/4270260552",
    "job_summary": "Senior Backend Python Engineer [32426]\nSenior Backend Python Engineer [32426]\nStealth AI Startup\nIndia (Remote)\n3 company alumni work here\n3 Walmart Global Tech India company alumni work here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nCompensation: Up to $300,000 USD annually + Equity\n\nType: Full-time | Remote\n\n\n\n\nWe're looking for a Senior Python Backend Engineer to help build infrastructure powering real-time AI workflows and ML pipelines. Youll work on high-availability systems and collaborate with a global team of engineers and researchers.\n\n\n\n\nResponsibilities:\n\nBuild and optimize backend APIs and services for AI products\nIntegrate with task queues, model inference APIs, and vector search systems\nEnsure system reliability and scalability across deployments\n\n\n\n\nRequirements:\n\n5+ years of Python backend development\nExperience with FastAPI or Django, PostgreSQL, Celery, Redis\nFamiliarity with LLM infrastructure, data orchestration, or AI tools is a big plus\nStrong problem-solving, documentation, and testing practices",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4270410861": {
    "job_url": "https://www.linkedin.com/jobs/view/4270410861",
    "job_summary": "Data Engineer\nData Engineer with verification\nXebia\nBengaluru, Karnataka, India (Hybrid)\n1 school alum works here\n1 Indian Institute of Technology (Banaras Hindu University), Varanasi school alum works here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\n Hiring: Data Engineer  SDE2 | Bangalore | Immediate Joiners\n\n Join our growing team at Xebia!\n\n\n\n\nWere looking for a Data Engineer (SDE2 level) with strong hands-on expertise in Python, PySpark, Hive, Hadoop HDFS, Oozie, and Yarn.\n\n\n\n\nRole Details:\n\nPosition: Data Engineer  SDE2\nExperience: 6  10 Years\nLocation: Bangalore\nMode of Work: Hybrid  Work from client location in Whitefield 3 days a week\nNotice Period: Only Immediate Joiners or up to 2 weeks notice will be considered\n\n\n\n\nTechnical Skills Required:\n\nProficient in Python and PySpark\nExperience with Hive, Hadoop HDFS, Oozie, and Yarn\nStrong problem-solving and data engineering fundamentals\n\n\n\n\n How to Apply:\n\nIf you meet the criteria and are ready to take the next step in your career, please email your resume to vijay.s@xebia.com with the following details:\n\nFull Name\nTotal Experience\nCurrent CTC\nExpected CTC\nCurrent Location\nPreferred Xebia Location\nNotice Period / Last Working Day (if serving)\nPrimary Skills\nLinkedIn Profile\n\n\n\n\n Why Xebia?\n\nWork on cutting-edge data engineering projects with a global tech leader. Join a collaborative team culture that values innovation and agility.\n\nApply now  were moving fast!",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4226062221": {
    "job_url": "https://www.linkedin.com/jobs/view/4226062221",
    "job_summary": "Software development Engineer - Backend\nSoftware development Engineer - Backend with verification\nPocket FM\nBangalore Urban, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nSoftware Development Engineer-Backend\n\n\n\n\nLocation: Bengaluru\n\nExperience: 02 years\n\n\n\n\nAbout Pocket FM\n\nPocket FM is India's leading audio streaming platform with a mission to redefine the way stories are consumed. We are building a personalized entertainment experience for the next billion users through a robust tech platform powered by data, intelligence, and audio innovation. Join us on our journey to scale storytelling to millions, one stream at a time.\n\n\n\n\nRole Overview\n\nWe are looking for a motivated and curious SDE-1 to join our fast-paced engineering team. You will play a key role in building scalable backend services and APIs that power our audio platform. If you are passionate about backend development and have hands-on experience with Python or Golang, wed love to connect with you.\n\n\n\n\nResponsibilities\n\nBuild and maintain highly scalable backend systems using Python or Golang\nDevelop RESTful APIs and services for Pocket FMs core platform\nWork closely with product, design, and data teams to deliver seamless user experiences\nOptimize application performance and write clean, maintainable code\nParticipate in code reviews, learning sessions, and continuous improvement initiatives\nTroubleshoot and debug production issues as part of a collaborative team\n\nRequirements\n\nBachelor's degree in Computer Science, Engineering, or a related field\n02 years of backend development experience in Python or Golang\nStrong understanding of computer science fundamentals (DSA, OOP, OS, networking)\nFamiliarity with REST API development and version control (Git)\nWorking knowledge of databases (e.g., PostgreSQL, MongoDB, Redis)\nAbility to write modular, reusable, and testable code\nGood communication skills and a proactive attitude\n\nNice to Have\n\nExposure to cloud platforms like AWS, GCP, or Azure\nExperience with container technologies like Docker\nFamiliarity with monitoring, logging, or CI/CD tools\nContributions to open-source projects or personal backend projects",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4256690309": {
    "job_url": "https://www.linkedin.com/jobs/view/4256690309",
    "job_summary": "Developer\nDeveloper with verification\nIDFC FIRST Bank\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nApplied",
    "job_details": "About the job\n\nRole/ Job Title: Developer\n\nFunction/ Department: Information Technology\n\nJob Purpose: Senior Developer works with the Technology Delivery Managers, Business Units, Enterprise / Solution Architects, and vendor partners to implement API solutions to solve mission-critical business challenges. The Developer builds and maintains integrations for multiple on premises and/or cloud systems and must be capable of understanding business requirements, working with end users and developing and deploying the integrations.\n\nRoles and Responsibilities:\n\nMinimum of 2+ years of experience in Microservices architecture with the ability to collaborate effectively with team members and build positive working relationships.\nDesign and build and deploy APIs to meet business requirements.\nHigh level of commitment to business satisfaction and agility.\nStrong work ethic and a passion for the role, with a positive attitude and a willingness to learn.\nCommunicate effectively with the tech lead to thoroughly understand the requirements and highlight any blockers immediately.\nHandle programming and software development, including requirement gathering, bug fixing, testing, documenting, and implementation.\nWork in an agile environment to deliver high-quality solutions.\nUnderstand and implement Security, Logging, Auditing, Policy Management, and Performance Monitoring.\nFamiliarity with relational databases (E.g.: Oracle), non-relational databases (E.g.: MongoDB), MSK Kafka, Docker, Kubernetes, and CICD Technologies (Jenkins, GitHub, Maven)\n\nEducation Qualification: \n\nGraduation: Bachelor of Science (B.Sc) / Bachelor of Technology (B.Tech) / Bachelor of Computer Applications (BCA)\n\nPost-Graduation: Master of Science (M.Sc) /Master of Technology (M.Tech) / Master of Computer Applications (MCA)",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": true,
    "easy_apply": false
  },
  "https://www.linkedin.com/jobs/view/4256726393": {
    "job_url": "https://www.linkedin.com/jobs/view/4256726393",
    "job_summary": "Python+AI Developer\nPython+AI Developer with verification\nLTIMindtree\nBangalore Urban, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nDear Candidate,\n\nGreetings from LTIMindtree!\n\nThis is with reference to your profile on the job site. We have an urgent requirement for a - Python + AI\n\n\n\n\nSkill- Python + AI\n\nLocation  Pan India\n\nNP- immediate or 1 month notice period can be considered \n\nExperience  5-7 Years experience \n\n\n\n\nJob description -\n\n\n\n\nJob Description:\n\nWe are looking for a skilled and passionate Python Developer with experience in Generative AI to join our fast-paced AI/ML team. The ideal candidate will have strong Python programming skills, deep understanding of machine learning, and hands-on experience building or integrating with Generative AI models (like GPT, Stable Diffusion, etc.).\n\nKey Responsibilities:\n\nDesign, develop, and maintain backend services and AI pipelines using Python.\nIntegrate and fine-tune Generative AI models (e.g., GPT-3/4, LLaMA, Stable Diffusion, DALL E, etc.).\nDevelop APIs to serve AI model outputs for various use cases (chatbots, content generation, etc.).\nWork with ML engineers to deploy and scale generative models.\nCollaborate with cross-functional teams (product, data science, frontend) to deliver end-to-end features.\nOptimize performance and memory usage of AI services.\nStay updated with the latest in AI/ML research, especially in Generative AI.\n\nRequired Skills:\n\nStrong programming skills in Python (OOP, data structures, etc.)\nExperience with Generative AI frameworks (OpenAI, Hugging Face Transformers, LangChain, etc.)\nUnderstanding of deep learning concepts and neural networks.\nExperience working with PyTorch or TensorFlow.\nHands-on with RESTful APIs, FastAPI/Flask.\nFamiliarity with prompt engineering, embeddings, and vector databases (like FAISS, Pinecone, etc.)\nExperience with cloud platforms (AWS, Google Cloud Platform, or Azure) is a plus.\n\n \n\nInterested candidates kindly share your updated profile at: roshni.sah@ltimindtree.com\n\nWe encourage you to share this opportunity with your friends and colleagues who may be looking for a similar role.\n\nLTIMindtree is proud to be an equal opportunity employer. We are committed to equal employment opportunity regardless of race, ethnicity, nationality, gender, gender-identity, gender expression, language, age, sexual orientation, religion, marital status, veteran status, socio-economic status, disability or any other characteristic protected by applicable law.\n\nRegards, \n\nLTIM Talent Acquisition",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4266239249": {
    "job_url": "https://www.linkedin.com/jobs/view/4266239249",
    "job_summary": "Data Engineer\nData Engineer with verification\nIntellias\nIndia (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nTitle: Data Engineer\n\nLocation: Remote, India\n\nExperience: 3 to 6 yrs\n\n\n\n\nResponsibilities:\n\nWork as part of a team to develop and implement procedures for secure and effective data management.\nImplement data definitions, data mappings, and provide support across ongoing integration activities.\nWork collaboratively with our Product Owners and Software Engineering teams to understand and define application and platform data requirements.\nDemonstrate an in-depth understanding of database structures and principles.\nBe an advocate for the work done by the team and share achievements both at a technical and business level with the wider technology group.\nTranslate non-technical requirements to technical requirements\nProvide clean, transformed data ready for analysis\nMaintain data documentation and definitions\nTrain business users on how to use data visualisation tools\n\n\n\n\nRequired Technical Knowledge:\n\n3-5 Years of Experience. Good working knowledge of AWS data analytics services (Kinesis, Redshift, DataDog)\nExperience with scripting languages such as Python\nFamiliar with serverless, event-driven technology such as AWS Lambda\nExperience with AWS S3 bucket and AWS Glue\nMust have used Python for data processing. Building data, processing and data quality checks.\nExperience working with both SQL and NoSQL databases\nFamiliar working with Gitlab CI/CD to support the deployment of applications across cloud infrastructure\nGood working knowledge of JIRA and Confluence\nFamiliar working with cloud log management and monitoring data platforms\nGood understanding of Terraform\nThe ability and appetite to learn and use a wide variety of open-source technologies and tools",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4270617605": {
    "job_url": "https://www.linkedin.com/jobs/view/4270617605",
    "job_summary": "Software Engineer - AI Platform\nSoftware Engineer - AI Platform with verification\nCoinbase\nIndia (Remote)\n20 company alumni work here\n20 Walmart Global Tech India company alumni work here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nReady to be pushed beyond what you think youre capable of?\n\nAt Coinbase, our mission is to increase economic freedom in the world. Its a massive, ambitious opportunity that demands the best of us, every day, as we build the emerging onchain platform  and with it, the future global financial system.\n\nTo achieve our mission, were seeking a very specific candidate. We want someone who is passionate about our mission and who believes in the power of crypto and blockchain technology to update the financial system. We want someone who is eager to leave their mark on the world, who relishes the pressure and privilege of working with high caliber colleagues, and who actively seeks feedback to keep leveling up. We want someone who will run towards, not away from, solving the companys hardest problems.\n\nOur work culture is intense and isnt for everyone. But if you want to build the future alongside others who excel in their disciplines and expect the same from you, theres no better place to be.\n\nWhile many roles at Coinbase are remote-first, we are not remote-only. In-person participation is required throughout the year. Team and company-wide offsites are held multiple times annually to foster collaboration, connection, and alignment. Attendance is expected and fully supported.\n\n \n\nThe mission of the Platform Product Group engineers is to build a trusted, scalable and compliant platform to operate with speed, efficiency and quality. Our teams build and maintain the platforms critical to the existence of Coinbase. There are many teams that make up this group which include Product Foundations (i.e. Identity, Payment, Risk, Proofing & Regulatory, Finhub), Machine Learning, Customer Experience, and Infrastructure.\n\nThe AI Platform Team is a dynamic and ambitious group focused on building centralized AI infrastructure and acceleration solutions that drive productivity, innovation, and customer impact across Coinbase. Our mission is to accelerate AI adoption, enhance team efficiency, and deliver exceptional customer experiences by embedding growth pods directly within teams across the organization. As a Software Engineer on our team, youll be driving this transformative shift within the company. Youll work with state-of-the-art AI models, frameworks, and tools, playing a pivotal role in shaping how people and businesses engage with and benefit from AI in the future.\n\n\n\nWhat youll be doing (ie. job duties):\n\nExplore and apply advanced GenAI techniques, including large language models (LLMs) and Agentic AI, to solve complex challenges across the organization.\nLead project execution by managing priorities, deadlines, and deliverables, leveraging your technical expertise.\nWrite high-quality, well-tested code in Python and Golang to address critical product and business needs.\nArchitect scalable, secure systems using modern cloud technologies and industry best practices.\nMentor team members on design principles, coding standards, and AI productivity tools adoption.\nDebug complex technical issues to enhance system reliability, scalability, and ease of operation.\nReview and ensure the security, scalability, and architectural integrity of feature designs across teams.\nBuild pipelines to integrate with third-party vendors and streamline workflows.\n\n \n\nWhat we look for in you (ie. job requirements):\n\n3+ years of experience in software engineering.\nProven expertise in designing, building, scaling, and maintaining production services, with a strong understanding of micro-services architecture.\nAbility to write high-quality, well-tested code that meets customer needs.\nDeep understanding of what high-quality code and software engineering processes look like, and the ability to foster an environment that promotes them.\nStrong technical skills in system design and coding.\nPassion for building an open financial system that unites the world.\nExcellent written and verbal communication skills, with a preference for open and transparent cultural practices.\n\nNice to haves:\n\nExperience navigating rapid company growth (e.g., from startup to mid-size).\nFamiliarity with GenAI frameworks/tools, Python, GoLang, Docker, Postgres, MongoDB.\nBackground in AI/LLM infrastructure is a strong plus.\n\n \n\nJob Id : GPBE04IN\n\n*Answers to crypto-related questions may be used to evaluate your onchain experience.\n\n \n\nPlease be advised that each candidate may submit a maximum of four applications within any 30-day period. We encourage you to carefully evaluate how your skills and interests align with Coinbase's roles before applying.\n\nCommitment to Equal Opportunity\n\nCoinbase is proud to be an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, gender, national origin, age, disability, veteran status, sex, gender expression or identity, sexual orientation or any other basis protected by applicable law. Coinbase will also consider for employment qualified applicants with criminal histories in a manner consistent with applicable federal, state and local law. For US applicants, you may view the Employee Rights and the Know Your Rights notices by clicking on their corresponding links. Additionally, Coinbase participates in the E-Verify program in certain locations, as required by law. \n\nCoinbase is also committed to providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process, please contact us at accommodations[at]coinbase.com to let us know the nature of your request and your contact information. For quick access to screen reading technology compatible with this site click here to download a free compatible screen reader (free step by step tutorial can be found here).\n\nGlobal Data Privacy Notice for Job Candidates and Applicants\n\nDepending on your location, the General Data Protection Regulation (GDPR) and California Consumer Privacy Act (CCPA) may regulate the way we manage the data of job applicants. Our full notice outlining how data will be processed as part of the application procedure for applicable locations is available here. By submitting your application, you are agreeing to our use and processing of your data as required. For US applicants only, by submitting your application you are agreeing to arbitration of disputes as outlined here. \n\nAI Disclosure\n\nFor select roles, Coinbase is piloting an AI tool based on machine learning technologies to conduct initial screening interviews to qualified applicants. The tool simulates realistic interview scenarios and engages in dynamic conversation. A human recruiter will review your interview responses, provided in the form of a voice recording and/or transcript, to assess them against the qualifications and characteristics outlined in the job description. \n\nFor select roles, Coinbase is also piloting an AI interview intelligence platform to transcribe and summarize interview notes, allowing our interviewers to fully focus on you as the candidate. \n\nThe above pilots are for testing purposes and Coinbase will not use AI to make decisions impacting employment. To request a reasonable accommodation due to disability, please contact accommodations@coinbase.com.\n\n \n\n ",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4267683066": {
    "job_url": "https://www.linkedin.com/jobs/view/4267683066",
    "job_summary": "Python Developer\nPython Developer\nDexian India\nIndia (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob Title: Full-Stack Engineer  Snowflake & Cortex AI\n\n\n\n\n*ONLY IMMEDIATE JOINERS*\n\n\n\n\nAbout the Role\n\n Were looking for a hands-on full-stack engineer who can turn Snowflakes data infrastructure into intelligent, conversational products. Youll own end-to-end delivery of chat-based applications that surface both structured and unstructured data stored in Snowflake, leveraging the latest Snowflake Cortex AI capabilities (Cortex Analyst, Cortex Search, and Cortex Agents).\n\n\n\n\nWhat Youll Do\n\nDesign & build chatbots that access, reason over, and summarize Snowflake data sets (tables, documents, and semi-structured data).\nDevelop full-stack features (frontend, backend, and DevOps) to deliver secure, scalable conversational experiences.\nIntegrate Snowflake APIs & Cortex AI componentsimplement vector search, retrieval-augmented generation (RAG), and agent workflows.\nModel, transform, and optimize data pipelines to make information chatbot-ready (tokenization, embeddings, prompt engineering).\nEstablish engineering best practices around code quality, CI/CD, observability, and automated testing for AI-powered services.\nCollaborate cross-functionally with data engineers, data scientists, and product managers to iterate quickly from concept to production.\nStay current on Snowflake product releases, LLM advances, and GenAI safety/ethics guidelines; evangelize learnings within the team.\n\n\n\n\nMust-Have\n\n5+ years building production full-stack applications (any modern JS/TS framework + backend language).\n\nDemonstrated expertise with Snowflake SQL, warehousing concepts, and Snowflake APIs/Snowpark.\n\nHands-on work with Snowflake Cortex (Analyst, Search, Agents) or clear evidence you can ramp up fast.\n\nSolid grasp of REST/GraphQL, authentication (OAuth/JWT), and cloud infrastructure (AWS, Azure, or GCP).\n\nAbility to write clean, test code and perform code reviews.\n\n\n\n\nNice-to-Have\n\nExperience fine-tuning or deploying LLMs (OpenAI, Anthropic, etc.).\n\nFamiliarity with Lang Chain, LlamaIndex, or similar RAG frameworks.\n\nExperience with real-time streaming (Kafka, Snowpipe) and event-driven architectures.\n\nKnowledge of UI/UX patterns for conversational interfaces (chat widgets, voice, etc.).\n\nML/DS background or academic work in NLP / IR.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4267350926": {
    "job_url": "https://www.linkedin.com/jobs/view/4267350926",
    "job_summary": "Python Developer\nPython Developer with verification\nITC Infotech\nBangalore Urban, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nPython + AWS\n\n\n\n\nStrong knowledge and working experience in Advanced Python programming, \nDevelopment of RESTful APIs using AWS API Gateway, \nDevelopment of serverless program using AWS Lambda, \nWorking knowledge on Amazon S3 Buckets, \nDatabase skills  including both SQL and NoSQL\nWorking knowledge of ETL using AWS Glue (PySpark or Prefect preferred)\nWorking knowledge and good exposure of Django or similar framework\nShould be able to write/debug and troubleshoot configurations and programs in AWS environment\nGood exposure and working knowledge on Terraform\nBasic knowledge on deploying AWS resources using Terraform including S3, EC2, Lambda, Glue\nGood analytical and debugging skills\n\nKey Responsibilities & Skills:\n\n\n\n\nServe as the primary point of contact for clients throughout the engagement lifecycle\nCollaborate with clients to understand their requirements, goals, and expectations\nDevelop comprehensive project plans, including scope, schedule, budget, and resource allocation\nLead project kickoff meetings and ensure alignment among all stakeholders\nCoordinate project activities and manage project teams to ensure milestones are met on time and within budget\nMonitor project progress and identify potential risks or issues; develop and implement mitigation strategies as needed\nProvide regular status updates to clients and internal stakeholders, including progress reports, budget reviews, and risk assessments\nFacilitate communication and collaboration among project team members, clients, and third-party vendors\nEnsure project documentation is accurate, up-to-date, and accessible to all relevant parties.\nConduct post-project evaluations to assess outcomes, identify lessons learned, and make recommendations for process improvements.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4256504751": {
    "job_url": "https://www.linkedin.com/jobs/view/4256504751",
    "job_summary": "Software Engineer\nSoftware Engineer\nExxat\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nSoftware Development Engineer \n\nLocation: Bangalore\n\nExperience: 5 to 10 years\n\n\n\n\nAbout Exxat\n\nAt Exxat, we are on a mission to empower the next generation of healthcare professionals through smart, scalable technology. Our integrated platform supports academic institutions in managing clinical education, compliance, assessments, and student experiences efficiently and effectively.\n\n\n\n\nRole Overview\n\nWe are looking for Software Engineers who are passionate to work in a collaborative, fast-paced, microservices-based web solution. You will get to work on cutting-edge tech which will be used by thousands of clinical students and practitioners in the USA.\n\n\n\n\nAs a Software Engineer, you are expected to solve complex programming problems and have an understanding about how to build HLDs and LLDs. You should have experience in building enterprise-grade software using .NET or Java stack on cloud technologies, or with modern JavaScript (Angular, React, etc.) frameworks. Understanding of Agile Scrum process is a plus.\n\n\n\n\nResponsibilities\n\nDeliver clean code with automated unit tests.\nCreate High-Level and Low-Level Designs for the problem statement/feature.\nHands-on expertise in high-performance backend languages like Go, C#/.NET, or Java, or expertise in JavaScript/TypeScript along with a framework like React or Angular.\nFull stack understanding of web/mobile/API/database development concepts and design patterns.\nStrive for quality, performance, usability, reliability, maintainability, and extensibility.\nDesign and develop high-quality microservices and features, working with architects and development managers.\nParticipate and contribute to continuously improve Agile software development processes.\nWork under the guidance of development managers and product owners to analyze, modify, and implement various common business needs.\nGet involved in tech POCs to provide recommendations and apply the outcome to realization.\nImplement unit, integration, and other automated tests.\nUnderstanding of DevOps, automation testing, test-driven development, behavior-driven development, serverless or microservices.\nUnderstanding of Agile Scrum and SDLC principles.\n\n\n\n\nNice to Have\n\nExperience with AWS or Azure cloud technologies (such as Azure Functions, Lambda, or DynamoDB).\n\n\n\n\nDesired Experience\n\n5 to 10 years of experience building enterprise-grade software.\nWe look for good programmers (not just good technologists) who bring a deep understanding of algorithms, data structures, and SOLID principles to the table.\nWhile we operate on a .NET stack, we are not hung up on you knowing specific technologies or programming languages.\n\n\n\n\nEducation: Bachelor's or Masters degree in Computer Science or a related engineering field.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4269939472": {
    "job_url": "https://www.linkedin.com/jobs/view/4269939472",
    "job_summary": "Data Engineer\nData Engineer\nReveal HealthTech\nBengaluru, Karnataka, India (Hybrid)\nViewed\nEasy Apply",
    "job_details": "About the job\n\nThank you for considering the Data Engineer position at Reveal Health Tech. We are an early-stage IT startup based in the US and India, focused on leveraging technology to deliver transformative solutions for companies within healthcare and lifesciences.\n\nAbout The Role\n\nWe are seeking a skilled Data Engineer proficient in python with experience in Django framework, PostgreSQL database management, and AWS/Azure to join our dynamic team. As a Data Engineer, you will be responsible for designing, implementing, and maintaining scalable data pipelines to support our growing data processing needs. The ideal candidate is independent, detail-oriented, and capable of performing data validation and debugging to ensure high data quality and reliability.\n\nFind out more about our mission and why we started Reveal Health Tech on our website.\n\nRequirements\n\n\nDesigning and implementing scalable, robust, and maintainable data pipelines using AWS/Azure services\nImplementing data quality checks and validation processes to ensure accuracy, completeness, and integrity of data\nDesigning effective data models and architectures to optimize data processing and facilitate downstream Data Science and Machine Learning workflows\nUtilizing data quality validation tools to automate and streamline validation processes\nWork closely with Product Managers, Quality Assurance, and DevOps teams to deliver high-performance and reliable software solutions\nMonitoring and optimizing the performance of data pipelines\nDebugging issues and resolving data-related problems in a timely manner\nDocumenting data pipeline architectures, processes, and procedures\nStay up-to-date with new technologies, tools, and best practices in the data engineering field\n\n\n\nKey Skills & Qualifications:\n\n\nBachelor's degree in Computer Science, Engineering, or a related field (or equivalent work experience)\nMinimum 3+ years of experience in Data Engineering\nProficiency in data modeling and architecture, leveraging AWS/Azure services to architect scalable and efficient data solutions\nExperience designing and building data pipelines from diverse source systems\nSolid understanding of data lake and warehousing concepts and best practices\nProficiency in programming languages used for data manipulation and transformation (e.g., Python, SQL)\nExtensive knowledge and hands-on experience with the Django framework\nExperience with relational databases like PostgreSQL (PSQL)\nKnowledge of RESTful Web Services and API development\nUnderstanding of database systems, including schema design, SQL querying, and performance optimization\nExperience implementing data quality checks and validation processes\nExperience using CloudFormation and CI/CD for deployment\nProficiency in version control systems, particularly Git\nAbility to work independently and as part of a team in a fast-paced environment\nExcellent problem-solving skills and attention to detail. \n\n\n\nPreferred Skills:\n\n\nAWS certification (e.g., AWS Certified Solutions Architect, AWS Certified Data Analytics Specialty)\nFamiliarity with serverless computing (e.g., AWS Lambda) and containerization (e.g., Docker)\nExperience with LLMs and machine learning is highly preferred\n\n\n\nBenefits\n\n\nHow you will enrich us? \n\n\nEnergetic and enthusiastic\nAutonomous and self-motivated\nGrowth mindset\nEmbraces challenges\nBuilding new things gets your blood pumping!\nCuriosity and deep interest in the world\nChallenges the status quo constructively",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4259833185": {
    "job_url": "https://www.linkedin.com/jobs/view/4259833185",
    "job_summary": "Python Developer\nPython Developer\nThe Law Reporters\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob Summary:\n\nWe are seeking a dynamic and detail-oriented Python Developer to join our growing tech team in Bengaluru. This hybrid role is ideal for someone with a strong foundation in backend development using Python and hands-on experience in software testing. You will be involved in building scalable backend systems, integrating APIs, and ensuring high-quality product delivery through rigorous testing.\n\nKey Responsibilities:As a Python Developer:\n\nWrite clean, efficient, and maintainable Python code\nDevelop and maintain backend components using Django, Flask, or FastAPI\nDesign scalable and secure application architectures\nBuild and integrate RESTful and WebSocket APIs\nCollaborate with frontend teams for seamless integration\nImplement authentication, authorization, and data security best practices\nTroubleshoot and optimize system performance\nStay up to date with emerging development tools and frameworks\n\nRequirements:\n\n3+ years of professional experience in Python backend development\nExperience with Django, Flask, or FastAPI frameworks\nProficiency in testing tools like Selenium, Postman, PyTest, or JMeter\nStrong understanding of RESTful APIs and database (SQL/NoSQL) systems\nKnowledge of Git or similar version control systems\nExperience in writing unit tests and automated test scripts\nSolid debugging, analytical, and problem-solving skills\nExcellent communication and teamwork capabilities\nBachelors degree in computer science, Engineering, or related field\n\nNice to Have:\n\nKnowledge of cloud platforms (AWS, Azure, GCP)\nFamiliarity with container tools like Docker\nExperience in CI/CD tools (e.g., Jenkins, GitHub Actions)\nExposure to frontend technologies (React.js, JavaScript, HTML/CSS)\nUnderstanding of Agile/Scrum methodologies\nExperience with performance and security testing",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4265193195": {
    "job_url": "https://www.linkedin.com/jobs/view/4265193195",
    "job_summary": "Senior Software Engineer\nSenior Software Engineer with verification\nLucidity\nIndia (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nRole : Senior Software Engineer - Backend\n\nLocation : Bangalore/Remote\n\nExperience : 3-6 years\n\n\n\n\nAbout us\n\nLucidity is a rapidly growing company with a first of its kind and impactful product in the cloud storage. Joining Lucidity offers the opportunity to work on cutting-edge technology, solve real-world problems for major enterprises, and be part of a company that is reshaping the future of cloud storage.\n\n\n\n\nWe were also awarded Best Infra and Dev Tools SaaS Startup by SaaSBoomi  Link\nListed among Indias Top Startups by LinkedIn Link\nWe are backed by $32 M in funding from investors like Alpha Wave Global, WestBridge Capital, and Beenext - Link\nWe are the category leader in cloud storage optimization.\nTrusted by major enterprises, including Fortune 500 companies spanning across the US and the UK, being the major Markets.\nOpportunity to work with experienced co-founders Vatsal & Nitin - serial entrepreneurs who bring with them more than a decade of experience working with companies like Microsoft, Swiggy, and Tracxn and building and selling large tech products.\nWork in deep tech company and be part of an accelerated growth journey\nWe have a presence across India, Abu Dhabi, the US, and the UK.\n\n\n\n\nWhat we do\n\nLucidity is a company that provides an automated NoOps disk auto-scaler for cloud storage across AWS, Azure, and GCP. It addresses over-provisioned block storage by dynamically scaling capacity, increasing disk utilization to around 80% from 25-35%. This results in cost reductions of up to 70% for businesses. Here's a video of what Lucidity does.\n\n\n\n\nKey benefits include:\n\nSignificant Cost Savings on storage (especially EBS costs).\nElimination of Downtime by preventing disk space issues.\nReduced DevOps Effort through automation.\nApplication Agnostic solution works with various systems.\n\n\n\n\nTechnology is at the heart of our organization. As part of the tech team you will :\n\n1.Understand product requirements and brainstorm ways to address them\n\n2.Build features from scratch and have complete ownership for it\n\n3.Deliver efficient, reliable, scalable code with high automated test coverage\n\n4. Contribute to team decisions in the overall architecture and practices of the company\n\n\n\n\nWhat you'll need:\n\n\n\n\nMust haves\n\n\n\n\nAt least 4 year experience in a product based company\nWillingness to work in fast-paced, ambiguous, startup environments\nExperience working with distributed systems\nComfortable with at least one Object Oriented Programming language (C++, Java, Python, Go)\nHands on with AWS or at least one other public cloud\nStrong knowledge of SQL and RDBMS like MySQL\nExperience with git\n\n\n\n\n\n\n\nGood to have\n\n\n\n\nExperience handling highly scalable systems\nStrong systems understanding (Linux/Windows, kernel tuning/troubleshooting, performance benchmarking, filesystems tuning)\nExperience with Docker and Kubernetes\nStorage domain experience is a big plus\nFamiliarity with Agile development methodologies\nExcellent communication & collaboration skills\n\n\n\n\n\n\n\nWhy us\n\nWe're hiring a set of highly skilled, enthusiastic, and passionate people who thrive in a high-growth environment. We believe the best way to grow is to give everyone the opportunity to pursue their interests. Plus, with benefits like flexible hours, company offsite, unlimited leaves, we ensure you enjoy the journey as much as we do.\n\n\n\n\nWhat do we promise?\n\nA high-growth work environment\nAutonomy to decide & deliver on KPIs\nWork from home | Flexible hours | Unlimited Leaves\nAttractive ESOPs. Potential to see 100x in the next 5 years.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4259575925": {
    "job_url": "https://www.linkedin.com/jobs/view/4259575925",
    "job_summary": "Specialist Software Engineer-Python+React\nSpecialist Software Engineer-Python+React with verification\nSociete Generale Global Solution Centre\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nResponsibilities: \n\n\n\n\nDevelop code and test case scenarios by applying relevant software craftsmanship principles and meet the acceptance criteria\nStrong understanding and experience on Python and React\nComplete the assigned learning path and contribute to daily meetings.\nDeliver on all aspects of Software Development Lifecyle (SDLC) in-line with Agile and IT craftsmanship principles.\nTake part in team ceremonies be it agile practices or chapter meetings.\nDeliver high-quality clean code and design that can be re-used.\nActively, work with other Development teams to define and implement API's and rules for data access.\nPerform bug-free release validations and produce test and defect reports.\nContribute to developing scripts, configuring quality and automating framework usage.\nRun and maintain test suites with the guidance of seniors.\nSupport existing data models, data dictionary, data pipeline standards, storage of source, process and consumer metadata\n\n\n\n\nProfile Required: \n\nBachelors degree in Computer Science or a related field\n4-7 experience in python + React\nStrong development experience using Python & React\nGood work experience in writing API's and managing it\nStrong in DB concepts\nGood knowledge of Agile Scrum principles and practices\nGood understanding of CICD practice\nExcellent communication and interpersonal skills\nStrong problem-solving and analytical skills\nAbility to handle the development tasks individually\n\n\n\n\nEnvironment\n\nAt Socit Gnrale, we are convinced that people are drivers of change, and that the world of tomorrow will be shaped by all their initiatives, from the smallest to the most ambitious. Whether youre joining us for a period of months, years or your entire career, together we can have a positive impact on the future. Creating, daring, innovating, and taking action are part of our DNA. If you too want to be directly involved, grow in a stimulating and caring environment, feel useful on a daily basis and develop or strengthen your expertise, you will feel right at home with us!\n\nStill hesitating?\n\nYou should know that our employees can dedicate several days per year to solidarity actions during their working hours, including sponsoring people struggling with their orientation or professional integration, participating in the financial education of young apprentices, and sharing their skills with charities. There are many ways to get involved.\n\nWe are committed to support accelerating our Groups ESG strategy by implementing ESG principles in all our activities and policies. They are translated in our business activity (ESG assessment, reporting, project management or IT activities), our work environment and in our responsible practices for environment protection.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4259416560": {
    "job_url": "https://www.linkedin.com/jobs/view/4259416560",
    "job_summary": "Senior Software Engineer (Bigdata)\nSenior Software Engineer (Bigdata) with verification\nRoku\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nEasy Apply",
    "job_details": "About the job\n\nTeamwork makes the stream work.Roku is changing how the world watches TV\n\nRoku is the #1 TV streaming platform in the U.S., Canada, and Mexico, and we've set our sights on powering every television in the world. Roku pioneered streaming to the TV. Our mission is to be the TV streaming platform that connects the entire TV ecosystem. We connect consumers to the content they love, enable content publishers to build and monetize large audiences, and provide advertisers unique capabilities to engage consumers.\n\nFrom your first day at Roku, you'll make a valuable - and valued - contribution. We're a fast-growing public company where no one is a bystander. We offer you the opportunity to delight millions of TV streamers around the world while gaining meaningful experience across a variety of disciplines.\n\n \n\n \n\n \n\nAbout the team\n\nRoku runs one of the largest data lakes in the world. We store over 70 PB of data, run 10+M queries per month, scan over 100 PB of data per month. \nBig Data team is the one responsible for building, running, and supporting the platform that makes this possible. We provide all the tools needed to acquire, generate, process, monitor, validate and access the data in the lake for both streaming data and batch. We are also responsible for generating the foundational data. The systems we provide include Scribe, Kafka, Hive, Presto, Spark, Flink, Pinot, and others. The team is actively involved in the Open Source, and we are planning to increase our engagement over time. \n\n\nAbout the Role \n\nRoku is in the process of modernizing its Big Data Platform. We are working on defining the new architecture to improve user experience, minimize the cost and increase efficiency. Are you interested in helping us build this state-of-the-art big data platform? Are you an expert with Big Data Technologies? Have you looked under the hood of these systems? Are you interested in Open Source? If you answered Yes to these questions, this role is for you! \n\n \n\nWhat you will be doing \nYou will be responsible for streamlining and tuning existing Big Data systems and pipelines and building new ones. Making sure the systems run efficiently and with minimal cost is a top priority \nYou will be making changes to the underlying systems and if an opportunity arises, you can contribute your work back into the open source \nYou will also be responsible for supporting internal customers and on-call services for the systems we host. Making sure we provided stable environment and great user experience is another top priority for the team \n\n \n\nWe are excited if you have \n7+ years of production experience building big data platforms based upon Spark, Trino or equivalent \nStrong programming expertise in Java, Scala, Kotlin or another JVM language. \nA robust grasp of distributed systems concepts, algorithms, and data structures \nStrong familiarity with the Apache Hadoop ecosystem: Spark, Kafka, Hive/Iceberg/Delta Lake, Presto/Trino, Pinot, etc. \nExperience working with at least 3 of the technologies/tools mentioned here: Big Data / Hadoop, Kafka, Spark, Trino, Flink, Airflow, Druid, Hive, Iceberg, Delta Lake, Pinot, Storm etc \nExtensive hands-on experience with public cloud AWS or GCP \nBS/MS degree in CS or equivalent\nAI Literacy /AI growth mindset\n\n \n\n \n\n Benefits\n\nRoku is committed to offering a diverse range of benefits as part of our compensation package to support our employees and their families. Our comprehensive benefits include global access to mental health and financial wellness support and resources. Local benefits include statutory and voluntary benefits which may include healthcare (medical, dental, and vision), life, accident, disability, commuter, and retirement options (401(k)/pension). Our employees can take time off work for vacation and other personal reasons to balance their evolving work and life needs. It's important to note that not every benefit is available in all locations or for every role. For details specific to your location, please consult with your recruiter.\n\n \n\nThe Roku Culture\n\nRoku is a great place for people who want to work in a fast-paced environment where everyone is focused on the company's success rather than their own. We try to surround ourselves with people who are great at their jobs, who are easy to work with, and who keep their egos in check. We appreciate a sense of humor. We believe a fewer number of very talented folks can do more for less cost than a larger number of less talented teams. We're independent thinkers with big ideas who act boldly, move fast and accomplish extraordinary things through collaboration and trust. In short, at Roku you'll be part of a company that's changing how the world watches TV. \n\nWe have a unique culture that we are proud of. We think of ourselves primarily as problem-solvers, which itself is a two-part idea. We come up with the solution, but the solution isn't real until it is built and delivered to the customer. That penchant for action gives us a pragmatic approach to innovation, one that has served us well since 2002. \n\nTo learn more about Roku, our global footprint, and how we've grown, visit https://www.weareroku.com/factsheet.\n\nBy providing your information, you acknowledge that you have read our Applicant Privacy Notice and authorize Roku to process your data subject to those terms.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4262810911": {
    "job_url": "https://www.linkedin.com/jobs/view/4262810911",
    "job_summary": "Back End Developer\nBack End Developer with verification\nWooqer\nGreater Bengaluru Area (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout Wooqer\n\nWooqer is an App for Work that is changing the way organisations get work done! Instead of paper processes, endless internal e-mail and spreadsheet overload, Wooqer brings the power of technology to Business users. It enables them to create Apps with a DIY (Do it yourself) approach, bringing speed and flexibility to day to day work!\n\n Wooqer is built on a strong foundation. We bootstrapped our way towards establishing a profitable and scalable Business model, acquiring some of the largest companies as customers. Wooqer is changing the way they work! Their success has been documented in a Harvard Business Case, taught across universities globally, including IIMs and multiple global B-Schools including Stanford University. Its ensuring that some of the brightest minds are learning about Wooqer. Wooqer is rated as part of Indias Top 30 most valuable Software Product Companies by iSpirt, an industry body, in partnership with the Govt of India. With the belief and support of customers across 20+ countries, we are ready for the next phase of growth.\n\n At Wooqer, you get to work with some of the brightest brains in the country, all bound by the relentless pursuit of changing the way the world works. Its an environment where excellence is hygiene and belief is religion. Growth has no limits when you take ownership and deliver results. Every challenge is yet another opportunity for a Wooqer!\n\n\n\n\nWhat Youll Do\n\nBuild, scale, and optimize backend features and APIs used across our platform\nDesign and maintain RESTful APIs for both internal and external integrations\nCollaborate closely with product managers and developers to translate functional needs into working code\nParticipate in code reviews and advocate for best practices in clean code and architecture\nContribute to backend architectural discussions, refactoring, and performance improvements\nTake full ownership from development to deployment and support\n\n\n\n\nWhat Were Looking For\n\n1+ years of hands-on experience in Java-based backend development\nProficiency in Spring / Spring Boot\nExperience in REST API design and integration\nKnowledge of relational databases like MySQL or PostgreSQL\nFamiliarity with version control (Git) and CI/CD practices\nStrong analytical thinking and an ownership mindset\nHunger to learn, grow, and contribute to high-impact product development\n\n\n\n\nGood to Have\n\nExposure to microservices and distributed systems\nFamiliarity with AWS, GCP, or Azure\nKnowledge of Kafka, RabbitMQ, or similar message brokers\nUnderstanding of performance tuning and monitoring tools\n\nIf youre excited about solving real-world problems, love building scalable systems, and want to work with a team that values ownership and excellenceyou might be a Wooqer already.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4235412913": {
    "job_url": "https://www.linkedin.com/jobs/view/4235412913",
    "job_summary": "Software Development Engineer I, SMB\nSoftware Development Engineer I, SMB with verification\nFlexport\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout Flexport: \n\nAt Flexport, we believe global trade can move the human race forward. Thats why its our mission to make global commerce so easy there will be more of it. Were shaping the future of a $10T industry with solutions powered by innovative technology and exceptional people. Today, companies of all sizes - from emerging brands to Fortune 500s - use Flexport technology to move more than $19B of merchandise across 112 countries a year.\n\nThe recent global supply chain crisis has put Flexport center stage as we continue to play a pivotal role in how goods move around the world. We are proud to have the support of the best investors in the game who believe in our mission, solutions and people. Ready to tackle global challenges that impact business, society, and the environment? Come join us.\n\nThe opportunity:\n\nInvesting your time with Flexport means keeping pace with a rapidly growing business, learning new skills, and seeking opportunities to fill the gap. We appreciate your contributions to making Flexport an amazing place to work and we encourage upwards or lateral movement and transfers that align with current business needs.\n\nExceptional software development is integral in allowing us to fulfil our mission of making global trade easier for everyone. At Flexport youll develop systems that are at the forefront of reshaping the entire logistics & supply chain industries. The SMB organization strives to increase Flexports efficiency and effectiveness by providing self-serve platforms that reduce complexity for small and medium businesses. We solve foundational engineering challenges with the added complexity of the logistics domain that Flexport is in after merging Deliverr technology.\n\nHere are some of the things we work on:\n\n\nReplenishment to FBA, WFS - Building the next generation of automated replenishment systems as merchant scale with Flexport Reserve Storage, with the promise of lean inventory and no stock-outs. \nUpstream Inventory Management - Creating a single platform for merchants to manage their inventory and plan their supply chain in the self-serve portal with all the insights and recommendations from Flexport. \nWholesale and Retail orders - Building the distribution capabilities to brick-and-mortar retailers and wholesalers. This includes onboarding, ingestion, digitalization, and outbounds of bulk orders. \nWarehouse Operational excellence - Improving the freight booking process and communication across operations, clients, carriers, and partners for inbound, outbound, and all related shipments from or to US warehouse facilities at Flexport. \n\n\nYou will:\n\n\nTake on complex product initiatives and run them to completion with minimal supervision. \nDesign flexible, maintainable and scalable code. \nSafeguard code quality on your team, reviewing others code with an eye to performance and maintainability. \nCollaborate with engineering teams to execute against the vision and roadmap\nWork closely with designers and product managers to distill complex business problems into elegant technical solutions. \nBe part of a close-knit engineering team that ships new code with every PR, every day. \nGeek out about supply-chain, shipping and logistics. (We do this often.)\n\n\nYou should have:\n\n\n1+ years experience writing software and a strong engineering background. \nA love of simple, well-tested code that is easy to extend and hard to break. \nAbility to convey technical ideas in common terms to business stakeholders, product managers, and engineers alike. \nA self-starter attitude. When you see a problem, you solve it. \nKnowledge of at least one programming language such as Typescript, Java, or JS. \n\n\nOur Stack:\n\nOur continuous releases are integrated with Buildkite and Github. On the frontend, we create our views with React, manage data flow with redux, and test our application with Jest. On the backend, it is in Node.js, typescript and Java. Our data persisted in mostly RDS and Algolia. Our stack is hosted on AWS using Docker.\n\nCulture and Values:\n\nOur mission is to make global trade easy for everyone.\n\nTo do so, we operate by our six Flexport values:\n\n\nEmpower Your Client - Reinvigorate customer obsession\nStrengthen Feedback Loops - Seek truth and build trust\nDrive Agility - Unlock faster, more effective operations\nThink From End-to-End - Connect your work to the wider network\nDive Deep - Sweat the details\nPlay the Long Game - Keep the (really) big picture in mind\n\n\nIn the process, we support communities in need and a sustainable environment. Flexport.org is the humanitarian and sustainability arm of Flexport and works with nonprofit and for-profit partners to address environmental and social issues, both globally and locally. Our programs focus on crisis relief, reducing global carbon emissions, low-cost global freight forwarding solutions for nonprofits, and community engagement.\n\nWant to tackle global challenges that have an impact on business, society, and the environment? Come join us.\n\nWorried about not having any logistics experience?\n\n\nDont be! Were building the first Operating System for Global Trade. Thats why its incredibly important for us to bring people from diverse backgrounds and experiences together with our industry veterans to help move the freight forwarding industry forward. \nWhats freight forwarding and why does it matter? Freight forwarding is the coordination and shipment of goods from one place to another and its what makes global trade possible. Flexport is on a mission to make global trade easier for everyone because we believe it can help connect the world and break down economic barriers. \nWe know this industry is complex. Thats why we invest in education starting day one with Flexport Academy, a one-week intensive onboarding program designed specifically to set every new Flexport employee up for success. \n\n\nCommitment to Equal Opportunity\n\nAt Flexport, our ability to fulfill our mission of making global commerce easy and accessible relies on having a diverse, dedicated and engaged workforce. All qualified applicants will receive consideration for employment regardless of race, color, religion, sex, national origin, age, physical and mental disability, health status, marital and family status, sexual orientation, gender identity and expression, military and veteran status, and any other characteristic protected by applicable law.\n\nGlobal Data Privacy Notice for Job Candidates and Applicants\n\nDepending on your location, the General Data Protection Regulation (GDPR) and California Consumer Privacy Act (CCPA) may regulate the way we manage the data of job applicants. By submitting your application, you are agreeing to our use and processing of your data as required. Please see our Privacy Notice available at www.flexport.com/privacy for additional information.\n\n",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4266012660": {
    "job_url": "https://www.linkedin.com/jobs/view/4266012660",
    "job_summary": "Full Stack Engineer\nFull Stack Engineer\nFortinet\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout the Role:\n\n\n\n\nWe are looking for a Full-Stack Engineer with strong backend engineering skills and working knowledge of frontend technologies. This role is ideal for someone passionate about system-level programming, microservices, and backend infrastructure, but is also comfortable working across the stack when needed.\n\nYou will play a critical role in developing robust, scalable software solutions and contributing to the product architecture and design.\n\n\n\n\nKey Responsibilities:\n\nDesign and develop scalable backend services using GoLang, C/C++.\nBuild and maintain microservices in containerised environments using Docker, Kubernetes, etc.\nWork with SQL databases to design schemas, write efficient queries, and optimise performance.\nWrite and maintain shell scripts for automation and operational tooling on Linux.\nApply solid knowledge of data structures and algorithms to solve complex technical problems.\nDevelop clean, responsive UI components using JavaScript, HTML, CSS, and modern frontend frameworks (e.g., Angular or React).\nCollaborate closely with frontend developers, product managers, and DevOps to deliver end-to-end features.\nDebug issues across the stack, especially within Linux-based systems.\n\n\n\n\nRequired Skills:\n\n\n\n\n4 to 8 years of relevant experience.\nProgramming experience in GoLang, C/C++.\nProficiency in JavaScript for frontend work.\nExperience with frontend frameworks like Angular or React.\nHands-on experience with microservices architecture, Docker, and/or Kubernetes.\nProficient in SQL database design and query optimisation.\nExcellent understanding of data structures and algorithms.\nExperience with multithreaded systems and concurrent programming.\nStrong debugging skills in Linux.\nAbility to design clean, modular, and scalable software systems.\nKnowledge of relational database design and best practices.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4257670249": {
    "job_url": "https://www.linkedin.com/jobs/view/4257670249",
    "job_summary": "Python Developer\nPython Developer\nSosuv Consulting\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nWe have an urgent requirement for Python Developers (3-5 years of exp).\n\n\n\n\nJob Description:\n\nOur clients data platform consists of a series of Python microservices, which become integrated through REST and RabbitMQ. We are actively searching for an enthusiastic Core Python Developer to become a valuable member of our vibrant team. The selected individual will play a pivotal role in advancing our platform, making it more feature-rich, robust, streamlined, and performant by employing innovative architectural and development principles. \n\n\n\n\nResponsibilities:\n\nPython Development: \n\nWrite clean, maintainable, and efficient Python code in line with common Pythonic principles. \nDevelop and maintain Python microservices, ensuring seamless integration with our existing platform stack. \nUtilize common Python data libraries, such as Pandas, Polars, NumPy, and SciPy for data manipulation and analysis tasks. \nFamiliarity with asynchronous programming in Python using libraries like asyncio or Dask and understanding of concurrency and parallelism concepts. \nWrite unit tests for developed code using pytest to ensure functionality and reliability. \nCollaborate with the QA team to ensure comprehensive test coverage. \n\n\n\n\nAPI Development & Integration: \n\nDesign and develop RESTful APIs using frameworks like FastAPI and Flask. \nEnsure smooth communication between microservices via REST and message brokers like RabbitMQ. \n\n\n\n\nMessaging/Caching Systems: \n\nUnderstand and work with pub/sub architectures and are familiar with message brokers including RabbitMQ and Kafka. \nImplement and manage caching solutions using Redis to enhance application performance. \n\n\n\n\nVersion Control: \n\nUse Git for source code management, adhering to best practices for branching, merging, and collaborative development. \n\n\n\n\nDatabase Operations:\n\n Work with database technologies such as PostgreSQL and SQLite, understanding schema design, querying, and optimization. \n\n\n\n\nTechnical Skills Required :\n\nBachelors degree in Computer Science, Engineering, or a related field. \n3-5 years minimum as a Python Developer with a solid understanding of the Python language and its best practices, adhering to common Pythonic principles. \nDevelopment experience within the paradigms of microservices, cloud technologies and modern containerization platforms, e.g. AWS, Azure, GCP, Docker, and Kubernetes. \nProficient in implementing and managing Redis as an in-memory data structure store, used for caching, session management, and real-time analytics. \nFamiliarity with Redis data types, such as strings, lists, sets, and hashes, and their appropriate use cases. \nStrong understanding of RabbitMQ as a message broker, facilitating asynchronous processing and inter-service communication. Familiarity with RabbitMQ's exchange types, routing, and queue bindings, and the ability to troubleshoot common RabbitMQ issues. \nProficient in writing tests using libraries like pytest or unit test to ensure code reliability and functionality. \nExperience with Object-Relational Mapping tools like SQLAlchemy or Django ORM, simplifying database operations and queries. \nStrong understanding of relational database concepts, with hands-on experience in designing, querying, and managing data using PostgreSQL, SQLite and Cloud Data Warehouses. Familiarity with normalization, indexing, and optimization techniques to ensure efficient data retrieval and storage. \nExperience in developing applications using frameworks like FastAPI, Flask or Django to simplify tasks like routing, database operations, and security authentication/authorization flows as examples. \n Familiar with tools like Jenkins, Travis CI, or GitHub Actions to automate the building, testing, and deployment of applications throughout the CI/CD lifecycle. \nProactively identify challenges and bottlenecks, employing strong troubleshooting skills to address them. \n\n\n\n\nSoft Skills Required :\n\nStrong verbal and written communication skills. \nEnergetic, self-directed, and comfortable in a fast-paced environment. \nTeam player with good interpersonal skills and quick to learn.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4268200772": {
    "job_url": "https://www.linkedin.com/jobs/view/4268200772",
    "job_summary": "Data Engineer\nData Engineer\nSapaad\nIndia (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nWHO WE ARE\n\nSapaad is a global leader in all-in-one unified commerce platforms, dedicated to delivering world-class software solutions. Its flagship product, Sapaad, has seen tremendous success in the last decade, with thousands of customers worldwide, and many more signing on.\n\n\n\n\nDriven by a team of passionate developers and designers, Sapaad is constantly innovating, introducing cutting-edge features that reshape the industry. Headquartered in Singapore, with offices across five countries, Sapaad is backed by technology veterans with deep expertise in web, mobility, and e commerce, making it a key player in the tech landscape.\n\n\n\n\nTHE OPPORTUNITY\n\nSapaad PTE LTD is seeking a Data Engineer who will take charge of constructing our distributed processing and big data infrastructure, as well as the accompanying applications and tools. We're looking for someone with a fervent drive to tackle intricate data challenges and collaborate closely with the data team, all while staying abreast of the latest features and tools in Big Data and Data Science.\n\n\n\n\nThe successful candidate will play a pivotal role in supporting software developers, data architects, data analysts, and data scientists in various data initiatives. He/She will ensure the smooth and efficient delivery of data across ongoing projects. We require an individual who is self-directed and capable of adeptly managing the data requirements of multiple teams, systems, and products.\n\n\n\n\nROLES AND RESPONSIBILITIES\n\nCreate and maintain optimal data pipeline architecture.\nAssemble large, complex data sets that meet functional / non-functional business requirements.\nIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\nBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS big data technologies.\nBuild analytics tools that utilize the data pipeline to provide actionable insights into key business performance metrics.\nWork with stakeholders including the Executive, Product, Data Architects, and Design teams to assist with data-related technical issues and support their data infrastructure needs.\nTo keep the data separated and secure.\nCreate data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.\nWork with data and analytics experts to strive for greater functionality in our data systems.\n\n\n\n\nROLE REQUIREMENTS\n\nCandidate with 2 to 7 years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, IT or Statistics, or another quantitative field.\nAdvanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.\nExperience building and optimizing big data data pipelines, architectures, and data sets.\nStrong analytic skills related to working with unstructured datasets.\nBuild processes supporting data transformation, data structures, metadata, dependency, and workload management.\nWorking knowledge of message queuing, stream processing, and highly scalable big data data stores.\nGood communication skills and team player.\nExperience supporting and working with cross-functional teams in a dynamic environment.\nPreferred to have experience using the following software/tools:\n\nExperience with big data tools: Hadoop, Spark, Kafka, etc.\n\nExperience with relational SQL and NoSQL databases.\n\nExperience with data pipeline / ETL tools like Informatica, DataStage, and with any cloud tool like Azure Data Factory (ADF), etc.\n\nExperience with data engineering on cloud services like Azure, AWS, or GCP.\n\nExperience with stream-processing systems: Storm, Spark-Streaming, etc.\n\nExperience with object-oriented/object function scripting languages: Python, Java, Scala, etc.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4266129363": {
    "job_url": "https://www.linkedin.com/jobs/view/4266129363",
    "job_summary": "Senior Software Engineer\nSenior Software Engineer\nOptym\nBangalore Urban, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nCompany Overview\n\nFounded in 2000,Optym is building SaaS solutions for the transportation and logistics industry and making it more efficient. Optyms software solutions are used by leading railroads, airlines and trucking companies, and have created a cumulative business value of over $1 billion for its clients. With its headquarters based in Dallas,Texas, and centers of excellence located in Europe and India, Optyms team consists of 250+ professionals. Optym has about 50 highly specialized professionals in US and is expecting a major growth in the next five years. Optym is looking for brilliant, highly qualified and well-educated Senior Software Engineer to assist in building Optimization and AI/ML solutions for the transportation and logistics industry.\n\n\n\n\nOptym offers competitive wages, excellent benefits,a great working environment, and the culture of entrepreneurship and ownership. Optym offers a generous profit and equity sharing plan with the potential to increase your compensation substantially salary based on the success of Optym.\n\n\n\n\nOptym (http://www.optym.com) currently has presence in India by way of Development Center located at Bengaluru, which works on complex technology and operations challenges that directly drive business. We are expanding our Indias operations and scouting out for top talent to become a part of growing organisation.\n\n\n\n\nRole: Senior Software Engineer - Node.js\n\n\n\n\nResponsibilities:\n\nDetermines technical feasibility of medium to low complexity features or solutions by evaluating the problem,customer requirements, possible solutions, and technology requirements.\nExercises judgement in prioritising tasks and selecting methods and techniques for obtaining\n\n solutions.\n\nCreates a low-level design of modules of a software application through proper documentation and diagrams.\nDevelops software solutions by studying requirements, clarifying customer/user needs, analysing data and processes, and following established software development practices and processes.\nUpdates and shares knowledge by studying state-of-the-art development tools, programming\n\n techniques, and computing technology.\n\nGuides junior team members about coding and best practices.\n\n\n\n\nRequirements:\n\nB.Tech/B.S. or M.Tech/M.S. in Computer Science, IT or related field.\nExperience 4+ years\n\n\n\n\nMandatory Skills\n\nExcellent Aptitude\nShould be proficient in the following areas of NodeJS20.0 and above\n\n * Experience with the framework like Express JS, Nest JS or equivalent\n\n * Expert in JavaScript/Typescript\n\n * Parallel and Asynchronous programming\n\n * Debugging/troubleshooting in NodeJS\n\nShould have experience in NoSQL DB, preferably DynamoDB.\nShould have worked on Serverless Architecture, using Lambda\nShould have the following designskills\n\n * OOPs\n\n * Proficiency in Design Patterns,Unit testing patterns\n\nUnderstanding of Algorithms and Data structures.\nFamiliarity with unit testing frameworks\nHave worked on Graph QL\nHave worked on WebSockets\nExperience in Requirement/Design/Code Review& Inspections\nHands-on experience with using Git (handling branchingand merging)\nOutstanding interpersonal and communication skills\n\n\n\n\nDesirable Skills:\n\nExperience with Agile methodologies\nDomain Driven Design\nExperience with event-driven architectures using tools such as AWS Event Bridge, Amazon Kinesis, and Kibana for monitoring and analysis.\nES6/7, Node, package management /webpack/parcel.\n\n\n\n\nLocation: Whitefield, Bengaluru",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4267972057": {
    "job_url": "https://www.linkedin.com/jobs/view/4267972057",
    "job_summary": "Software Engineer (Routing Protocols)\nSoftware Engineer (Routing Protocols) with verification\nArista Networks\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nEasy Apply",
    "job_details": "About the job\n\nCompany Description\n\nArista Networks is an industry leader in data-driven, client-to-cloud networking for large data centers, campus, and routing environments. Arista is a well-established and profitable company with over $7 billion in revenue. Aristas award-winning platforms, ranging in Ethernet speeds up to 800G bits per second, redefine scalability, agility, and resilience. Arista is a founding member of the Ultra Ethernet consortium. We have shipped over 20 million cloud networking ports worldwide with CloudVision and EOS, an advanced network operating system. Arista is committed to open standards, and its products are available worldwide directly and through partners.\n\nAt Arista, we value the diversity of thought and perspectives each employee brings. We believe fostering an inclusive environment where individuals from various backgrounds and experiences feel welcome is essential for driving creativity and innovation.\n\nOur commitment to excellence has earned us several prestigious awards, such as the Great Place to Work Survey for Best Engineering Team and Best Company for Diversity, Compensation, and Work-Life Balance. At Arista, we take pride in our track record of success and strive to maintain the highest quality and performance standards in everything we do.\n\nJob Description\n\nWho Youll Work With\n\nArista Networks is looking for world-class software engineers to join our IP Routing Protocols development team. As a core member of the IP Routing Protocols team, you will be part of a fast paced, high caliber team building routing protocol software to run the world's largest data center networks. Your software will be a key component of Arista's Extensible Operating System (EOS), Arista's unique, Linux-based network operating system that runs on all of Arista's data center networking products.\n\nThe Routing Protocols team is responsible for all aspects of the development and delivery of our routing protocol software. You will work with your fellow engineers and members of the marketing team to gather functional and technical requirements for upcoming projects. You will write functional specifications, design specifications, test plans, and the code to bring all of these to life. You will also work with customers to triage and fix problems in their networks. Internally, you will develop automated tests for your software, monitor the execution of those tests, and triage and fix problems found by your tests. At Arista, you will own your projects from definition to deployment, and you will be responsible for the quality of everything you deliver.\n\nWhat Youll Do\n\nThis role demands a strong and broad software engineering background, and good understanding of IP routing protocols, how they are implemented, and the networks in which they are used. Your role will not be limited to a single aspect of IP routing at Arista, but cover all of our unicast and multicast protocols for both IPv4 and IPv6.\n\nResponsibilities\n\n\nWrite functional specifications and design specifications for small-sized routing protocol features.\nIndependently implement solutions to small-sized problems in our routing protocol software, using the C, C++, and python programming languages.\nWrite test plan specifications for small-sized routing protocol features, and implement automated test programs to execute the cases described in the test plan.\nDebug problems found by our automated test programs and fix the problems.\nWork on a team implementing, testing, and debugging solutions to larger routing protocol problems.\nWork with Customer Support Engineers to analyze problems in customer networks and provide fixes for those problems when needed in the form of new software releases or software patches.\nWork with the System Test Engineers to analyze problems found in their tests and provide fixes for those problems.\nMentor new and junior engineers to bring them up to speed in Arista's software development environment.\nReview and contribute to the specifications and implementations written by other team members.\nHelp to create a schedule for the implementation and debugging tasks, update that schedule weekly, and report it to the project lead.\n\n\nQualifications\n\n\nB.Tech, M.Tech or Ph.D. in Computer Science/Electrical Engineering/Computer Engineering with 2-8 years of related work experience\nKnowledge of C or C++\nKnowledge of UNIX or Linux\nUnderstanding of IP networking and IP routing protocols, specifically one of RIP, OSPF, BGP, IS-IS, or PIM.\nHands-on experience in the design and development of IP routing protocol or distributed systems software.\nHands-on experience with enterprise or service provider class, Ethernet switch/router system software development, or significant PhD-level research in the area of network routing and packet forwarding.\nApplied understanding of software engineering principles\nStrong problem-solving and software troubleshooting skills.\nAbility to design a solution to a small-sized problem and implement that solution without outside help. Able to work on a small team solving a medium-sized problem with limited oversight\n\n\nAdditional Information\n\nArista stands out as an engineering-centric company. Our leadership, including founders and engineering managers, are all engineers who understand sound software engineering principles and the importance of doing things right.\n\nWe hire globally into our diverse team. At Arista, engineers have complete ownership of their projects. Our management structure is flat and streamlined, and software engineering is led by those who understand it best. We prioritize the development and utilization of test automation tools.\n\nOur engineers have access to every part of the company, providing opportunities to work across various domains. Arista is headquartered in Santa Clara, California, with development offices in Australia, Canada, India, Ireland, and the US. We consider all our R&D centers equal in stature.\n\nJoin us to shape the future of networking and be part of a culture that values invention, quality, respect, and fun.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4270673435": {
    "job_url": "https://www.linkedin.com/jobs/view/4270673435",
    "job_summary": "Software Engineer(C++, STL, Data Structures)\nSoftware Engineer(C++, STL, Data Structures) with verification\ninsightsoftware\nBengaluru, Karnataka, India\n1 company alum works here\n1 Walmart Global Tech India company alum works here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob Description\n\nWe are looking for a C++ Software Engineer for our software development team. Apart from writing high quality code, you will be responsible for key deliverables during your teams software development lifecycle including software design, code reviews, and comprehensive automated tests. The successful candidate will have a passion for continuous improvement and must have excellent written and verbal communication skills. You will also be writing Java code for connectivity solutions.\n\nResponsibilities \n\n\nDevelop maintain and improve software\nManage individual project priorities, deadlines and deliverables\nContribute improvements to our continuous delivery infrastructure\nParticipate in recruiting and mentoring of top engineering talent\nDrive roadmap execution and enhance customer feedback into the product\nDevelop, collaborate on, and execute Agile development, product scenarios, in order to release high quality software on a regular cadence \nProactively assist your team to find and solve development and production software issues through effective collaboration \n\n\nDesirable - \n\n\nContributing to performance testing & various continuous improvement efforts.\nStrong OS, Data structure and Algorithms fundamentals\nStrong hold on object-oriented programming concepts and their implementation through C++.\nExperience developing database technologies extremely valuable\nExperience with low-level C and networking is desired, but not necessary.\nExperience programming database APIs such as ODBC and using database tools strongly preferred\nExperience using BI tools such Tableau, Microsoft Power BI and Lumira desirable but not mandatory.\nExperience using any memory and performance profiling tools is required\nExperience working with Agile methodology i.e Participating in all team activities, including sprint retrospectives, thoughtful code reviews, knowledge sharing sessions, status reporting for project stakeholders, etc\n\n\nPersonal Skills -\n\n\nStrong written and verbal communications skills to collaborate developers, testers, product owners, scrum masters, directors, and executives\nExperience taking part in the decision-making process in application code design, solution development, code review \nStrong worth ethic and emotional intelligence including being on time for meetings \nAbility to work in fast-changing environment and embrace change while still following a greater plan\n\n\nQualifications\n\nWe are looking for a C++ Software Engineer for our software development team. Apart from writing high quality code, you will be responsible for key deliverables during your teams software development lifecycle including software design, code reviews, and comprehensive automated tests. The successful candidate will have a passion for continuous improvement and must have excellent written and verbal communication skills. You will also be writing Java code for connectivity solutions.\n\nAdditional Information\n\nAll your information will be kept confidential according to EEO guidelines.\n\n** At this time insightsoftware is not able to offer sponsorship to candidates who are not eligible to work in the country where the position is located. **\n\ninsightsoftware About Us: Hear From Our Team - InsightSoftware (wistia.com)\n\nBackground checks are required for employment with insightsoftware, where permitted by country, state/province.\n\nAt insightsoftware, we are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, national origin, gender, sex, gender identity or expression, sexual orientation, age, citizenship, marital or parental status, disability, veteran status, or other class protected by applicable law. We are proud to be an equal opportunity workplace.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4269381218": {
    "job_url": "https://www.linkedin.com/jobs/view/4269381218",
    "job_summary": "Python Software Engineer\nPython Software Engineer\nWeekday AI (YC W21)\nIndia (Remote)\n\u20b950K/yr - \u20b91.4M/yr\nViewed\nEasy Apply",
    "job_details": "About the job\n\nThis role is for one of Weekday's clients\n\nSalary range: Rs 50000 - Rs 1350000 (ie INR 0.50-13.5 LPA)\n\nMin Experience: 5 years\n\nLocation: Remote (India)\n\nJobType: full-time\n\nRequirements\n\nWe are looking for a skilled and experienced Python Developer with strong expertise in SQL to join our growing team. As a Python Developer, you will be responsible for developing backend components, connecting applications with third-party services, and supporting front-end developers by integrating their work with the Python application. Strong SQL skills are essential for managing large datasets and writing complex queries for data extraction and transformation.\n\nKey Responsibilities:\n\n\nDevelop and maintain backend components and services using Python\nWrite efficient and reusable Python code\nDesign and optimize SQL queries and manage relational databases\nWork with large datasets and perform ETL operations\nCollaborate with front-end developers, data engineers, and analysts to integrate user-facing elements\nTroubleshoot and debug applications and database issues\nEnsure data security, quality, and integrity in all solutions\nParticipate in code reviews and follow best development practices\nWrite documentation and technical specifications as needed\n\n\nRequired Skills: \n\n\n5+ years of professional experience as a Python Developer\nStrong proficiency in SQL (Joins, Stored Procedures, Triggers, Optimization)\nExperience with relational databases like PostgreSQL, MySQL, or SQL Server\nFamiliarity with Python libraries like Pandas, NumPy, SQLAlchemy, etc\nKnowledge of REST APIs and JSON/XML data structures\nExperience with version control systems such as Git\nUnderstanding of Agile development methodologies\nExcellent problem-solving and communication skills",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4270617476": {
    "job_url": "https://www.linkedin.com/jobs/view/4270617476",
    "job_summary": "Software Engineer, Platform - Core Automation\nSoftware Engineer, Platform - Core Automation with verification\nCoinbase\nIndia (Remote)\n20 company alumni work here\n20 Walmart Global Tech India company alumni work here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nReady to be pushed beyond what you think youre capable of?\n\nAt Coinbase, our mission is to increase economic freedom in the world. Its a massive, ambitious opportunity that demands the best of us, every day, as we build the emerging onchain platform  and with it, the future global financial system.\n\nTo achieve our mission, were seeking a very specific candidate. We want someone who is passionate about our mission and who believes in the power of crypto and blockchain technology to update the financial system. We want someone who is eager to leave their mark on the world, who relishes the pressure and privilege of working with high caliber colleagues, and who actively seeks feedback to keep leveling up. We want someone who will run towards, not away from, solving the companys hardest problems.\n\nOur work culture is intense and isnt for everyone. But if you want to build the future alongside others who excel in their disciplines and expect the same from you, theres no better place to be.\n\nWhile many roles at Coinbase are remote-first, we are not remote-only. In-person participation is required throughout the year. Team and company-wide offsites are held multiple times annually to foster collaboration, connection, and alignment. Attendance is expected and fully supported.\n\n \n\nThe mission of the Platform Product Group engineers is to build a trusted, scalable and compliant platform to operate with speed, efficiency and quality. Our teams build and maintain the platforms critical to the existence of Coinbase. There are many teams that make up this group which include Product Foundations (i.e. Identity, Payment, Risk, Proofing & Regulatory, Finhub), Machine Learning, Customer Experience, and Infrastructure.\n\nThe Core Automation Team is a highly driven and innovative group dedicated to developing AI infrastructure and automation solutions that enhance productivity, foster innovation, and create meaningful customer impact across Coinbase. Our mission is to streamline operations for customer support and compliance teams while delivering exceptional customer experiences. As a Software Engineer on our team, you will play a key role in this transformation, utilizing state-of-the-art AI models, frameworks, and tools, along with diverse and extensive data sources, including blockchain data. Your work will focus on breaking down barriers to cryptocurrency adoption and shaping the future of AI-powered customer interactions.\n\n \n\nWhat youll be doing (ie. job duties):\n\nExplore and apply advanced GenAI techniques, including large language models (LLMs) and Agentic AI, to solve complex challenges across the organization.\nExcel at project execution by managing priorities, deadlines, and deliverables, leveraging your technical expertise.\nWrite high-quality, well-tested code in Python and Golang to address critical product and business needs.\nBuild scalable, secure systems using modern cloud technologies and industry best practices.\nDebug complex technical issues to enhance system reliability, scalability, and ease of operation.\nReview and ensure the security, scalability, and architectural integrity of feature designs across teams.\nBuild pipelines to integrate with third-party vendors and streamline workflows.\n\n \n\nWhat we look for in you (ie. job requirements):\n\n3+ years of experience in software engineering.\nProven expertise in designing, building, scaling, and maintaining production services, with a strong understanding of micro-services architecture.\nAbility to write high-quality, well-tested code that meets customer needs.\nDeep understanding of what high-quality code and software engineering processes look like, and the ability to foster an environment that promotes them.\nStrong technical skills in system design and coding.\nPassion for building an open financial system that unites the world.\nExcellent written and verbal communication skills, with a preference for open and transparent cultural practices.\n\n \n\nNice to haves:\n\nExperience navigating rapid company growth (e.g., from startup to mid-size).\nFamiliarity with GenAI frameworks/tools, Python, GoLang, Docker, Postgres, MongoDB.\nBackground in AI/LLM infrastructure is a strong plus.\n\n \n\nJob Id : GPBE04IN\n\n*Answers to crypto-related questions may be used to evaluate your onchain experience.\n\n \n\nPlease be advised that each candidate may submit a maximum of four applications within any 30-day period. We encourage you to carefully evaluate how your skills and interests align with Coinbase's roles before applying.\n\nCommitment to Equal Opportunity\n\nCoinbase is proud to be an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, gender, national origin, age, disability, veteran status, sex, gender expression or identity, sexual orientation or any other basis protected by applicable law. Coinbase will also consider for employment qualified applicants with criminal histories in a manner consistent with applicable federal, state and local law. For US applicants, you may view the Employee Rights and the Know Your Rights notices by clicking on their corresponding links. Additionally, Coinbase participates in the E-Verify program in certain locations, as required by law. \n\nCoinbase is also committed to providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process, please contact us at accommodations[at]coinbase.com to let us know the nature of your request and your contact information. For quick access to screen reading technology compatible with this site click here to download a free compatible screen reader (free step by step tutorial can be found here).\n\nGlobal Data Privacy Notice for Job Candidates and Applicants\n\nDepending on your location, the General Data Protection Regulation (GDPR) and California Consumer Privacy Act (CCPA) may regulate the way we manage the data of job applicants. Our full notice outlining how data will be processed as part of the application procedure for applicable locations is available here. By submitting your application, you are agreeing to our use and processing of your data as required. For US applicants only, by submitting your application you are agreeing to arbitration of disputes as outlined here. \n\nAI Disclosure\n\nFor select roles, Coinbase is piloting an AI tool based on machine learning technologies to conduct initial screening interviews to qualified applicants. The tool simulates realistic interview scenarios and engages in dynamic conversation. A human recruiter will review your interview responses, provided in the form of a voice recording and/or transcript, to assess them against the qualifications and characteristics outlined in the job description. \n\nFor select roles, Coinbase is also piloting an AI interview intelligence platform to transcribe and summarize interview notes, allowing our interviewers to fully focus on you as the candidate. \n\nThe above pilots are for testing purposes and Coinbase will not use AI to make decisions impacting employment. To request a reasonable accommodation due to disability, please contact accommodations@coinbase.com.\n\n \n\n ",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4255006226": {
    "job_url": "https://www.linkedin.com/jobs/view/4255006226",
    "job_summary": "Software Engineer\nSoftware Engineer with verification\nDigiCert\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nWho we are\n\n\n\n\nWe're a leading, global security authority that's disrupting our own category. Our encryption is trusted by the major ecommerce brands, the world's largest companies, the major cloud providers, entire country financial systems, entire internets of things and even down to the little things like surgically embedded pacemakers. We help companies put trust - an abstract idea - to work. That's digital trust for the real world.\n\n \n\n \n\n\n\n\nJob summary\n\n\n\n\nThe DigiCert ONE CA team is looking for a knowledgeable front-end engineer to join our agile cross functional team to build the future of PKI and security management.\n\n\n\n\n \n\n\n\n\nWhat you will do\n\n\n\n\n\nBuild beautiful, engaging interfaces using React\n\n\nCollaborate with the team in the design, development, testing, and deployment of high-quality code\n\n\nEngage with other engineering leaders to implement industry best practices\n\n\nAnalyze, troubleshoot, and debug product defects and provide timely solutions to customer needs\n\n\nDevelop a deep understanding of PKI products, architecture, and systems\n\n\n\n\n\n \n\n\n\n\nWhat you will have\n\n\n\n\n\n2+ years of professional experience in the engineering industry\n\n\nExpertise in development using a UI framework like React or Vue\n\n\nDemonstrated ability develop engaging user interfaces on the web\n\n\nSamples of work showing proficiency in creating web frontends\n\n\nKnowledge of software engineering best-practices, design, and architecture\n\n\nPassionate about good testing practices and building high quality software\n\n\nStrong interpersonal communication skills\n\n\n\n\n\n \n\n\n\n\nNice to have\n\n\n\n\n\nBachelors degree in Computer Science, Information Systems, etc., or equivalent years of experience in the industry\n\n\nExperience with service-based architectures and distributed systems\n\n\nUnderstanding of SSL/TLS, PKI, and other security related technologies\n\n\nTechnologies we use, any experience is a bonus: Go; MySQL; Docker and Kubernetes; Jira; Git and GitHub\n\n\n\n\n\n \n\n\n\n\nBenefits\n\n\n\n\n\nGenerous time off policies\n\n\nTop shelf benefits\n\n\nEducation, wellness and lifestyle support\n\n\n\n\n\n \n\n\n\n\n\n__PRESENT",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4267671974": {
    "job_url": "https://www.linkedin.com/jobs/view/4267671974",
    "job_summary": "Cloud Data Engineer\nCloud Data Engineer with verification\nLemongrass\nIndia (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout Lemongrass\n\nLemongrass is a software-enabled services provider, synonymous with SAP on Cloud, focused on delivering superior, highly automated Managed Services to Enterprise customers. Our customers span multiple verticals and geographies across the Americas, EMEA and APAC. We partner with AWS, SAP, Microsoft and other global technology leaders.\n\n\n\n\nWe are seeking an experienced Cloud Data Engineer with a strong background in AWS, Azure, and GCP. The ideal candidate will have extensive experience with cloud-native ETL tools such as AWS DMS, AWS Glue, Kafka, Azure Data Factory, GCP Dataflow, and other ETL tools like Informatica, SAP Data Intelligence, etc. You will be responsible for designing, implementing, and maintaining robust data pipelines and building scalable data lakes. Experience with various data platforms like Redshift, Snowflake, Databricks, Synapse, Snowflake and others is essential. Familiarity with data extraction from SAP or ERP systems is a plus.\n\n\n\n\nKey Responsibilities:\n\nDesign and Development:\n\nDesign, develop, and maintain scalable ETL pipelines using cloud-native tools (AWS DMS, AWS Glue, Kafka, Azure Data Factory, GCP Dataflow, etc.).\nArchitect and implement data lakes and data warehouses on cloud platforms (AWS, Azure, GCP).\nDevelop and optimize data ingestion, transformation, and loading processes using Databricks, Snowflake, Redshift, BigQuery and Azure Synapse.\nImplement ETL processes using tools like Informatica, SAP Data Intelligence, and others.\nDevelop and optimize data processing jobs using Spark Scala.\n\n\n\n\nData Integration and Management:\n\nIntegrate various data sources, including relational databases, APIs, unstructured data, and ERP systems into the data lake.\nEnsure data quality and integrity through rigorous testing and validation.\nPerform data extraction from SAP or ERP systems when necessary.\n\n\n\n\nPerformance Optimization:\n\nMonitor and optimize the performance of data pipelines and ETL processes.\nImplement best practices for data management, including data governance, security, and compliance.\n\n\n\n\nCollaboration and Communication:\n\nWork closely with data scientists, analysts, and other stakeholders to understand data requirements and deliver solutions.\nCollaborate with cross-functional teams to design and implement data solutions that meet business needs.\n\n\n\n\nDocumentation and Maintenance:\n\nDocument technical solutions, processes, and workflows.\nMaintain and troubleshoot existing ETL pipelines and data integrations.\n\n\n\n\nQualifications\n\n\n\n\nEducation:\n\nBachelors degree in Computer Science, Information Technology, or a related field. Advanced degrees are a plus.\n\n\n\n\nExperience:\n\n7+ years of experience as a Data Engineer or in a similar role.\nProven experience with cloud platforms: AWS, Azure, and GCP.\nHands-on experience with cloud-native ETL tools such as AWS DMS, AWS Glue, Kafka, Azure Data Factory, GCP Dataflow, etc.\nExperience with other ETL tools like Informatica, SAP Data Intelligence, etc.\nExperience in building and managing data lakes and data warehouses.\nProficiency with data platforms like Redshift, Snowflake, BigQuery, Databricks, and Azure Synapse.\nExperience with data extraction from SAP or ERP systems is a plus.\nStrong experience with Spark and Scala for data processing.\n\n \n\nSkills:\n\n Strong programming skills in Python, Java, or Scala.\n Proficient in SQL and query optimization techniques.\n Familiarity with data modeling, ETL/ELT processes, and data warehousing concepts.\n Knowledge of data governance, security, and compliance best practices.\nExcellent problem-solving and analytical skills.\nStrong communication and collaboration skills.\n\n\n\n\nPreferred Qualifications:\n\nExperience with other data tools and technologies such as Apache Spark, or Hadoop.\nCertifications in cloud platforms (AWS Certified Data Analytics  Specialty, Google Professional Data Engineer, Microsoft Certified: Azure Data Engineer Associate).\nExperience with CI/CD pipelines and DevOps practices for data engineering\nSelected applicant will be subject to a background investigation, which will be conducted and the results of which will be used in compliance with applicable law.\n\n\n\n\nWhat we offer in return:\n\nRemote Working: Lemongrass always has been and always will offer 100% remote work\nFlexibility: Work where and when you like most of the time\nTraining: A subscription to A Cloud Guru and generous budget for taking certifications and other resources youll find helpful\nState of the art tech: An opportunity to learn and run the latest industry standard tools\nTeam: Colleagues who will challenge you giving the chance to learn from them and them from you\n\n\n\n\nLemongrass Consulting is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate on the basis of race, religion, color, national origin, religious creed, gender, sexual orientation, gender identity, gender expression, age, genetic information, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4270710441": {
    "job_url": "https://www.linkedin.com/jobs/view/4270710441",
    "job_summary": "Software Engineer Backend (SDE 4)\nSoftware Engineer Backend (SDE 4)\nArcana\nBangalore Urban, Karnataka, India (On-site)\n3 school alumni work here\n3 Indian Institute of Technology (Banaras Hindu University), Varanasi school alumni work here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJoin our dynamic team at the forefront of cutting-edge technology as we seek a seasoned Senior Backend Engineer. Embark on a journey where your deep-rooted expertise in computer science fundamentals, alongside an intricate understanding of data structures, algorithms, and system design, becomes the cornerstone of innovative solutions. This pivotal role not only demands your proficiency in developing and elevating compute and I/O-intensive applications but also ensures their peak performance and unwavering reliability.\n\n\n\n\nResponsibilities:\n\nArchitect, refine, and escalate the capabilities of complex backend systems using Python, with a laser focus on efficiency, durability, and scale.\nElevate application performance, optimizing for speed, scalability, and resource allocation.\nForge robust methodologies to manage high concurrency and vast data volumes, setting new industry benchmarks.\nCollaborate intimately with engineering and product peers to crystallize requirements into resilient, scalable architectures.\nDemonstrate proficiency with advanced storage solutions and databases like Redis, PostgreSQL, and ClickHouse, enhancing system integrity.\nChampion coding excellence, testing rigor, and deployment precision, driving best practices across the development lifecycle.\n\nRequirements:\n\nBachelor's or Master's degree in Computer Science, Engineering, or a related field.\nMinimum of 6 years of experience in backend development with Python in a production environment.\nProven experience in scaling compute and I/O-intensive applications.\nStrong foundation in computer science, with a deep understanding of data structures, algorithms, and system design principles.\nExperience in handling concurrent requests at scale and optimizing large-scale systems for performance and reliability.\nFamiliarity with database technologies such as Redis, PostgreSQL, and ClickHouse.\nExperience in the financial sector, particularly in developing fintech applications or systems, is a plus.\nSolid understanding of software development life cycle, continuous integration, and continuous delivery (CI/CD) practices.\n\nExcellent problem-solving abilities and strong communication skills.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4266892943": {
    "job_url": "https://www.linkedin.com/jobs/view/4266892943",
    "job_summary": "Python Developer\nPython Developer\nBrace Infotech Private Ltd\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nEasy Apply",
    "job_details": "About the job\n\nCompleted Bachelors degree or diploma (or equivalent experience) in Computer Science, Software Engineering or Software Architecture preferred; candidates with substantial and relevant industry experience are also eligible\n6-10 years of engineering experience\nAbility to learn, understand, and work quickly with new emerging technologies, methodologies, and solutions in the Cloud/IT technology space\nAdvanced understanding of web technologies (HTTP, SSL, Headers, Cookies, TCP, Caching)\nKnowledge of CI/CD principles and best-practices.\nExperience working with bug tracking and task management software such as JIRA, Bugzilla, etc.\nExperience developing solutions for retail or eCommerce businesses and other relevant domains such as manufacturing & logistics, supply chain, or corporate shared services\nAbility to assume the leadership/mentorship of Engineers\nExperience with modern front-end frameworks such as React, Angular\nProficiency in Python for building backend services, automation, and API development\nExperience with integrating or extending SaaS platforms (e.g. Backstage)\nExperience with AWS cloud and IAC knowledge (Terraform)\nExperience with day-to-day tools such as Jira, PagerDuty, ServiceNow is nice to have\n\nMust Haves:\n\nAcknowledge the presence of choice in every moment and take personal responsibility for your life.\nPossess an entrepreneurial spirit and continuously innovate to achieve great results. \nCommunicate with honesty and kindness and create the space for others to do the same. \nLead with courage, knowing the possibility of greatness is bigger than the fear of failure. \nFoster connection by putting people first and building trusting relationships. \nIntegrate fun and joy as a way of being and working, aka doesnt take yourself too seriously.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4268058513": {
    "job_url": "https://www.linkedin.com/jobs/view/4268058513",
    "job_summary": "Senior Back End Engineer\nSenior Back End Engineer with verification\nHDFC Bank\nBangalore Urban, Karnataka, India (On-site)\n9 school alumni work here\n9 Indian Institute of Technology (Banaras Hindu University), Varanasi school alumni work here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob Purpose \n\nUnderstand the requirement in detail and perform engineering tasks on developing APIs, Microservices and other related batch activities.\n\n\n\n\nJob Responsibilities:\n\nResponsible for developing microservices and batch programs meeting quality and timeliness goals. \nEnsure adequate documentation included in code for future maintainability \nContinuously develop self in line with improvements / changes in backend technology \nParticipate in daily scrums \nDevelop identified user stories, with considerations of security and code quality \nComplete thorough unit testing \nParticipate in team code review \nDevelop code using best coding practice and adhere to performance, security and compliance metrics\n\n\n\n\nTotal Yrs of experience: 6-12\n\n\n\n\nSkills:  \n\nHands-On coding experience \nJava / J2EE (Professional) \nRestAPI (Professional) \nSpringBoot (Professional) \nCaching (Professional) \nMicroservices (Professional) \n\n \n\n- Atleast 6 year experience developing APIs on Java/J2EE \n\n- Atleast 6 years experience in Java \n\n- Experience with SQL, persistence layer",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4267676680": {
    "job_url": "https://www.linkedin.com/jobs/view/4267676680",
    "job_summary": "Senior Associate- Data Engineer | Working Professional\nSenior Associate- Data Engineer | Working Professional with verification\nupGrad\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nDesignation- Senior Associate- Data Engineer\n\nBU- Working Professional\n\nLocation- Bangalore- AMR Tech Park- WFO\n\nSalary Range- 8LPA- 9 LPA\n\n\n\n\nRequired Skills: Python & Data Engineer.\n\n\n\n\nRole Summary:\n\nThe Data Engineer role offers a unique opportunity to rapidly learn new topics, develop industry-relevant projects, collaborate with top professionals and faculty, coordinate across teams, and directly impact learners' careers. upGrad seeks individuals passionate about education and technology to help design cutting-edge learning programs for working professionals.\n\n\n\n\nRoles & Responsibilities:\n\nUnderstand industry and learner needs to develop high-quality courses.\nManage and coordinate teams to ensure content quality and timely delivery.\nPlan and execute student assessments and engagement strategies.\nConduct research to refine program-market fit.\nDevelop instructional content (videos, assessments, discussions, etc.) with internal teams.\nBuild and maintain a network of subject matter experts and faculty.\nDefine content development processes and improve learning experiences.\nTroubleshoot and optimize content/program challenges post-launch.\n\n\n\n\nMandatory Requirements:\n\nGraduate in STEM (BTech/BE/BCA).\nStrong Python programming skills.\n\n\n\n\nPreferred Skills:\n\nSQL knowledge is a plus.\nPostgraduate (MTech/ME/MCA) preferred.\nTeaching experience (online/offline) preferred.\nInterest in analytics & machine learning.\nExperience in developing and managing digital educational content.\nStrong problem-solving and process structuring skills.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4267064219": {
    "job_url": "https://www.linkedin.com/jobs/view/4267064219",
    "job_summary": "Data Engineer\nData Engineer\nWeekday AI (YC W21)\nBengaluru, Karnataka, India (On-site)\nViewed\nEasy Apply",
    "job_details": "About the job\n\nThis role is for one of the Weekday's clients\n\nMin Experience: 4 years\n\nLocation: Bengaluru\n\nJobType: full-time\n\nRequirements\n\nKey Responsibilities\n\nAs a Data Engineer, you will play a crucial role in designing and maintaining scalable and high-performance data systems. Your responsibilities will include:\n\n\n Data Pipeline Development and Management\n Design, build, test, and maintain efficient data pipelines and data management systems. \n Develop and manage ETL (Extract, Transform, Load) and ELT (Extract, Load, Transform) processes to integrate data from diverse sources such as databases, APIs, and real-time streams. \n Data Modeling and Architecture\n Design data models and implement schemas for data warehouses and data lakes to support analytics and business operations. \n Optimize data storage, access, and performance for scalability and maintainability. \n Data Quality and Integrity\n Implement validation, cleansing, and monitoring to maintain data accuracy, consistency, and reliability. \n Define and enforce best practices and standards for data governance and quality. \n Infrastructure Management\n Manage and monitor key data infrastructure components including databases, data lakes, and distributed computing environments. \n Apply data security protocols and ensure proper access controls are in place. \n Automation and Optimization\n Automate data workflows and pipelines to improve reliability and performance. \n Continuously monitor and fine-tune systems for operational efficiency. \n Collaboration and Support\n Partner with data scientists, analysts, software engineers, and business stakeholders to gather requirements and provide scalable data solutions. \n Document processes, workflows, and system designs; support cross-functional teams with technical guidance. \n Technology Evaluation\n Stay current with emerging tools and technologies in the data engineering space. \n Evaluate and recommend new solutions to enhance data capabilities and performance. \n\n\nEducation And Experience\n\n\n Bachelor's or Master's degree in Computer Science, Engineering, Information Systems, Data Science, or a related field. \n 5 to 7 years of experience in data engineering, software development, or a similar domain. \n\n\nTechnical & Functional Competencies\n\nRequired Skills & Qualifications\n\nTechnical Proficiency\n\n\n Programming: Strong experience in Python and SQL. \n Databases: Proficient in relational (PostgreSQL, MySQL) and NoSQL (MongoDB, Cassandra) databases. \n Data Warehousing & Lakes: Hands-on experience with platforms like Snowflake, Redshift, BigQuery. \n ETL/ELT Tools: Proficiency with tools like Apache Airflow, AWS Glue, Azure Data Factory, Talend. \n Big Data: Working knowledge of Apache Spark or similar big data technologies. \n Cloud Platforms: Experience with AWS, Azure, or GCP for data engineering workflows. \n Data Modeling: Strong understanding of modeling techniques and best practices. \n API Integration: Ability to build and consume APIs for data integration. \n Version Control: Experience with Git or other version control systems. \n\n\nSoft Skills\n\n\n Analytical mindset with a strong problem-solving approach. \n Excellent communication skills for both technical and non-technical audiences. \n Team player with a collaborative work ethic. \n Detail-oriented with a commitment to data quality. \n Adaptability to new technologies and changing project requirements. \n\n\nKey Skills:\n\nETL, Data Modeling, Data Architecture, Cloud Data Platforms, Python, SQL, Big Data, Data Warehousing, API Integration",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4258394718": {
    "job_url": "https://www.linkedin.com/jobs/view/4258394718",
    "job_summary": "PYTHON SOFTWARE ENGINEER\nPYTHON SOFTWARE ENGINEER\nConnext\nIndia (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob Summary: The Python Software Engineer is responsible for designing, developing, and maintaining scalable data pipelines and backend services that facilitate efficient data processing, storage, and access. This role ensures the highest standards of data integrity and reliability by implementing robust systems for data quality and consistency.\n\n\n\n\nJob Description:\n\n Design, develop, and maintain scalable data pipelines and backend services for data processing, storage, and access.\n\n Implement systems for tracking data quality and consistency, ensuring the highest standard of data integrity and reliability.\n\n Collaborate with cross-functional teams to understand data needs and deliver solutions that aid in achieving strategic goals.\n\n Optimize data retrieval, and reports for various user segments, facilitating effective decision-making. Write clean, efficient, and reusable Python code that meets industry standards\n\n Review and improve existing systems, enhancing performance and integrating new features.\n\n Stay current with industry trends and technologies, and apply this knowledge to enhance the businesss technological resources.\n\n\n\n\nRequired Qualifications:\n\n Proficient in Python, with extensive knowledge of FastAPI and other modern frameworks.\n\n Experience with cloud services (Azure) and integrating diverse data sources.\n\n Expertise in SQL and NoSQL database technologies, such as PostgreSQL, MongoDB, etc.\n\n Familiarity with big data tools like Hadoop and Spark, and workflow orchestration tools such as Airflow.\n\n Skilled in designing and implementing RESTful APIs and microservices architecture.\n\n Clear and coherent in both written and verbal communication skills with the ability to convey complex technical concepts to non-technical stakeholders.\n\n Strong problem-solving skills and ability to work in a dynamic, team-based environment. \n\n\n\n\nBachelors or masters degree in computer science, engineering, or a related field.\n\n At least five (5) years of experience as a Python Software Engineer, specifically in data engineering. \n\nMust have a stable employment history.\n\n\n\n\n** Proficiency in the English language is required, Strong command of English is essential. Fluency in English is a mandatory requirement.\n\nExperience: 5 to 7 years\n\n\n\n\nShift Timing: 6.30 PM to 3.30 AM (Monday to Friday)",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4261254948": {
    "job_url": "https://www.linkedin.com/jobs/view/4261254948",
    "job_summary": "Python developer (Bangalore)\nPython developer (Bangalore)\nNaukripay group\nBangalore North Rural, Karnataka, India (On-site)\nViewed\nEasy Apply",
    "job_details": "About the job\n\nmail:- info@naukripay.com\n \nPython Developer is responsible for designing, developing, and maintaining software applications using the Python programming language. This can involve creating web applications, data analysis tools, machine learning models, or automation scripts. They collaborate with teams to understand requirements, write clean and efficient code, and ensure the functionality and performance of applications. \nKey Responsibilities:Coding and Development: Writing well-structured, testable, and efficient Python code for various applications. Back-end Development: Constructing server-side logic, APIs, and database interactions. Web Development: Developing web applications using frameworks like Django or Flask. Data Analysis and Science: Utilizing Python libraries like Pandas and NumPy for data manipulation, analysis, and visualization. Automation: Creating scripts for automating tasks and workflows. Integration: Integrating with front-end components, databases, and third-party services. Testing and Debugging: Ensuring code quality through testing and debugging. Collaboration: Working with other developers, designers, and stakeholders. Staying Updated: Keeping up with the latest Python libraries, frameworks, and best practices. Skills and Qualifications:Proficiency in Python programming language.Experience with Python web frameworks (Django, Flask).Familiarity with databases and data storage solutions.Understanding of software development principles and methodologies.Strong problem-solving and analytical skills.Excellent communication and teamwork skills.Knowledge of testing and debugging tools.Experience with version control systems (e.g., Git).Understanding of front-end technologies (HTML, CSS, JavaScript) is often beneficial.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4239693819": {
    "job_url": "https://www.linkedin.com/jobs/view/4239693819",
    "job_summary": "Software Engineer-C++\nSoftware Engineer-C++ with verification\nIvanti\nBengaluru, Karnataka, India (On-site)\n1 company alum works here\n1 Walmart Global Tech India company alum works here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nWho We Are\n\nIn todays work environment, employees use a myriad of devices to access IT applications and data over multiple networks to stay productive, wherever and however they work. Ivanti elevates and secures Everywhere Work so that people and organizations can thrive.\n\nWhile our headquarters is in the U.S., half of our employees and customers are outside the country. We have 36 offices in 23 nations, with significant offices in London, Frankfurt, Paris, Sydney, Shanghai, Singapore, and other major cities around the world.\n\nIvantis mission is to be a global technology leader enabling organizations to elevate Everywhere Work, automating tasks that discover, manage, secure, and service all their IT assets. Through diverse and inclusive hiring, decision-making, and commitment to our employees and partners, we will continue to build and deliver world-class solutions for our customers.\n\nOur Culture - Everywhere Work Centered Around You\n\nAt Ivanti, our success begins with our people. This is why we embrace Everywhere Work across the globe, where Ivantians and our customers are thriving. We believe in a healthy work-life blend and act on it by fostering a culture where all perspectives are heard, respected, and valued. Through Ivantis Centered Around You approach, our employees benefit from programs focused on their professional development and career growth.\n\nWe align through our core values by locking arms in collaboration, being champions for our customers, focusing on the outcomes that matter most and fighting the good fight against cyber-attacks. Are you ready to join us on the journey to elevate Everywhere Work?\n\nWhy We Need You!\n\nAs a Software Engineer at Ivanti, you will play a pivotal role in enhancing the security of our cutting-edge Network Security products. With a focus on quality, reliability, and scalability, you'll collaborate with a talented team of architects and engineers to tackle complex security challenges. If you're passionate about working with networking protocols, programming in C++, and improving security practices in a dynamic AGILE environment, this role offers the opportunity to make a significant impact while advancing your career. Join us to be at the forefront of innovation in a company dedicated to securing digital assets worldwide.\n\nAbout The Team\n\nIvanti Engineering is a driving force behind transforming market challenges into innovative ideas and successful solutions that resonate with customers and achieve business objectives. By combining market insights, strategic planning, and cross-functional collaboration, the Engineering organization ensures every product release meets evolving user needs and competitive demands. This team is instrumental in developing Ivanti's purpose-built platform for CIOs and CISOs powered by Ivanti Neurons - a cloud-scale, hyperautomation layer that enables proactive healing, user-friendly security across the organization and provides an enhanced user experience. This department plays a pivotal role in shaping the company's growth trajectory through continuous innovation and customer-centric solutions.\n\nWhat You Will Be Doing\n\n\nDesign and develop innovative features to enhance the security of our Network Security products.\nImplement best practices in Quality Assurance and Security throughout all development stages, including unit testing and automation.\nWork collaboratively with architects and software engineers to devise effective solutions for complex security challenges.\nEnsure product reliability, availability, performance, and scalability while maintaining a strong focus on security.\nSupport and maintain existing code, troubleshoot issues in large-scale, complex environments.\nEngage and collaborate with cross-functional teams to drive impactful security initiatives.\nPromote a culture of continuous learning and improvement by sharing knowledge and mentoring junior engineers.\nStay abreast of industry trends and emerging threats to proactively adapt security strategies and solutions.\n\n\nTo Be Successful in The Role, You Will Have\n\n\n2-5 years of hands-on software Engineering experience targeting Linux/Unix applications\nMUST have experience working in Networking Protocols (DHCP, TCP/IP, AAA, RADIUS, LDAP, SNMP, 802.1X, IPSec, SSL/TLS) and various Authentication methods\nMUST have programming experience with C++ and good understanding of Perl and Python\nMUST have good understanding of the Linux Operating System Internals, Linux OS Bring Up, Secure Boot, Bootloader, SELinux\nSignificant PLUS: have experience with triaging & analyzing issues, recommending recommendations and implementing fixes for security vulnerabilities (CVEs and OWASP Top 25 issues)\nSignificant PLUS: Strong understanding of certificates, encryption and Security Tools such as Metasploit, BurpSuite, Nessus, ZAP, Qualys, Blackduck etc.\nExperience working in an AGILE environment and working with a geographically distributed team\n\n\nOur Employer Commitment\n\nThis job posting will remain active until a qualified candidate is identified.\n\nAt Ivanti, we are committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and teammates without regard to race, color, religion, sex, pregnancy (including childbirth, lactation and related medical conditions), national origin, age, physical and mental disability, marital status, sexual orientation, gender identity, gender expression, genetic information (including characteristics and testing), military and veteran status, and any other characteristic protected by applicable law. Ivanti believes that diversity and inclusion among our teammates is critical to our success as a global company, and we seek to recruit, develop and retain the most talented people from a diverse candidate pool.\n\nIf you require special assistance for the best interview experience, please contact us at recruiting@ivanti.com .\n\n",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4243446112": {
    "job_url": "https://www.linkedin.com/jobs/view/4243446112",
    "job_summary": "Backend Developer\nBackend Developer\nAtomicwork\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAtomicwork is on a mission to transform the digital workplace experience by uniting people, processes, and platforms through AI automation. Our team is building a modern service management platform that enables growing businesses to reduce operational complexity and drive business success.\n\nWere looking for an experienced backend engineer to join our team and help us build our modern service management platform. This is based out of our Bengaluru office. We offer competitive pay to employees and practical benefits for their whole family.\n\nIf this sounds interesting to you, read on.\n\n\n\n\nWhat you'll do:\n\nWere looking for experienced individual contributors whove worked on large-scale products before, and we expect you to ramp up quickly and help us launch our products.\n\nBuild the foundations for all things Atomicwork. Develop and maintain complex web applications emphasizing usability, performance, and scalability.\nDesign and build enterprise-grade systems. Implement and maintain high-quality applications and show craftsmanship while coding, testing, and deploying.\nCollaborate with partner teams. Collaborate with cross-functional teams, including design, product management, and backend engineering, to develop and launch new features.\nContinuously improve our platform. Participate in code reviews and provide constructive feedback to other team members.\nStay ahead of the curve. Keep up with emerging trends and technologies in front-end development, and recommend new approaches to improve the user experience.\nSelf-direct your work and co-own the product. You will act like the technical founder of the product and will have autonomy and responsibility to do whats right for the customer.\nSolve interesting technical problems. You will use your creativity and skills to solve challenging technical problems.\n\n\n\n\nWhat we're looking for:\n\n\n\n\nWe do not require any formal qualifications, but we value hands-on skills. We also enjoy working with people looking to learn new things and have a sense of responsibility towards their work.\n\n\n\n\nYou have spent at least three years working on complex, distributed software applications and know how to write them from scratch.\nYou are knowledgeable in Java and Python - understand designing beautiful, functional experiences using React.\nYoull need strong database fundamentals and be comfortable with concepts like caching, query optimization, indexing, etc. Any experience working on MySQL will be preferred.\nYou enjoy working with APIs extensively and are comfortable building scalable platform systems and leveraging existing ones to your advantage.\nYou know your way around Amazon Web Services (AWS) and are comfortable in managing applications on any public cloud infrastructure.\nYou understand the importance of documentation and like presenting your work to your peers before implementing your changes.\nYou arent faced with troubleshooting issues and can patiently debug large codebases without getting frustrated by complexity.\nYou have taken the time to read and understand our cultural values. Most importantly, you are a good person and dont act like a jerk around your teammates\nShould be familiar with Code editors like Cursor.\n\n\n\n\n\n\n\nWhat we offer (compensation and benefits)\n\nWe are big on benefits that make sense to you and your family.\n\nFantastic team the #1 reason why everybody joins us. \nConvenient offices  well-located offices spread over five different cities.\nPaid time off  Unlimited sick leaves and 15 days off every year.\nHealth insurance  comprehensive health coverage upto 75% premium covered.\nFlexible allowances  with hassle-free reimbursements across spends.\nAnnual outings  for everyone to have fun together.\n\n\n\n\nWhy we are different (culture)\n\nAs a part of Atomicwork, you can shape our company and business from idea to production. Our cultural values also set the bar high, helping us create a better workplace for everyone.\n\nAutonomy: We champion self-direction to deliver customer success, empowering teams and individuals to deliver peak performance.\nTrust: We unwaveringly believe in our colleagues' positive intentions, approaching every interaction with trust to accelerate execution.\nOwnership: We demonstrate unwavering commitment to our mission and goals, taking full responsibility for triumphs and setbacks.\nMastery: We relentlessly pursue continuous self-improvement as individuals and teams, dedicating ourselves to constant learning and growth.\nImpatience: We recognize that our world moves swiftly and is driven by an unyielding desire to progress with every endeavor.\nCustomer Obsession: We place our customers at the heart of everything we do, relentlessly seeking to understand their needs and exceed their expectations",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4261695496": {
    "job_url": "https://www.linkedin.com/jobs/view/4261695496",
    "job_summary": "Software Engineer, Backend\nSoftware Engineer, Backend\nSpotnana\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAre you ready for the best destination of your career?\n\nSpotnana is transforming the $11 trillion travel industry by building modern infrastructure that brings freedom, simplicity, and trust to travelers worldwide.\n\nBacked by over $115M in funding from top-tier investors, including ICONIQ, Durable, Mubadala, Madrona, and Sandberg Bernthal Ventures, we are addressing some of the travel industry's most complex challengesand we need your expertise to help us succeed.\n\n \n\nHow youll make an impact\n\nAre you ready to embark on an exciting adventure as a Software Engineer at Spotnana? Join our dynamic team and be a part of a mission-critical project that will propel Spotnana's growth and success! We're seeking versatile engineers with leadership qualities, a passion for problem-solving, and the enthusiasm to take on new challenges across the full-stack as we push the boundaries of technology. At Spotnana, we are an API-first company, leading the charge in innovative solutions.\n\nWhat youll own\n\nWork alongside a team of brilliant engineers to design and develop high-quality cloud-native services within the Spotnana platform and products (it's like being part of a superhero squad, but for coding!)\nTake charge of ensuring customer delight within your area of impact. You have the power to make our users jump with joy!\nEmbody and promote the best engineering practices and culture. You're like the Yoda of coding, guiding and mentoring others towards greatness.\nBecome a coding superhero with code reviews and test automation for your modules. Unleash your powers to defend against bugs and glitches!\nCollaborate with architects and technical leads to bring craftsmanship and innovation to the forefront. Together, we'll create a product that will make heads turn and jaws drop!\n\nExperience to bring with you\n\nBachelor's or Master's degree in Engineering, Computer Science, or a related technical field. Exceptional candidates without formal education, but with the skills to rival even the most educated, are encouraged to apply. We value talent and passion above all!\nExperience in backend distributed server-side development within a cloud-native stack is formidable. Building frameworks for consumption is your secret weapon!\n1-3 years of software development experience, battling with products and/or SaaS services. Your knowledge of data structures and algorithms is legendary!\nExperience with any programming language example Java/Python/C++\nExperience in complex, matrixed organizations has prepared you for the challenges of working across teams and projects. You're a master of collaboration!\nSuccessfully assembled and nurtured full-stack engineering teams, bringing out the best in each member. You're a superhero team builder!\nAbility to work in an open office environment in a hybrid structure at Bangalore - This is not a remote-eligible role\n\nLets talk compensation\n\nSpotnana strives to offer fair, industry-competitive and equitable compensation. Our approach holistically assesses total compensation, including cash, company equity and comprehensive benefits. Our market-based compensation approach uses data from trusted third party compensation sources to set salary ranges that are thoughtful and consistent with the role, industry, company size, and internal equity of our team. Each employee is paid within the minimum and maximum of their positions compensation range based on their skills, experience, qualifications, and other job-related specifications. \n\nWe care for the people who make everything possible - our benefits offerings include:\n\nEquity in the form of stock options which provides partial ownership in the company so you can share in the success of the company as it grows\nComprehensive benefit plans covering medical for self, spouse, children and parents, Free doctor consultations, Employee assistance program effective on your hire date. \n18 Privilege leaves, 12 casual/sick leave days per year in additional to 12 company holidays, 4 company recharge/wellness days and an end of year company shutdown\nUp to 26 weeks of Parental Leave\nMonthly cell phone / internet stipend\nMeal allowance\nWellness/Gym Reimbursement\nRelocation assistance to new joiners\nEmployee retirement planning such as corporate NPS and EPF\n \n\nWe are committed to fostering a diverse, inclusive environment and to encourage these values in everyone on our team. We provide an environment of mutual respect where opportunities are available without regard to race, color, religion, sex, pregnancy (including childbirth, lactation and related medical conditions), national origin, age, physical and mental disability, marital status, sexual orientation, gender identity, gender expression, genetic information (including characteristics and testing), military and veteran status, and any other characteristic protected by applicable law. We believe that diversity and inclusion for people from all walks of life is key to our success as a company.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4258684237": {
    "job_url": "https://www.linkedin.com/jobs/view/4258684237",
    "job_summary": "Software Engineer - Golang\nSoftware Engineer - Golang\nNomiso\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nGolang Developer\n\n\n\n\nAbout Nomiso India: Nomiso is a product and services engineering company. We are a team of Software Engineers, Architects, Managers, and Cloud Experts with expertise in Technology and Delivery Management.\n\nOur mission is to Empower and Enhance the lives of our customers through simple solutions for their complex business problems.\n\nAt Nomiso, we encourage entrepreneurial spirit - to learn, grow and improve. A great workplace thrives on ideas and opportunities. That is a part of our DNA. Were in pursuit of colleagues who share similar passions, are nimble, and thrive when challenged. We offer a positive, stimulating, and fun environment  with opportunities to grow, a fast-paced approach to innovation, and a place where your views are valued and encouraged.\n\nWe invite you to push your boundaries and join us in fulfilling your career aspirations!\n\n\n\n\nWhat You Can Expect from Us:\n\nWe work hard to provide our team with the best opportunities to grow their careers. You can expect to be a pioneer of ideas, a student of innovation, and a leader of thought. Innovation and thought leadership is at the center of everything we do at all levels of the company. Lets make your career great!\n\n\n\n\nPosition Overview:\n\nAs our Senior Engineer (Back End), you'll be responsible for building new features, enhancing the existing ones as well as supporting them in production. You will also be responsible for building reusable libraries or technology platforms that address multiple use cases. You will work towards delivering specific milestones and objectives in a very dynamic environment.\n\n\n\n\nRoles and Responsibilities:\n\n Work along with development team leads on assigned tasks.\n\n Communicate effectively and work with limited guidance from the leads.\n\n A Team player and willing to explore new technologies.\n\n Able to handle the daily challenges of the fast paced technical environment.\n\n\n\n\nMust Have Skills:\n\n\n\n\n 7+ years of Software development experience\n\n Good Go implementation capabilities.\n\n Understanding of different design principles.\n\n Good understanding of Linux OS - memory, instruction processing, filesystem, system daemons etc.\n\n Fluent with linux command line and shell scripting.\n\n Working knowledge of servers (nginx, apache, etc.), proxy-servers, and load balancing.\n\n Understanding of service based architecture and microservices.\n\n Working knowledge of AV codecs, MpegTS and adaptive streaming like Dash, HLS.\n\n Good understanding of computer networking concepts.\n\n Working knowledge of relational Databases.\n\n Good analytical and debugging skills.\n\n Knowledge of git or any other source code management.\n\n\n\n\nGood to Have Skills:\n\nWorking knowledge of Core Java and Python are preferred.\nExposure to cloud computing is preferred.\nExposure to API or video streaming performance testing is preferred.\nPreferred experience in Elasticsearch and Kibana (ELK Stack)\nProficiency in at least one modern web front-end development framework such as React JS will be a bonus\nPreferred experience with messaging systems like RabbitMQ\n\n\n\n\nQualification:\n\nBachelors degree in Computer Science Engineering or a related field\n\n\n\n\nLocation:\n\nBangalore\n\nWebsite: https://www.nomiso.io/",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4254880846": {
    "job_url": "https://www.linkedin.com/jobs/view/4254880846",
    "job_summary": "Machine Learning Engineer\nMachine Learning Engineer with verification\n6thStreet.com\nGreater Bengaluru Area (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout the Company\n\n6thStreet.com is an omnichannel fashion & lifestyle destination that offers 1400+ fashion & beauty brands in the UAE, KSA, Kuwait, Oman, Bahrain & Qatar. Customers can shop the latest on-trend outfits, shoes, bags, beauty essentials and accessories from international brands such as Tommy Hilfiger, Calvin Klein, Hugo, Marks & Spencers, Dune London, Charles & Keith, Aldo, Crocs, Birkenstock, Skechers, Levis, Nike, Adidas, Loreal and Inglot amongst many more. 6thStreet.com recently opened GCCs first phygital store at Dubai Hills Mall; an innovative tech-led space which\n\ncombines the best of both online & offline shopping with online browsing & smart fitting rooms.\n\n\n\n\nOverview\n\nThe ML Engineer will extract insights and build models that will drive key business decisions. The candidate will work closely with other data scientists, software engineers and product managers to design, build, optimize and deploy machine learning systems and solutions. This role is ideal for someone with a strong analytical mindset, a passion for data, and a desire to grow in a fast-paced e-commerce environment.\n\n\n\n\nNecessary Skills \n\nPython: Proficiency in python, with knowledge of popular libraries like pandas, numpy, scipy, scikit-learn, tensorflow, pytorch\nSQL: Strong ability to write and optimize complex SQL queries to extract and manipulate large datasets from relational databases\nData Analysis & Visualization: Ability to work with large datasets and extract meaningful insights and able to leverage data visualization tools and libraries\nData Wrangling & Preprocessing: Expertise in cleaning and transforming raw data into structured formats\nStatistical Analysis: A solid understanding of descriptive and inferential statistics, including hypothesis testing and probability theory\nMachine Learning & Deep Learning: Familiarity with supervised and unsupervised learning algorithms such as regression, tree based methods, clustering, boosting and bagging methodologies\nMachine learning workflows: feature engineering, model training, model optimization , validation and evaluation\nML Deployment: Deploying machine learning models to production environments, ensuring they meet the scalability, reliability, and performance requirements\nDevOps: Git, CI/CD pipelines, dockerization, model versioning (mlflow), monitoring platforms\nCloud Platforms: Experience with cloud platforms like AWS, Google Cloud or Azure for deploying models\nProblem-Solving & Analytical Thinking: Ability to approach complex problems methodically and implement robust solutions\nCollaboration & Communication: Strong ability to work with cross-functional teams and communicate technical concepts to non-technical stakeholders.\nAdaptability & Learning: Willingness to quickly learn new tools, technologies, and algorithms\nAttention to Detail: Ability to carefully test and validate models, ensuring they work as intended in production\n\n\n\n\nGood to have:\n\nFamiliarity with big data technologies such as Spark or Hadoop\nObject-oriented programming (OOP)\nKnowledge of data privacy and security practices when working with sensitive data\nExperience working with big data tools (e.g., Apache Kafka, Apache Flink) for streaming data processing\nFamiliarity with feature stores like Feast\nExperience working with e-commerce data\n\n\n\n\nResponsibilities\n\nDesign and implement machine learning models, algorithms, and systems\nBuild and maintain end-to-end machine learning pipelines- model training, validation, and deployment\nExperiment with different algorithms and approaches to optimize model performance\nCollaborate with software engineers, product managers, analysts to build scalable, production-ready solutions\nCommunicate complex technical concepts to non-technical stakeholders\nStay updated with the latest advancements in machine learning and deep learning.\nEvaluate and experiment with new tools, libraries, and algorithms that could improve model performance\nCollaborate on proof-of-concept (POC) projects to validate new approaches and techniques\n\n\n\n\nBenefits\n\nFull-time role\nCompetitive salary\nCompany employee discounts across all brands\nMedical & health insurance\nCollaborative work environment\nGood vibes work culture\n\n\n\n\nQualifications\n\nBachelor's degree or equivalent experience in quantative field (Statistics, Mathematics, Computer Science, Engineering, etc.)\nAt least 2 years' of experience in quantitative analytics or data modeling and development\nDeep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithms\nFluency in a programming language (Python, C,C++, Java, SQL)",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4270227876": {
    "job_url": "https://www.linkedin.com/jobs/view/4270227876",
    "job_summary": "Backend Engineer - Go Lang\nBackend Engineer - Go Lang with verification\nHalian\nIndia (Remote)\nCompany review time is typically 1 week\nViewed\nEasy Apply",
    "job_details": "About the job\n\n#Halian is hiring Backend Engineer - Golang in India/Remote .\n\n\n\n\nGreetings!\n\n\n\n\nExperience required: 5+ Years\n\nDuration: 3 Months & Extendable project\n\nWorkplace Type: Remote\n\nNotice Period: Immediate/15 Days\n\n\n\n\nTechnical Skills:\n\n* Master's Degree in Computer Science or other related technical field. \n\n* Minimum 4 years of experience in Go lang. \n\n* Advanced level at system design.\n\n* Retail, e-commerce, FMCG, fintech, or any start-up background.\n\n* Experience with Java Spring, Golang and Cloud platforms such as Azure, Google Cloud Platform and AWS. \n\n* Experience working with container technology including Docker and Kubernetes. \n\n* Experience working with relational and non-relational database systems. \n\n* Experience applying professional software engineering best practices, including coding standards, code reviews, source control management, build processes, testing, and operations.\n\n\n\n\n* Interested people, share your resume to Syed.Muhammedali@halian.com\n\n\n\n\nRegards\n\nSyed Rameez",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4270263022": {
    "job_url": "https://www.linkedin.com/jobs/view/4270263022",
    "job_summary": "Python Developer\nPython Developer\nRiDiK (a Subsidiary of CLPS. Nasdaq: CLPS)\nGreater Bengaluru Area (On-site)\nCompany review time is typically 1 week\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob Position Title: Python Fullstack Developer\n\nExperience: 6 Years\n\nCompany: CLPS Global or RiDiK Pvt Ltd\n\nSkills: Python, Django/Flask/FastAPI, Cloud, SQL, CI/CD, Docker\n\nLocation: Bangalore / Hyderabad\n\nNotice Period: Max 15 days\n\n\n\n\nJob Summary\n\n\n\n\nWere looking for Python Fullstack Developer to support our team in Hyderabad and Bangalore. This role offers the opportunity to work on meaningful projects, collaborate with talented colleagues, and contribute to the success of a growing company. If youre someone who takes initiative, values continuous learning, and thrives in a collaborative setting, wed love to hear from you.\n\n\n\n\nRequired Skillsets:\n\n6 years of professional experience in Python software development.\nProven experience in designing and developing scalable and reliable applications.\nExperience with Agile development methodologies.\nStrong proficiency in Python and related frameworks (e.g., Django, Flask, FastAPI).\nSolid understanding of object-oriented programming principles and design patterns.\nExperience with relational databases (e.g., Microsoft SQL , MySQL)\nExperience with cloud platforms (e.g. Azure, GCP).\nExperience with containerization technologies (e.g. Docker, Kubernetes).\nExperience with testing frameworks (e.g., pytest, unit test).\nExperience with CI/CD pipelines (e.g., Jenkins, GitLab)\nFamiliarity with Linux/Unix environments.\nExperience with RESTful API design and development\n\n\n\n\nAbout CLPS RiDiK\n\nRiDiK is a global technology solutions provider and a subsidiary of CLPS Incorporation (NASDAQ: CLPS), delivering cutting-edge end-to-end services across banking, wealth management, and e-commerce. With deep expertise in AI, cloud, big data, and blockchain, we support clients across Asia, North America, and the Middle East in driving digital transformation and achieving sustainable growth. Operating from regional hubs in 10 countries and backed by a global delivery network, we combine local insight with technical excellence to deliver real, measurable impact. Join RiDiK and be part of an innovative, fast-growing team shaping the future of technology across industries.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4269863712": {
    "job_url": "https://www.linkedin.com/jobs/view/4269863712",
    "job_summary": "Sr. Python & Docker Developer 4+\nSr. Python & Docker Developer 4+\nJupiter AI Labs \u2714\nIndia (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\n About the Role:\n\nWe are seeking a Sr. Python Developer with strong Docker experience to join our remote engineering team on a freelance/contract basis. The ideal candidate will have 5+ years of hands-on development experience, particularly with containerized applications, scalable systems, and backend services.\n\n\n\n\nYou will be responsible for building and maintaining Python-based modules and managing Docker environments that power key services. This is a remote position with flexible hours, but you must commit to at least 20 hours per week.\n\n\n\n\n Key Responsibilities:\n\nDesign, develop, and maintain scalable and reusable Python applications.\nCreate and manage Docker containers, images, and Docker Compose setups.\nOptimize application performance in containerized environments.\nWork with CI/CD pipelines and version control systems (Git).\nIntegrate RESTful APIs and third-party services.\nWrite unit and integration tests to ensure high code quality.\nCollaborate remotely with cross-functional teams (DevOps, QA, PM).\nAttend periodic sync-ups or check-ins.\n\n\n\n\n Required Skills & Qualifications:\n\n5+ years of professional experience in Python development.\nStrong expertise with Docker (writing Dockerfiles, managing containers, volumes, and networks)\nSolid understanding of microservices, API development, and deployment.\nFamiliarity with Git and CI/CD tools (e.g., GitHub Actions, Jenkins)\nExperience working in cloud environments (AWS, Azure, or GCP preferred)\nComfortable working independently and in remote teams.\nStrong communication and documentation skills.\n\n\n\n\n Nice to Have:\n\nExperience with Kubernetes, Terraform, or container orchestration.\nPrior contributions to open-source projects or personal GitHub portfolio.\nBackground in data pipelines or machine learning environments.\nExperience with Flask, FastAPI, or Django.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4259132427": {
    "job_url": "https://www.linkedin.com/jobs/view/4259132427",
    "job_summary": "Software Engineer (Data)\nSoftware Engineer (Data)\nAirbtics\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nLocation: Wework Galaxy, MG Road, Bangalore (Hybrid: 1 day WFH/week)\n\nType: Full-time (Initial 2-month review with potential for equity)\n\n\n\n\nAbout the Role\n\nWe're looking for a Software Engineer (Data) whos passionate about building scalable products and thrives in a fast-paced, high-ownership environment. This role is ideal for someone with 2+ years of hands-on experience working across the full stack of modern data infrastructurewho enjoys diving deep into SQL, scripting complex logic, and designing reliable data pipelines.\n\n\n\n\nWhat You'll Do\nOwn and improve the full stack of our data pipelinesfrom ingestion to processing to delivery\nDesign, build, and maintain scalable data infrastructure in a cloud environment\nWrite efficient, production-ready code in Python or a similar scripting language\nContribute to and review technical architecture; make sound trade-offs\nCollaborate closely with engineers and business teams to translate real-world problems into data-driven solutions\n(Bonus) Build and maintain scraping systems for custom data needs\n\n\n\n\nWhat Were Looking For\n2+ years of experience in building and scaling data-intensive products\nStrong command of SQLyou should be comfortable optimizing complex queries\nExperience with at least one scripting language (e.g. Python, Go)\nExperience with cloud platforms (AWS, GCP, etc.)\nExperience improving or maintaining data pipelines end-to-end\nBonus: Familiarity with scraping tools and techniques\nProactive mindsetyou take ownership and drive things forward\nStrong communication skillsable to explain ideas clearly and work cross-functionally\nGrowth-oriented and comfortable in a fast-moving, challenging environment\n\n\n\n\nWhy Join Us?\nWork with a lean, ambitious team solving real problems in the Airbnb investment space\nHigh autonomy, direct impact, and close collaboration with the founder\nOpportunity to shape key systems and architecture\nEquity offered after 2-month review (based on performance)\n\n\n\n\nInterview Process\nInitial Screening  30-minute call with the founder\nTechnical Interview  On-site session with our tech lead at our Bangalore office",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4256123149": {
    "job_url": "https://www.linkedin.com/jobs/view/4256123149",
    "job_summary": "Software Engineer\nSoftware Engineer\nLeadSquared\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nEasy Apply",
    "job_details": "About the job\n\nThe Role\n\nWe are looking for a passionate and skilled backend developer with strong expertise in .NET Core to join our team. This role is ideal for someone who thrives in building scalable, high-performance services and is open to transitioning into Java-based technologies in the future.\n\nYou will be responsible for designing and developing robust backend systems, APIs, and services that power our applications. A strong sense of ownership, attention to detail, and a commitment to writing clean, maintainable code are essential.\n\n\n\n\nKey Responsibilities\n\nDesign, develop, and maintain scalable backend services using .NET Core.\nBuild and optimize RESTful APIs and microservices.\nCollaborate with cross-functional teams to define, design, and ship new features.\nWrite clean, efficient, and testable code.\nOptimize database queries and ensure high performance for data-intensive operations.\nImplement caching and messaging solutions for performance and reliability.\nParticipate in code reviews and contribute to best practices.\nPrepare for and support a future transition to Java-based backend systems.\n\n\n\n\nRequired Skills & Qualifications\n\n23 years of experience in backend development with .NET Core.\nStrong programming skills in C#.\nExperience with ASP.NET Core MVC, Web API, and WCF.\nSolid understanding of multi-threading, asynchronous programming, and concurrency.\nExperience with MySQL, SQL Server, or equivalent relational databases.\nStrong expertise in SQL programming and query optimization for large datasets.\nFamiliarity with caching solutions like Redis.\nExperience with message brokers such as RabbitMQ, Kafka, or AWS SQS.\nHands-on experience with cloud platforms (preferably AWS, or Azure/GCP).\nExposure to analytics, observability, monitoring, and performance tuning.\nLogical thinking and a strong foundation in software design principles.\nWillingness to learn and transition to Java stack over time.\n\n\n\n\nNice to Have\n\nExperience with Java, Spring Boot, or other JVM-based technologies.\nFamiliarity with containerization (Docker, Kubernetes).\nUnderstanding of CI/CD pipelines and DevOps practices.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4264103200": {
    "job_url": "https://www.linkedin.com/jobs/view/4264103200",
    "job_summary": "Software Engineer\nSoftware Engineer with verification\nCAST\nGreater Bengaluru Area (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nBrief about the Position:\n\nWorking at CAST R&D means being an important part of a highly talented, fast-paced, multi-cultural an agile team based in Paris (France) and Bangalore (India). The team builds a sophisticated source code analysis platform leveraging parsing, control flow, data flow and other mechanisms to fully understand the inner structure of the complex IT Systems developed and used by the Fortune 500 companies.\n\n\n\n\nPrimary Job Responsibilities\n\n Contribute to the core part of our platform - source code analyzers.\n\n Support the latest evolution of languages and frameworks.\n\n Opportunity to work on the different parts of the analysis chain from parsing to developing new quality rules notably the ones related to the emerging CISQ standard.\n\n Python or C++ will be your main languages.\n\n\n\n\nSkillset and Qualifications:\n\n Must have at least 4 years of experience\n\n Must have expertise in Python development\n\n Must be pragmatic\n\n Must have excellent written, oral and telephone communication skills in English.\n\n Must have strong analytical and logical skills\n\n Must accept to follow a framework of rules on how to write/design static analyzers\n\n Hands on TDD addict: writing unit tests.\n\n Must accept to do a lot of maintenance\n\n Eager to learn new languages and frameworks at high level",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4263194425": {
    "job_url": "https://www.linkedin.com/jobs/view/4263194425",
    "job_summary": "Backend / Platform Engineer\nBackend / Platform Engineer\nTestUnity\nBengaluru, Karnataka, India (Hybrid)\n\u20b9100K/yr - \u20b91.3M/yr\nViewed\nEasy Apply",
    "job_details": "About the job\n\nRole: Backend Engineer / Platform Engineer\n\nExperience: 3-6 Years\n\nLocation: Bellandur, Bengaluru [Hybrid] or Remote\n\nMandatory Skills: Python or Golang or Node.js, RestAPI calls (for data interaction), Data Pipeline Activities or Workflow Functions.\n\nWe are looking for a highly motivated Backend Engineer / Platform Engineer with hands-on experience in designing and developing scalable backend systems and data workflows. The ideal candidate will have proficiency in backend languages such as Python, Golang, or Node.js, experience in RESTful API development, and a strong understanding of data pipeline or workflow orchestration. Experience in the healthcare domain is a plus.\n\nResponsibilities\n\n\n Design, develop, and maintain backend services and RESTful APIs for internal and external data interactions.\n Implement data pipeline tasks or workflow functions to automate ingestion, transformation, and delivery.\n Collaborate with frontend developers, data engineers, DevOps, and product teams for feature implementation and platform enhancements.\n Ensure system reliability, scalability, and performance of APIs and backend components.\n Write clean, maintainable, and testable code following best engineering practices (unit tests, code reviews, CI/CD).\n Participate in system design discussions and architecture decisions.\n\n\nRequired Skills\n\n\n Bachelors or Masters degree in Computer Science, Engineering, or a related field.\n Proficiency in Python or Golang or Node.js.\n Experience building and consuming RESTful APIs.\n Working knowledge of workflow orchestration tools or pipeline frameworks (e.g., Airflow, Temporal, custom schedulers)\n Experience working with version control and CI/CD tools like Git, GitHub, Jenkins or similar tools.\n Familiarity with unit testing and debugging of backend components.\n Healthcare domain experience (FHIR, HL7, HIPAA compliance understanding) is a plus.\n\n\nSkills: node.js,data pipeline activities,version control (git, github),workflow functions,unit testing,python,ci/cd (jenkins),github,restapi,debugging,ci/cd,rest api,jenkins,golang",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4262390001": {
    "job_url": "https://www.linkedin.com/jobs/view/4262390001",
    "job_summary": "Database Developer\nDatabase Developer with verification\nAirbus\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nRole : Database Designer / Developer\n\n\n\n\nDescription\n\nTo be responsible for designing and developing IT products, particularly to be responsible for the design and implementation of API services used inside the Core ELEC system for Aircraft electrical data.\nHe/she builds/assembles high-quality code on both COTS and custom built applications to fulfilla defined purpose. Keeps up-to-date with new and emerging technologies including ability to autonomously develop POCs.\nPossesses a good knowledge of Full Stack development and has the agility to transition between front/back end technologies. The jobholder engages in all phases of the product development (DevOps mind-set) to keep the Airbus IT landscape running smoothly, reliably, and efficiently.\n\nQualification & Experience\n\n1. Engineering graduate (preferably in Computer Science) with 3-5 years of experience in\n\ndatabase development, maintenance & administration\n\n2. At least 3 years of experience in the area of product development using PostgreSQL,\n\nNode.js, JavaScript.\n\n3. Strong understand of relational databases along with NoSQL and Graph database\n\ntechnologies\n\n4. Ability to quickly adapt existing Schema/Database Design and also come up with\n\nSchema/Database Design when required\n\n5. Experience in designing & implementing application database architecture\n\n6. Thorough knowledge of writing, modifying and optimizing complex database queries.\n\nHands -on with writing complex SQL scripts, user-defined functions, and stored\n\nprocedures.\n\n7. Strong understanding of database performance tuning and optimization techniques.\n\n8. Experience working in a Unix/Linux/Windows environment and developing shell\n\nscripts\n\n9. Strong knowledge of source code version control using Git\n\n10. Knowledge of SAFe agile methodology and workflow, preferably using\n\nVersionOne/JIRA 12) Ability to collaborate with a diversity of customer's teams to\n\naddress important issues and to resolve them\n\n11. Experienced in collaborating with internal and external stakeholders, adaption and\n\nlearning of the business processes speak of the customer especially around Aircraft\n\nelectrical data management.\n\n12. Excellent analytical, organizational and problem-solving skills coupled with a strong work\n\nethic.\n\n13. Experienced in working within a product delivery lifecycle, Agile/scrum experience in\n\nsoftware development (plus)\n\nGood to have:\n\n Data Modeling as per UML standards\n\n Github / Confluence\n\n Hands-on experience with Amazon RDS, AWS APIs and services\n\nHands-on experience on Node.js full stack based applications\n\n UNIX shell scripting (for operational activities)",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4258993490": {
    "job_url": "https://www.linkedin.com/jobs/view/4258993490",
    "job_summary": "Backend Engineer - AI Ops\nBackend Engineer - AI Ops with verification\nSolarWinds\nBengaluru, Karnataka, India\nActively reviewing applicants\nViewed\nEasy Apply",
    "job_details": "About the job\n\nAt SolarWinds, were a people-first company. Our purpose is to enrich the lives of the people we serveincluding our employees, customers, shareholders, Partners, and communities. Join us in our mission to help customers accelerate business transformation with simple, powerful, and secure solutions.\n\n\n\n\nThe ideal candidate thrives in an innovative, fast-paced environment and is collaborative, accountable, ready, and empathetic. Were looking for individuals who believe they can accomplish more as a team and create lasting growth for themselves and others. We hire based on attitude, competency, and commitment. Solarians are ready to advance our world-class solutions in a fast-paced environment and accept the challenge to lead with purpose. If youre looking to build your career with an exceptional team, youve come to the right place. Join SolarWinds and grow with us!\n\n \n\nWe are seeking a talented and motivated Software Engineer to join our Observability Platform team. In this role, youll contribute to the design and development of scalable, resilient, and real-time observability solutions that help companies monitor and optimize their distributed systems. Youll work with cutting-edge cloud infrastructure, distributed systems, and high-scale data processing, collaborating closely with cross-functional teams to deliver impactful solutions.\n\n\n\n\nKey Responsibilities:\n\n\n\n\n\nSystem Development: Design, develop, and maintain components of our observability platform using Kotlin and/or Java. \n\n\nDistributed Systems: Implement high-volume telemetry data processing systems, ensuring scalability, performance, and reliability. \n\n\nCode Quality & Best Practices: Write clean, efficient, and maintainable code, adhering to industry best practices and participating in code reviews. \n\n\nCollaboration: Work closely with product managers and senior engineers to deliver features aligned with business goals and technical requirements. \n\n\nTroubleshooting & Optimization: Identify and resolve performance bottlenecks in distributed systems and improve platform resilience. \n\n\nContinuous Improvement: Contribute to technical discussions, architecture decisions, and process improvements within the team. \n\n\n\n\n\nRequired Skills and Experience:\n\n\n\n\n\nExperience: 3+ years of software engineering experience, preferably in distributed systems or observability platforms. \n\n\nProgramming Languages: Proficiency in Kotlin and/or Java. Full-stack experience is a plus. \n\n\nCloud-Native Expertise: Familiarity with cloud platforms (AWS, GCP, or Azure) and cloud-native technologies (Kubernetes, Docker, etc.). \n\n\nData Systems: Experience with SQL/NoSQL databases and real-time data processing. \n\n\nSystem Design: Understanding of scalable system design and microservices architecture. \n\n\nProblem-Solving: Strong troubleshooting skills and the ability to optimize performance in complex systems. \n\n\nCollaboration: Excellent teamwork and communication skills, with a proactive mindset. \n\n\n\n\n\nPreferred Qualifications:\n\n\n\n\n\nFamiliarity with observability concepts (metrics, logging, tracing). \n\n\nExperience with frontend frameworks or modern frontend development is a plus. \n\n\nContributions to open-source projects or community involvement. \n\n\n \n\nSolarWinds is an Equal Employment Opportunity Employer. SolarWinds will consider all qualified applicants for employment without regard to race, color, religion, sex, age, national origin, sexual orientation, gender identity, marital status, disability, veteran status or any other characteristic protected by law.\n\n\n\n\nAll applications are treated in accordance with the SolarWinds Privacy Notice: https://www.solarwinds.com/applicant-privacy-notice",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4266980696": {
    "job_url": "https://www.linkedin.com/jobs/view/4266980696",
    "job_summary": "Back End Developer\nBack End Developer\nCodeVyasa \nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nRole Overview\n\nWe are seeking a highly skilled and motivated Backend Developer || Bangalore with 5+ years of experience. If you're passionate about coding, problem-solving, and innovation, we'd love to hear from you!\n\n\n\n\nAbout Us\n\nCodeVyasa is a mid-sized product engineering company that works with top-tier product/solutions companies such as McKinsey, Walmart, RazorPay, Swiggy, and others. We are about 550+ people strong and we cater to Product & Data Engineering use-cases around Agentic AI, RPA, Full-stack and various other GenAI areas. \n\n\n\n\nResponsibilities: \n\nDesign and implement backend services and APIs using Golang, Python, and Node.js.\nDevelop and optimize complex database queries and schemas using MySQL.\nBuild and maintain scalable, containerized microservices using Docker and Kubernetes.\nDeploy and manage cloud infrastructure and services on AWS (EC2, RDS, S3, Lambda, etc.).\nCollaborate with frontend developers, DevOps, and product managers to deliver end-to-end solutions.\nWrite clean, testable, and efficient code while following best practices (e.g., SOLID principles).\nImplement monitoring, logging, and performance tuning for high-availability systems.\n\n\n\n\nMust-Have Skills:\n\n5-7 years of backend development experience in Golang, Python, and Node.js.\nStrong understanding of RESTful API design and implementation.\nProficiency in relational databases, especially MySQL.\nHands-on experience with AWS cloud services.\nWorking knowledge of Docker and Kubernetes for orchestration and deployment.\nExperience with CI/CD pipelines and DevOps culture.\n\n\n\n\n\n\n\nWhy Join CodeVyasa?\n\nWork on innovative, high-impact projects with a team of top-tier professionals.\nContinuous learning opportunities and professional growth.\nFlexible work environment with a supportive company culture.\nCompetitive salary and comprehensive benefits package.\nFree healthcare coverage.\n\n\n\n\nHere's a glimpse of what life at CodeVyasa looks likeLife at CodeVyasa.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4266193381": {
    "job_url": "https://www.linkedin.com/jobs/view/4266193381",
    "job_summary": "Us Technology International Private Limited logo\nPython Developer\nPython Developer\nUs Technology International Private Limited\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nDesignation : Python Developer \n\nExperience : 4 to 8 Years \n\nLocation : Bangalore\n\nWork Mode : Hybrid \n\nNotice Period : Immediate to currently serving \n\n\n\n\nKey Responsibilities:\n\nDesign, develop, and maintain backend services using Python.\nBuild and integrate RESTful APIs for internal and external use.\nWrite efficient SQL queries and manage relational databases (e.g., PostgreSQL, MySQL).\nCollaborate with front-end developers, product managers, and other stakeholders.\nOptimize application performance and troubleshoot issues.\nEnsure code quality through unit testing and code reviews.\nDocument technical specifications and system architecture.\n\nRequired Skills:\n\nStrong proficiency in Python \nExperience with API development and integration (REST, GraphQL is a plus).\nSolid understanding of SQL and relational databases.\nFamiliarity with frameworks like Flask, Django, or FastAPI.\nKnowledge of version control systems (e.g., Git).\nUnderstanding of software development best practices and design patterns.\nExperience with cloud platforms (AWS, Azure, or GCP) is a plus.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4263416940": {
    "job_url": "https://www.linkedin.com/jobs/view/4263416940",
    "job_summary": "Senior Software Engineer(Python/Django)\nSenior Software Engineer(Python/Django)\nZenduty\nBangalore Urban, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nZenduty:\n\nModern engineering teams are all about site reliability. They want to keep their sites up and running, no matter what. But managing complex infrastructure and handling production incidents is tough. That's where Zenduty comes in. We're a complete site reliability engineering suite that helps teams build intelligence into their production operations and put in the processes they need to deliver rock-solid SLAs to their customers. We help companies recover from downtime faster, learn more from incidents, and deliver a better experience for the end users.\n\nHere's how we do it:\n\nWe centralize all of the alerts and notifications, so you never miss a thing.\nWe route alerts to the right people at the right time, so you can respond quickly and effectively.\nWe help you collaborate and communicate with your team members and stakeholders, so everyone is on the same page.\nWe provide you with the insights you need to learn from incidents and prevent them from happening again.\n\n\n\n\nThe Role: Senior Software Engineer\n\nWe are looking for a purist Python developer to manage and improve our REST APIs, role based access control functionalities, and build out new product features in our products while maintaining data integrity in various systems.\n\nAt the end of the year:\n\nYou will have shipped code that would have been used by a bunch of your industry peers\nYou will have mastered a host of open source technologies\nYou will know all you need to know about how startups work\nYou will have networked with some of the top investors and subject matter experts in the country\nYou will see your friends and family using the technology you create\nYou will have built long lasting relationships with your co-workers\nYou will be able to chug a can of Beer or Red Bull in a second\n\n\n\n\nSkills we are looking for:\n\nYou are a graduate in Computer Science, Engineering or other related fields with 3+ years of work experience.\nYou possess a good breadth of algorithmic and data structures knowledge.\nYou are research oriented and are able to grasp concepts and languages quickly.\nYou are a team player who is driven by passion for learning and making a difference.\n\n\n\n\nAlso:\n\nExtensive knowledge of Python\nExpertise in data structures, databases and algorithms\nExpertise in Unix/Linux administration\nExperience with Django\nStrong knowledge of web applications, distributed systems and network systems\nStrong analytical and communication skills\n\n\n\n\nAnd brownie points for:\n\nExperience with Celery, RabbitMQ and Kakfa\nExperience with frontend tech like React.js, HTML, CSS, JavaScript etc.\nExperience with NLTK, SciKit, NumPy or TensorFlow\nKnowledge of mobile application development in Android and iOS\nKnowledge of Music theory\nAt least one idea for a perpetual motion machine\nProficiency in foosball, cricket, badminton, ultimate frisbee or any other indoor games\n\n\n\n\nWhy join us? We're a fast-growing SaaS company backed by some of the best SaaS VCs and Angel investors in India and the US. We're a team of passionate engineers and product people who are dedicated to helping our customers succeed.\n\nWe believe in creating a positive and productive work environment for our employees. We offer competitive salaries and benefits, and we are committed to helping our employees grow and develop their careers.\n\nIf you are a talented and experienced Python Developer who is looking for a challenging and rewarding opportunity, we encourage you to apply.\n\n\n\n\nPerks and benefits:\n\nCompetitive salary\nFlexible work hours\nSystems and accessories of your choice\nCompany sponsored developer events and conferences\nConnections with industry experts and tech investors\nComprehensive health insurance.\nGame nights every Friday (Cricket, Badminton, D&D,quizzes, and more)\nUnlimited coffee and snacks\n\n\n\n\nCulture:\n\nAcknowledge & Own\nBragworthy work\nEntrepreneurial\nEmbrace risk calmly (Zen)\nChampion the customer experience",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4270619442": {
    "job_url": "https://www.linkedin.com/jobs/view/4270619442",
    "job_summary": "Software Development Engineer [T500-19286]\nSoftware Development Engineer [T500-19286] with verification\nDelta Air Lines\nBengaluru, Karnataka, India (On-site)\n3 company alumni work here\n3 Walmart Global Tech India company alumni work here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout Delta Tech Hub:\n\nDelta Air Lines (NYSE: DAL) is the U.S. global airline leader in safety, innovation, reliability and customer experience. Powered by our employees around the world, Delta has for a decade led the airline industry in operational excellence while maintaining our reputation for award-winning customer service. With our mission of connecting the people and cultures of the globe, Delta strives to foster understanding across a diverse world and serve as a force for social good. Delta has fast emerged as a customer-oriented, innovation-led, technology-driven business. The Delta Technology Hub will contribute directly to these objectives. It will sustain our long-term aspirations of delivering niche, IP-intensive, high-value, and innovative solutions. It supports various teams and functions across Delta and is an integral part of our transformation agenda, working seamlessly with a global team to create memorable experiences for customers.\n\n\n\n\nResponsibilities include, but are not limited to:\n\nDeveloping, Designing and demonstrating new features and components of back-end to users to ensure compliance with requirements\nAssisting in the design, implementation and optimization of related approaches, tools and workflows.\nCollaborate with the technical teams, business teams, and product managers to ensure that the code that is developed meets their vision.\nDevelop the solutions to meet functional and technical requirements.\nAlign to Security / Compliance frameworks and controls requirements.\nOwn quality posture. Write automated tests, ideally before writing code.\nWrite well designed, non-complex, testable, efficient code.\nDevelop Continuous Integration & Continuous Deployment pipelines and automated deployment scripts.\nConfigure services, such as databases and monitoring.\nImplement Service Reliability Engineering.\nFix problems from the development phase through the production phase, which requires being on call for production support.\n\n\n\n\nWhat you need to succeed (minimum qualifications):\n\n2+ years of hands-on experience on Software Development in Java, Microservices, Rest-Apis, Monitoring, AWS, Relational & NoSql Databases.\nExpert in Functional Programming approaches, mostly in Java 21.\nExperience working with containerization technologies.\nIn-depth working knowledge of Lambda, CloudFormation, IAM etc.\nKnowledge of Authentication and Authorization protocols like oAuth2.0 and OpenID Connect etc.\nExperience in Spring Framework, Springboot or similar Java Based framework for microservices development.\nExcellent judgment and problem-solving skills; individuals should be able to resolve problems in a calm and quick manner and display a high degree of initiative and drive.\nProfessional experience working with Agile Methodologies is required.\nExperience working with DevOps principles, practices and tools in an enterprise technology environment is required.\nExperience of engineering software within an Amazon Web Services (AWS) cloud infrastructure or other prominent enterprise cloud provider is required.\nWorking knowledge of the full Software Development Lifecycle, building CI/CD pipelines and practicing Test Driven Development is a requirement.\nExperience with source control, build tools and GIT (GitHub, Bitbucket or other) is required.\nEmbraces diverse people, thinking and styles.\nConsistently makes safety and security, of self and others, the priority.\nHigh School diploma, GED or High School Equivalency.\n\n\n\n\nWhat will give you a competitive edge (preferred qualifications):\n\nBachelors degree in computer science, Information Systems or related technical field is preferred.\nExperience in AWS Cloud Platform is required.\nExperience working in an airline technology environment is an added advantage.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4269708575": {
    "job_url": "https://www.linkedin.com/jobs/view/4269708575",
    "job_summary": "SDE / ML Engineer\nSDE / ML Engineer\nMinivet.ai\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob Overview\n\nAs an SDE / ML Engineer, you will be responsible for designing, developing, and maintaining scalable pipelines and infrastructure for machine learning models, ensuring high performance, reliability, and efficient deployment. You will work closely with a team of senior engineers to optimize systems, implement robust engineering practices, and contribute to the evolution of our ML and AI infrastructure through scalable software solutions. This position is for immediate joinees only.\n\n\n\n\nKey Responsibilities\n\nML Engineering\n\nTranslating working models into scalable ML pipeline solutions.\nMaintaining, deploying, and optimizing machine learning pipelines for production environments.\nParticipate in the operational lifecycle of ML systems, including feature engineering support, performance benchmarking, monitoring, and seamless deployment.\nTuning pipelines and infrastructure for efficiency, scalability, and low-latency operations.\nCollaborate with team members to integrate ML models into high-throughput data pipelines and distributed workflows, focusing on code quality, system reliability, and maintainability.\n\nData Engineering\n\nBuilding and maintaining robust, scalable, and high-performance modelling pipelines that handle large-scale data processing.\nCleaning, aggregating, & preprocessing data from diverse sources with an emphasis on efficient, parallelizable code.\nOptimize data retrieval, storage, and processing for speed and resource efficiency in distributed systems.\nCollaborate with the team on the development and maintenance of large-scale database systems, ensuring fault-tolerance and high availability.\n\nQualifications\n\nBachelors degree with 3-5 years of experience or Masters degree with 2-4 years of experience in Computer Science, Software Engineering, or a related field.\nExcellent understanding of data structures, algorithms, and software engineering principles, with a proven track record of writing clean, efficient, and maintainable code.\nStrong command over programming languages, especially Python and Java.\nExperience with distributed systems and orchestration frameworks such as Kafka for streaming data and Kubernetes for container management.\nKnowledge of SQL and hands-on experience with large-scale databases and distributed systems (e.g., BigTable, Spark, Hive).\nStrong problem-solving skills, ability to optimize for performance and scale, and quick learning aptitude.\nExcellent communication and teamwork skills.\n\n\n\n\nAbout Us\n\nMinivet.ai is a small AI products and services firm providing on-prem AI solutions tailored to clients in India and across the world. We take pride in our innovation, and in our ability to empower businesses to address their unique challenges. We collaborate closely with each client, ensuring that every AI solution is a pivotal business advantage to them. This role is a full-time position and is for people living in Bengaluru, India. \n\n\n\n\nApplication Process\n\nPlease send your resume as a PDF to jobs@minivet.ai with the subject SDEJUL25 and the following fields in the message: Name, Highest Qualification, Year of completion, Phone Number, Earliest Joining Date, Reason why you think you are a good fit. If you have less than 2 years of experience, we will be opening up a different position, please DO NOT apply. Applications will be scanned by software and hence applications not meeting the format requirements will not be considered.\n\n\n",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4259275920": {
    "job_url": "https://www.linkedin.com/jobs/view/4259275920",
    "job_summary": "Software Engineer\nSoftware Engineer with verification\nEurofins\nBengaluru, Karnataka, India (On-site)\n1 company alum works here\n1 Walmart Global Tech India company alum works here\nViewed\nEasy Apply",
    "job_details": "About the job\n\nAbout Eurofins:\n\n\n\nEurofins Scientific is an international life sciences company, providing a unique range of analytical testing services to clients across multiple industries, to make life and the environment safer, healthier and more sustainable. From the food you eat to the medicines you rely on, Eurofins works with the biggest companies in the world to ensure the products they supply are safe, their ingredients are authentic and labelling is accurate. Eurofins is a global leader in food, environmental, pharmaceutical and cosmetic product testing and in agroscience CRO services. It is also one of the global independent market leaders in certain testing and laboratory services for genomics, discovery pharmacology, forensics, CDMO, advanced material sciences and in the support of clinical studies.\n\n\n\nIn over just 30 years, Eurofins has grown from one laboratory in Nantes, France to 58,000 staff across a network of over 1,000 independent companies in 54 countries, operating 900 laboratories. Performing over 450 million tests every year, Eurofins offers a portfolio of over 200,000 analytical methods to evaluate the safety, identity, composition, authenticity, origin, traceability and purity of biological substances and products, as well as providing innovative clinical diagnostic testing services, as one of the leading global emerging players in specialised clinical diagnostics testing.\n\n\n\nEurofins is one of the fastest growing listed European companies with a listing on the French stock exchange since 1997. In FY 2021, Eurofins achieved a record revenue of over EUR 6.7 billion.\n\n\n\nEurofins IT Solutions India Pvt Ltd (EITSI) is a fully owned subsidiary of Eurofins and functions as a Global Software Delivery Center exclusively catering to Eurofins Global IT business needs. The code shipped out of EITSI impacts the global network of Eurofins labs and services.\n\n\n\nThe primary focus at EITSI is to develop the next generation LIMS (Lab Information Management system), Customer portals, e-commerce solutions, ERP/CRM system, Mobile Apps & other B2B platforms for various Eurofins Laboratories and businesses. Young and dynamic, we have a rich culture and we offer fulfilling careers.\n\n\n\n\n\nQualifications\n\n\n\nPOSITION TITLE: Software Engineer\n\n\n\nREPORTING TO: Manager \n\n\n\nREPORTING LOCATION: Bangalore \n\n\n\nWORKING LOCATION: Bangalore, India \n\n\n\nSUMMARY OF POSITION AND OBJECTIVES:\n\n\n\nA software crasftsman who can contribute to the design, development, troubleshoot, test and document enterprise web applications and services.\n\n\n\nPOSITION & OBJECTIVES:\n\n\n\nAs a Software Engineer, the main objective of this position is to deliver high quality software on his/her own and/or together with the team (including design, code, tests, document) and to accelerate the delivery. Job description:\nTest drive and Implement complex features with quality in a timely manner\nPeer review teams code and suggest improvements\n Should be able to efficiently refactor existing code to improve quality\n Liaison with Architects to review and propose architectural design changes and ensure team implements it with quality\nInteract in a constructive manner with Business Analysts in order to:\nEstimate the complexity and the workload;\nChoose the most appropriate technical solution to meet the user requirements;\nReach the optimal requirement artifact that will lead to a working software solution. \nInteract in a constructive manner with other IT teams. \n\nExperience:\n\n\n\n2-4 years of experience with developing end to- end web applications using Microsoft stack of Technologies. \nStrong working knowledge of Web application development using .NET technologies and Angular 16+\nStrong working knowledge of SOLID principles and design patterns\nGood understanding of UML, object-oriented programming (OOP) and Object Oriented Design principles\nShould have worked on at least one SOA (Service Oriented Architecture) project\nStrong experience in designing and working with n-tier architectures\nUncompromising attitude towards quality\nTDD, BDD, UML\nShould have worked in an AGILE practice methodology (preferably SCRUM)\nAble to provide technical recommendations and solve technical problems\nMust be a quick learner\n\nTechnology skills:\n\n\n\nStrong work experience of .NET Core, C#, MVC, WCF Rest and WebAPI, nUnit/MsUnit, EF\nStrong working knowledge of Azure DevOps, HTML5 and CSS3, SASS technologies. \nGood knowledge of MS SQL Databases, PowerShell, MongoDB\nStrong work experience in Angular 16+ for UI development\nWorking knowledge of Azure/AWS, MFE, Micro-services, ESB or Message Queuing (MSMQ, RabbitMQ) is an added advantage. \nWell versed with Unit testing frameworks\nFamiliarity with UI testing framework\nFamiliarity with WPF\n\n\nAdditional Information\n\n\n\nPersonal Skills:\n\n\n\nExcellent analytical and problem-solving skills\nExcellent verbal/written communication skills. Fluent in English\nScrum values: Commitment, Focus, Collaboration, Openness, Respect, Courage\n\n \n\n\n\nPREFERED CANDIDATES: \n\n\n\nThe successful candidate will have a self-motivated, get-it-done attitude; the ability to think critically; enjoy working with teams spread globally and across cultures; a desire to learn in new areas; and the discipline to pay attention to deadlines, details and quality. \nGood communication and interpersonal skills to interact with team in Europe\nBE Computer Science/MCA or any other bachelors degree with the right experience\nWill be an added advantage if worked on Laboratory related applications\n\n \n\n\n\nPERFORMANCE APPRAISAL CRITERIA:\n\n\n\nEurofins has a strong focus on Performance Management system. This includes quarterly calibrations, half-yearly reviews, and annual reviews. The KPIs shall be set and may vary slightly between projects. These will be clearly communicated, docum\n\n",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4267634991": {
    "job_url": "https://www.linkedin.com/jobs/view/4267634991",
    "job_summary": "Senior Software Engineer - Applications\nSenior Software Engineer - Applications with verification\nLinkedIn\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nLinkedIn was built to help professionals achieve more in their careers, and everyday millions of people use our products to make connections, discover opportunities and gain insights. Our global reach means we get to have a direct impact on the worlds workforce in ways no other company can. We are much more than a digital resume  we transform lives through innovative products and technology.\n\nAs a part of this world-class software engineering team, you will be charged with architecting, designing, developing, and supporting some Internet-scale features and infrastructures at LinkedIn. The ideal candidate will be excited for the challenge to transform and think critically on many computer science disciplines including product design, usability, building APIs and user-centric online applications, business logic, scaling performance, and 24x7 reliability.\n\nAt LinkedIn, our approach to flexible work is centered on trust and optimized for culture, connection, clarity, and the evolving needs of our business. The work location of this role is hybrid, meaning it will be performed both from home and from a LinkedIn office on select days, as determined by the business needs of the team.\n\nResponsibilities:\n- Scale distributed applications, make architectural trade-offs applying synchronous and asynchronous design patterns, write code, and deliver with speediness and quality.\n- Develop multi-tier scalable, high-volume performing, and reliable user-centric applications that operate 24x7.\n- Produce high quality software that is unit tested, code reviewed, and checked in regularly for continuous integration.\n- Identify, leverage, and successfully evangelize opportunities to improve engineering productivity.\n\nBasic Qualifications:\n- BA/BS Degree in Computer Science or related technical discipline, or related practical experience.\n- 5+ years experience programming experience in Java and/or C++\n\nPreferred Qualifications:\n- 8+ years of relevant work experience.\n- Expert knowledge of computer science, with strong competencies in data structures, algorithms, and software design.\n- Experience with object-oriented design, coding, testing patterns, and programming languages (Java, C++).\n- Proven coding skills in a high level language with interest and ability to learn other coding languages as needed.\n- Experience building web applications and services with IDEs and general development practices.\n\nSuggested Skills:\n Data Structures & Algorithms\n Software Design\n Java\n\nYou will Benefit from our Culture:\nWe strongly believe in the well-being of our employees and their families. That is why we offer generous health and wellness programs and time away for employees of all levels.\n\nIndia Disability Policy\nLinkedIn is an equal employment opportunity employer offering opportunities to all job seekers, including individuals with disabilities. For more information on our equal opportunity policy, please visit https://legal.linkedin.com/content/dam/legal/Policy_India_EqualOppPWD_9-12-2023.pdf\n\nGlobal Data Privacy Notice for Job Candidates\nThis document provides transparency around the way in which LinkedIn handles personal data of employees and job applicants: https://legal.linkedin.com/candidate-portal",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4268247262": {
    "job_url": "https://www.linkedin.com/jobs/view/4268247262",
    "job_summary": "Data Engineer\nData Engineer with verification\nIntraEdge\nIndia (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nWebsite-https://intraedge.com/\n\nJob Title: Data Engineer\n\nLocation: [Remote]\n\nExperience: [5+ years]\n\nEmployment Type: [Full-time]\n\nJob Summary:\n\nWe are seeking a skilled and motivated Data Engineer with strong expertise in Python, AWS serverless technologies, and Snowflake. This role involves developing APIs and automation scripts, orchestrating data pipelines, managing secure cloud access, and building scalable data solutions for compliance and reconciliation needs.\n\nKey Responsibilities:\n\nDesign and develop Python-based APIs and automation scripts for data processing and integration.\nBuild and maintain AWS Lambda and AWS Glue jobs for serverless compute and data orchestration workflows.\nImplement and manage IAM policies and roles for secure and compliant access control across cloud services.\nDevelop and optimize SQL queries for compliance logic and data reconciliation.\nDesign, build, and maintain Snowflake cloud data warehouse structures and data pipelines.\nCollaborate with analysts, data scientists, and application teams to understand data needs and deliver scalable solutions.\nMonitor, debug, and improve data pipelines and jobs for performance, reliability, and accuracy.\n\nRequired Skills:\n\nProficiency in Python for both API development and automation.\nHands-on experience with AWS Lambda, Glue, and IAM.\nStrong knowledge of SQL, especially in data transformation and reconciliation logic.\nExperience with Snowflake including schema design, performance tuning, and data loading.\nFamiliarity with data integration, orchestration, and cloud security best practices.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4255201260": {
    "job_url": "https://www.linkedin.com/jobs/view/4255201260",
    "job_summary": "Data Engineer\nData Engineer with verification\nFinacPlus\nIndia (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nData Engineer\n\n\n\n\nFinacPlus provides virtual business process services to various types of overseas clients and this position is to be part of the team which provides IT services to a leading provider of data, insights, and technology solutions to the structured finance, banking markets and company is based in U.S.A\n\n \n\nResponsibilities: \n\n \n\n Demonstrate data engineering expertise in building reliable data products \n\n Ability to quickly learn, understand, and work with new emerging technologies, and methodologies \n\n A drive to work on financial data systems & pipelines including experience working with large datasets \n\n Work effectively with other engineers, product managers in a collaborative environment \n\n Involve in identifying data quality issues and apply techniques to improve the same \n\n Identify critical infrastructure dependency/updates and work to plan those tasks \n\n Understand the requirements of stakeholders to build optimal solutions for various data challenges \n\n \n\nQualifications:  \n\n \n\n Bachelor's or Master's degree in computer science or in a related field \n\n 6+ years of industry experience building backend software and/or data systems \n\n 3+ years of experience with Python or Java, or Scala \n\n 3+ years of experience with SQL \n\n Experience with cloud services like AWS and/or GCP \n\n Experience building data pipelines using Spark/Airflow \n\n Experience with Agile and SDLC, Git workflows, and CI/CD \n\n Strong understanding of data engineering concepts \n\n \n\nPreferred Skills:  \n\n \n\n Analyze, design, and implement interactive RESTful services and APIs \n\n Exposure to pub-sub messaging systems like Kafka \n\n Exposure to IaaS like Terraform \n\n Understanding of serverless architectures, and containers \n\n Good written and verbal communication skills.\n\n\n\n\n LOCATION: Work from Home\n\nTIMINGS: 2: 00 PM to 11: 00 PM IST\n\nSALARY RANGE: Best in Industry",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4266192009": {
    "job_url": "https://www.linkedin.com/jobs/view/4266192009",
    "job_summary": "Software Engineer III, Backend\nSoftware Engineer III, Backend\nWayfair\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nWho We Are:\n\n\n\n\nAt Wayfair we are well on the way to becoming the worlds number one, online destination for all things home. Our core belief is that everyone should live in a home they love. We make this possible by ensuring our 24 million customers have all the technology and innovation they need at their fingertips, to give them access to our more than 33 million products which are provided by our 23,000 awesome global suppliers. In the Storefront team, we are the first impression of a customers shopping experience; we own the design and implementation of the customer-facing website. We partner with Product, Experience Design, Analytics and business leaders across Wayfair; our Storefront Engineering teams ensure that were building technology that solves important customer problems in elegant, scalable, measurable ways. \n\nBengaluru is home to our brand new, strategic technology delivery center and will be critical to achieving our future growth plans. We are looking for best in class Engineers to come in and help scale our technical products and teams alike as we continue on our path to be the worlds number one online destination for the home. As one of the early members of the team here in our strategic technology delivery center, you will partner closely with our technology and business leaders from around the world to help build the platform to support our growth plans to $50B USD and beyond in the next 3 to 5 years.\n\n\n\n\nThe team in the Bengaluru delivery center can work across multiple domains that drive speed and convenience for the customer and cost efficiency across the full value chain. The work we do at Wayfair means we have to move quickly, collaborating with the best and brightest engineers, creatives, product managers, data scientists, and analysts to discover, build, and scale world-class software products.\n\nIf you love to solve real business problems at scale, in a fast-paced, high growth and agile environment, this is the role for you!\n\n\n\n\nWhat You Will Do:\n\n\n\n\nFlex your strength and knowledge on Java, DevOps, and microservice development.\nDefine and ensure services are built to industry best practices, including observability, architectural patterns, and inter-team dependency mechanisms (like SLOs)\nWork closely with architects and other teams across Storefront to breakdown an existing PHP monolith into well defined Java Microservices with clean boundaries and clear API contracts\nServe as the local technical lead in the critical domain, designing & building a platform that interfaces with many different systems within and outside Wayfair and partner globally.\nArchitect and write code to implement high-quality, scalable, future-proof services that will have effective system boundaries and will support long-term vision & strategy\nConduct technical debate across an entire platform and help come to durable documented conclusions\nDrive high-impact architectural solutions and hands-on development, including inception, design, execution, and delivery following good design and coding practices\nObsessively focus on production readiness for the team including testing, monitoring, deployment, documentation, and proactive troubleshooting\nIdentify risks and gaps in technical approaches and propose solutions to meet the department's technical vision\nWork closely with product managers, designers, and peer engineering teams to define project requirements and execution plans\n\n\n\n\nWhat you bring to the table\n\n\n\n\n6+ years of experience in engineering, with a preference for candidates with a mix of start-up and large-company experience \neComm domain expertise is a bonus\nHands-on experience driving software transformations within high-growth environments at scale \nExperienced in architecting and building large-scale, cloud-based, and event-driven systems across various projects\nExcellent communication skills with demonstrated experience driving teams forward and ability to influence results\n\n\n\n\nTechnology Requirements\n\n\n\n\nGCP target cloud platform, experience with AWS/Azure at scale \nDistributed microservice architectures with well architected domain boundaries\nHigh volume async messaging architectures\nLarge scale relational and NoSQL style data stores\nCommon open source platforms, tools and framework, eg: Kafka, Kubernetes, Containerization, Java microservices, GraphQL APIs, Aerospike etc",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4267784562": {
    "job_url": "https://www.linkedin.com/jobs/view/4267784562",
    "job_summary": "Staff Engineer - Backend Engineering, Digital Business (Location: Bangalore)\nStaff Engineer - Backend Engineering, Digital Business (Location: Bangalore)\nSony Pictures Networks India\nBengaluru, Karnataka, India (On-site)\n1 company alum works here\n1 Walmart Global Tech India company alum works here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nStaff Engineer, Backend Engineering, Digital Business (Location: Bangalore)\n\n\n\n\nPurpose: Responsible for driving the architecture, design, and development of scalable backend systems that power SonyLIVs digital experiences.\n\nActs as a technical leader and mentor within the engineering team, ensuring high performance, reliability, and innovation across services and platforms.\n\n\n\n\nEducation: Bachelors or masters degree in computer science, Information Technology, or related field.\n\n\n\n\nExperience:\n\nHands-on with scalable backend systems, cloud platforms, and modern backend stacks (Node.js, No/SQL, REDIS, Kafka). Its a strong ICE role that needs 70 %+ direct coding Position Internal Stekholders - Frontend Engineering, DevOps, QA, Product Management, Data Engineering, Security\n\n\n\n\nExternal - Tech vendors, third-party APIs/integrations, CDN partners\n\nLocation: Bangalore\n\nReporting Relationship: AVP/ Sr.EM, Backend Engineering, Digital Business\n\n\n\n\nBusiness/Channel/Function: Digital\n\nKey Responsibilities:\n\nLead the design and development of scalable backend services for SonyLIVs core OTT platform Architect microservices with a focus on modularity, performance, and fault tolerance 70% + direct code contribution, owning end-to-end critical services.\nMentor junior engineers, conduct design/code reviews, and promote best practices Collaborate with cross-functional teams to define, build, and release product features\nEnsure service uptime, latency, and performance through effective observability and monitoring Contribute to technical strategy and long-term architectural decisions Drive automation, CI/CD, and deployment excellence\n\n\n\n\nCritical Competencies:\n\nExpertise in scalable backend architecture and RESTful API design Strong proficiency in RDBMS/NoSQL databases (PostgreSQL, MongoDB, Redis, etc.)\nExperience with message queues and event-driven systems (Kafka, RabbitMQ, etc.) Deep understanding of cloud-native infrastructure and containerization (Docker, Kubernetes) Solid grasp of caching strategies, security principles, and system design\nFamiliarity with observability tools (Prometheus, Grafana, ELK stack, etc.)\n\n\n\n\nOther Personal Characteristics:\n\nTech agility\nAnalytical mindset with a problem-solving attitude\nStrong sense of ownership and accountability\nPassionate about clean code and performance optimization\nEffective communicator and technical collaborator\nSelf-motivated and adaptable to a dynamic, fast-paced environment\n\n\n\n\n\n\n\nWhy join us?\n\nSony Pictures Networks is home to some of Indias leading entertainment channels such as SET, SAB, MAX, PAL, PIX, Sony BBC Earth, Yay!, Sony Marathi, Sony SIX, Sony TEN, Sony TEN1, SONY Ten2, SONY TEN3, SONY TEN4, to name a few! Our foray into the OTT space with one of the most promising streaming platforms, Sony LIV brings us one step closer to being a progressive digitally-led content powerhouse. Our independent production venture- Studio Next has already made its mark with original content and IPs for TV and Digital Media. But our quest to Go Beyond doesnt end there. Neither does our search to find people who can take us there.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4264414654": {
    "job_url": "https://www.linkedin.com/jobs/view/4264414654",
    "job_summary": "Software Engineer (DPDK / Forwarding)\nSoftware Engineer (DPDK / Forwarding) with verification\nArista Networks\nBengaluru, Karnataka, India (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nCloud EOS Team\n\n Arista Networks is the leader in building software driven cloud networks for todays datacenter, cloud and campus environments. Arista delivers the most efficient, reliable and high performance Universal Cloud Network architectures based on 10G, 25G, 40G, 50G, 100G and 400G platforms delivered with an extensible operating system  Arista EOS. Arista EOS is built on an open, programmable, and resilient state-sharing architecture that delivers maximum system uptime, reduces CAPEX and OPEX by simplifying IT operations and enables business agility.\n\n We are building disruptive products and services that deliver highly automated networks that interconnect and secure connectivity between various global locations. As a part of the team you will be exposed to wide variety of technologies like EOS (Extensible Operating System), multithreaded, multicore software forwarding based on DPDK, public cloud (AWS, Azure, GCP) infrastructure, Path selection, NFV, Containers, Network Segmentation, Virtualization, microservice based architectures, CI/CD pipelines, and Terraform-based declarative provisioning models. As a core member of the CloudEOS team, you will be part of a fast paced, high-caliber team building cutting edge software products for Cloud-enabled WAN connectivity. The team is responsible for all aspects of the development and delivery of control plane, software data plane, and management platform/APIs/services.\n\n Arista provides an open Engineering-driven culture which fosters innovation and enables engineers to Learn, Lead and Thrive. Our adoption of modern software tools, methodologies and processes and emphasis on automation enables our engineers to focus their energies on the truly complex problems and be among the most productive in the industry. Arista's products are purpose built with the scale, performance and quality required to operate in some of the most demanding environments - this provides engineers the platform and rigour to learn and gain experience in building complex, scalable software systems.\n\nBasic qualifications\n\n Bachelor's/Master's degree in Engineering\n\n 3+ years of experience working as a Systems Software Development Engineer\n\n Proficiency in C++/C programming language\n\n Software Development experience with Linux\n\nPreferred qualifications\n\n Experience with DPDK, Software Forwarding, Qos.\n\n Python and/or Golang development experience\n\n Strong communication skills and the ability to work in a team environment\n\n Experience working through the complete software development life cycle right from requirements gathering to delivering the fully developed feature.\n\n Strong software debugging skills especially in embedded systems.\n\n Experience in Network Systems Software development is a plus",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4262458879": {
    "job_url": "https://www.linkedin.com/jobs/view/4262458879",
    "job_summary": "Software Engineer|Python|AI Automation\nSoftware Engineer|Python|AI Automation\nMiratech\nBengaluru, Karnataka, India\nActively reviewing applicants\nViewed\nEasy Apply",
    "job_details": "About the job\n\nCompany Description\n\nMiratech is a global IT services and consulting company that brings together global enterprise innovation and start-up innovation. Today we support digital transformation for the largest enterprises on the planet. Our highly professional team achieves success with 99% of IT projects in financial, telecommunication and technology domains since Miratech inception in 1989. Technical complexity is our passion, stability is our standard, friendly work environment is our style. We empower our employees to grow together with the company, to achieve ambitious goals, to be a part of international relentless team which helps the visionaries to change the world.\n\nJob Description\n\nMiratech is seeking a talented and experienced Software Engineer with Python and AI Automation to support our AI-powered Contact Center modernization initiatives. In this role, you will automate legacy routing systems using Large Language Models (LLMs), cloud-native tools, and modern scripting capabilities. Your work will directly impact the customer journey by developing intelligent, scalable solutions within highly regulated industries\n\nResponsibilities:\n\n\nAutomate existing contact center routing systems using AI agent technologies. \nDesign and implement cloud-native automation solutions using Python and LLMs. \nLeverage AWS or Azure services such as storage, compute, and serverless functions to build scalable solutions. \nCollaborate with cross-functional teams to ensure high-quality deliverables aligned with business requirements. \nCreate and maintain technical documentation to ensure continuity and clarity. \nProvide timely updates to team leads and stakeholders on project progress\n\n\nQualifications\n\n\n4+ years of hands-on experience with Python and a strong understanding of data structures and algorithms. \nSolid experience in automation scripting. \nExperience working with LLMs and AI agents (e.g., prompt engineering, API integration). \nOver 3 years of hands-on experience with Cloud platforms such as AWS or Azure, including compute, storage, and serverless services. \nStrong understanding of SDLC and CI/CD best practices. \nExcellent communication skills with the ability to collaborate effectively in a team environment. \nSelf-starter with strong analytical and problem-solving skills. \n\n\nNice to have:\n\n\nExperience with Node.js/Java\nAWS Bedrock\nContact Center knowledge (Genesys Engage, Amazon Connect)\n\n\nWe offer:\n\n\nCulture of Relentless Performance: join an unstoppable technology development team with a 99% project success rate and more than 30% year-over-year revenue growth. \nCompetitive Pay and Benefits: enjoy a comprehensive compensation and benefits package, including health insurance, and a relocation program. \nWork From Anywhere Culture: make the most of the flexibility that comes with remote work. \nGrowth Mindset: reap the benefits of a range of professional development opportunities, including certification programs, mentorship and talent investment programs, internal mobility and internship opportunities. \nGlobal Impact: collaborate on impactful projects for top global clients and shape the future of industries. \nWelcoming Multicultural Environment: be a part of a dynamic, global team and thrive in an inclusive and supportive work environment with open communication and regular team-building company social events. \nSocial Sustainability Values: join our sustainable business practices focused on five pillars, including IT education, community empowerment, fair operating practices, environmental sustainability, and gender equality.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4265677420": {
    "job_url": "https://www.linkedin.com/jobs/view/4265677420",
    "job_summary": "Python Developer\nPython Developer\nVeraxion\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nWere hiring a Python Developer with 3-5 years of hands-on development experience. This role is ideal for someone who enjoys automating business processes, building simple yet effective applications, and working on reconciliation solutions that help streamline operations.\n\n\n\n\nExperience: 3-5 years\n\nLocation: Bengaluru, India [Preferred]\n\n\n\n\nWhat youll do:\n\nDevelop Python scripts/apps to automate workflows and processes.\nBuild reconciliation modules ensuring data integrity.\nCreate simple, user-friendly internal applications.\nCollaborate with stakeholders to understand and deliver requirements.\nOptimize and maintain existing code.\n\n\n\n\nWhat were looking for:\n\nStrong Python skills with 3-5 years hands-on experience.\nProven experience in business process automation and data reconciliation.\nAbility to develop and maintain small-scale business tools.\nFamiliarity with databases, version control, and APIs.\nGood problem-solving and communication skills.\n\n\n\n\nNice to have:\n\nExposure to finance/operations domains.\nExperience with databases (SQL, NoSQL) and API integrations.\n\n \n\nHow to Apply:\n\nIf this sounds like you, share your resume and a brief note about your experience to info@veraxion.com \n\nRefer someone in your network who fits this role!\n\n#hiring #pythondeveloper #automation\n\n\n",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4268626160": {
    "job_url": "https://www.linkedin.com/jobs/view/4268626160",
    "job_summary": "Remote Python Programmer - 17852\nRemote Python Programmer - 17852 with verification\nTuring\nBengaluru, Karnataka, India (Remote)\n7 school alumni work here\n7 Indian Institute of Technology (Banaras Hindu University), Varanasi school alumni work here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJoin a leading U.S.-based company as a Python Developer, where youll play a key role in driving innovative solutions in technology. Use your Python skills to tackle meaningful challenges and work on impactful projects with global experts, focusing on efficient development and problem-solving that makes a real difference.\n\n\n\n\nJob Responsibilities:\n\nDevelop efficient Python code to address problems effectively\nApply business acumen and analytical skills to extract meaningful insights from public databases\nArticulate reasoning and logic coherently when writing code in Jupyter notebooks or similar platforms\nCollaborate closely with researchers to exchange ideas and insights\nMaintain thorough documentation for all developed code\n\n\n\n\nJob Requirements:\n\nOpen to applicants of all levels, from junior to industry experts\nBachelor's degree in Engineering, Computer Science, or equivalent practical experience\nGood grasp of Python programming language for coding and debugging purposes\nKnowledge of databases (SQL/NoSQL) and cloud platforms (AWS, GCP, Azure) is a plus.\nA minimum 5-hour work overlap with PST/PT is required.\nStrong communication and teamwork skills in a remote setting.\n\n\n\n\n Perks: \n\nWork with top industry experts worldwide.\nThis is a contractual remote work opportunity without traditional job constraints.\nCompetitive salary aligned with global standards.\nBe part of cutting-edge, high-impact projects.\n\n\n\n\nSelection Process:\n\nShortlisted developers may be asked to complete an assessment.\nIf you clear the assessment, you will be contacted for contract assignments with expected start dates, durations, and end dates.\nSome contract assignments require fixed weekly hours, averaging 20/30/40 hours per week for the duration of the contract assignment.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4269034880": {
    "job_url": "https://www.linkedin.com/jobs/view/4269034880",
    "job_summary": "Python Developer\nPython Developer\nDminds Solutions Inc.\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nEasy Apply",
    "job_details": "About the job\n\nAbout the Company\n\n\n\n\n\n\n\nPrimary Skill Set - #Python Developer, #Fast API, #Microservices, #Django\n\n\n\n\n\n\n\nAbout the Role\n\n\n\n\n\n\n\nDesign, develop, and maintain robust and scalable Python applications.\n\n\n\n\nExperience : 4+ \n\n\n\n\nResponsibilities\n\n\n\n\n\n\n\nImplement and manage MongoDB databases, ensuring high performance and responsiveness.\nCollaborate with cross-functional teams to define, design, and ship new features.\nWrite clean, maintainable, and efficient code.\nTroubleshoot and debug applications.\nPerform code reviews and mentor junior developers.\nStay updated with the latest industry trends and technologies.\nDevelop and implement technical solutions to complex problems.\nArchitect and design scalable and secure software systems.\nOptimize application performance and scalability.\nIntegrate third-party APIs and services.\nEnsure code quality through automated testing and continuous integration.\nParticipate in the full software development lifecycle, including requirements gathering, design, development, testing, and deployment.\n\n\n\n\nNotice Period : 30 days / Immediate \n\n\n\n\nQualifications\n\n\n\n\n\n\n\nLocation: Chennai, Bangalore and Pune\n\n\n\n\n\n\n\nRequired Skills\n\n\n\n\n\n\n\nPython Developer, Fast API, Microservices, Django\n\n\n\n\n\n\n\nPreferred Skills\n\n\n\n\n\n\n\nPython Developer, Fast API, Microservices, Django\n\n\n\n\n\n\n\nPay range and compensation package\n\n\n\n\n\n\n\nNone specified.\n\n\n\n\n\n\n\nEqual Opportunity Statement\n\n\n\n\n\n\n\nWe are committed to diversity and inclusivity.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4260745405": {
    "job_url": "https://www.linkedin.com/jobs/view/4260745405",
    "job_summary": "Data Scientist-II\nData Scientist-II with verification\nZepto\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nOur Story\n\n\n\n\nFounded in 2021 by Aadit Palicha and Kaivalya Vohra, Zepto is on a mission to save you time making every second count towards life's real joys. Our platform has revolutionized rapid commerce in India with cutting-edge technology and strategically optimized delivery hubs. Zepto offers an extensive range of 45,000+ products, from fresh groceries to electronics, beauty essentials, apparels, toys and more, delivering across 50+ cities in 10 minutes*. Zepto Caf extends our commitment to convenience, featuring a curated menu of over 200 fresh items.\n\n\n\n\n\n\n\n\n\n\nAt Zepto, we deliver groceries in under 10 minutes but our commitment to delighting customers doesn't stop at delivery.\n\n\n\n\nWe're building intelligent, real-time systems that ensure a best-in-class post-order experience that help in resolving queries, automating support and improving customer experience.\n\n\n\n\nOur Customer Delight team is a small, high-ownership squad working at the intersection of product, DS and engineering. From LLM-powered agents to refund optimisation models, we design end-to-end solutions that go live in production and move real business metrics.\n\n\n\n\nRequired Competencies\n\n\n\n\nBuilding with ML, NLP, LLMs, Langchain / ADK / Haystack\n\n\n\n\nDesigning agentic AI systems for real-world workflows\n\n\n\n\nOwning ML evaluation, MLOps and shipping clean, scalable code\n\n\n\n\nBuilding with Docker, Kubernetes, AWS, Grafana\n\n\n\n\nQualifications\n\nBackground\n\n Bachelors in Engineering, Mathematics or Statistics from a reputed institute\n\n 2-4 years of experience in a relevant role",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4260890827": {
    "job_url": "https://www.linkedin.com/jobs/view/4260890827",
    "job_summary": "Data Engineer\nData Engineer with verification\nSia\nMumbai, Maharashtra, India (Remote)\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nSia is a next-generation, global management consulting group. Founded in 1999, we were born digital. Today our strategy and management capabilities are augmented by data science, enhanced by creativity and driven by responsibility. Were optimists for change and we help clients initiate, navigate and benefit from transformation. We believe optimism is a force multiplier, helping clients to mitigate downside and maximize opportunity. With expertise across a broad range of sectors and services, our 3,000 consultants serve clients worldwide from 48 locations in 19 countries. Our expertise delivers results. Our optimism transforms outcomes. \n\n\n\nStrategy & Management Consulting \n\n\n\nSias Strategy & Management Consulting global footprint and expertise in more than 40 sectors and services allow us to enhance our clients' businesses worldwide. We guide their projects and initiatives in strategy, business transformation, IT & digital strategy. \n\n\n\nFinancial Institutions have drastically changed over the last decade, driven by increased regulatory constraints, diverse competition inside and beyond traditional banking organizations, and emerging technologies reshaping long-standing ecosystems. Sias Financial Services Business Unit provides a comprehensive suite of core capabilities designed to address the diverse and evolving needs of our clients, enabling them to navigate complex challenges, seize new opportunities, and achieve their strategic objectives in an increasingly competitive and dynamic business environment.\n\n\n\n\n\nJob Description\n\n\n\nWe are looking for a talented and motivated Data Engineer with strong experience in PySpark and Python to design, build, and maintain scalable data pipelines and infrastructure. The successful candidate will support the delivery of data-driven insights by transforming raw data into clean, curated datasets for analytics and machine learning applications. Java experience is a plus and will be useful in hybrid environments.\n\n\n\nKey Responsibilities:\n\n\n\nDevelop and optimize robust, scalable data pipelines using PySpark and Python\n\n\n\nClean, transform, and enrich large-scale datasets from structured and unstructured sources\n\n\n\nImplement data ingestion, ETL/ELT workflows, and integration strategies across cloud and on-prem platforms\n\n\n\nCollaborate with data scientists, analysts, and business stakeholders to understand data requirements\n\n\n\nEnsure data quality, integrity, and lineage throughout the data lifecycle\n\n\n\nParticipate in performance tuning, troubleshooting, and production support\n\n\n\nContribute to best practices in data engineering, including code versioning, testing, and CI/CD\n\n\n\n\n\nQualifications\n\n\n\nRequired Qualifications:\n\n\n\nBachelors degree in Computer Science, Data Engineering, or related field\n\n\n\n3+ years of experience in data engineering with a focus on PySpark and Python\n\n\n\nStrong hands-on experience with distributed data processing frameworks (e.g., Apache Spark)\n\n\n\nSolid understanding of SQL, data modeling, and relational databases\n\n\n\nExperience working with cloud platforms (e.g., AWS, Azure, GCP)\n\n\n\nFamiliarity with workflow orchestration tools (e.g., Airflow, Azure Data Factory)\n\n\n\nPreferred Qualifications:\n\n\n\nJava experience for supporting hybrid data platforms and legacy integrations\n\n\n\nExposure to data lakes, delta lakes, and modern data architectures\n\n\n\nKnowledge of containerization (Docker), Kubernetes, and CI/CD pipelines\n\n\n\nFamiliarity with data governance, security, and compliance frameworks\n\n\n\n\n\nAdditional Information\n\n\n\nWe believe in supporting our team professionally and personally. \n\n\n\n \n\n\n\nOUR COMMITMENT TO DIVERSITY\n\n\n\nAt Sia, we believe in fostering a diverse, equitable and inclusive culture where our employees and partners are valued and thrive in a sense of belonging. We are committed to recruiting and developing a diverse network of employees and investing in their growth by providing unique opportunities for professional and cultural immersion. Our commitment toward inclusion motivates dynamic collaboration with our clients, building trust by creating an inclusive environment of curiosity and learning which affects lasting impact.\n\n\n\nPlease visit our website for more information. \n\n\n\nSia is an equal opportunity employer. All aspects of employment, including hiring, promotion, remuneration, or discipline, are based solely on performance, competence, conduct, or business needs.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4262388195": {
    "job_url": "https://www.linkedin.com/jobs/view/4262388195",
    "job_summary": "Backend Developer - (SDE-II & SDE-III)\nBackend Developer - (SDE-II & SDE-III)\nSTAN\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nKnow this about us\n\nSTAN, headquartered in Bengaluru, is the fastest-growing gaming startup. Founded in 2022, the\n\nplatform has the largest gaming community in Asia with over 15M+ downloads, the fastest in 2\n\nyears. STAN's goal is to create an ecosystem for gamers where every victory matters, where\n\nrewards are more than just tokens they're the embodiment of dedication and prowess, and\n\nthese gamers find a sense of belongingness. With a mobile-first design, STAN connects gamers\n\nworldwide, facilitating friendships and gaming groups while rewarding contributions. STAN\n\nempowers creators and supports developers, moving a step closer to becoming the Indian\n\nDiscord.\n\n\n\n\nRole Description\n\n 2-4+ years of experience as a back-end developer\n\n Bachelor's degree in Computer Science or related field\n\n 2+ years of working experience in application development using Node.js or Golang\n\n Proficient in AWS frameworks and modules, Websocket, Microservices, Payment Gateways\n\n Familiarity with relational or non-relational database [Preferably MYSQL, MongoDB, Cassandra]\n\n Strong knowledge in Golang Framework and NodeJs Framework, AWS(ECS, RDS, VPC, Code\n\npipeline), and ORM like Sequelize, typeORM\n\n Knowledge of Redis, Queue(SQS, RabbitMQ, Kenisis), API Rate limiting, Role-based Users logging, Role-based feature\n\n Experience with databases such as MySQL and MongoDB\n\n Working experience with micro services and lambda functions\n\n Take ownership of a product feature and build it end-to-end\n\n Writing robust code to be used in high-traffic services\n\n Monitoring and maintenance of live systems\n\n\n\n\nWhat you do\n\nWe're looking for an experienced individual contributor who enjoys working alongside other\n\nexperienced engineers and designers to build and iterate on backend/API/platform quickly.\n\n Build the time layer for the Product. You'll build the infrastructure for STAN from the\n\nground up, having a huge and direct impact by shipping your work to users on prod daily.\n\n Self-direct your work and co-own the product. You're a technical founder type and will\n\nhave autonomy and responsibility. You'll be involved in shaping the roadmap and will\n\nown Stans exploding backend needs.\n\n Solve interesting technical problems. Bring your full creativity to solve super-challenging\n\ntechnical problems: from complex backend architecture with 3rd party integrations,\n\nsyncing app state, to real-time collaboration.\n\n\n\n\nWhy join?\n\nAs a small team, we work in a highly collaborative environment, and you'll have the opportunity\n\nto participate in every part of the business from idea to production.\n\nImpact: Build the foundation and shape engineering practices, team, and company culture.\n\nExcellence: Practice your craft with other ICs in a well-organized, fast-paced environment.\n\nOwnership: Influence the direction of our product and strategy  we value your opinions.\n\n\n\n\nApply if you are:\n\n Excited about working in a fast-paced environment with curiosity and quick learning in a\n\ngrowing start-up.\n\n Intelligent and Articulate. Independent Thinker. Have attention to detail while being\n\npragmatic\n\n Good communication and stakeholder management skills to get work done across\n\ndifferent functions and drive product development.\n\n Willing to contribute to the ways the platform can be made much more engaging and can reach out to a larger audience",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4265093623": {
    "job_url": "https://www.linkedin.com/jobs/view/4265093623",
    "job_summary": "Backend Engineer - SDE 2\nBackend Engineer - SDE 2\nKredivo Group\nBengaluru, Karnataka, India (On-site)\n2 company alumni work here\n2 Walmart Global Tech India company alumni work here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nResponsibilities\n\n\nSuccessfully and independently deliver large-size projects, including scoping, planning, design, development, testing, rollout and maintenance. \nWrite clean, concise, modular and well-tested code. Review code from junior engineers and provide constant and constructive feedback.\nContribute to building and maintaining documentation related to the team's projects. \nCreate high quality, loosely coupled, reliable and extensible technical designs. Actively understand trade-offs between different designs and apply the solution suited to the situation / requirements. \nParticipate in the team's on-call rotation and lead the troubleshooting and resolution process of any issues related to the services/ work sub-streams/ products owned by your team.\nConstantly improve the health and quality of the services / code they work on, through set practices and new initiatives. \nLead the cross-team collaborations for the projects they work on. \nSupport hiring and on-boarding activities along with coaching and developing junior members in your team, and contribute to knowledge sharing.\n\n\nMust Have\n\nQualifications and Experience: \n\n\n4-6 years of hands-on experience in designing, developing, testing, and deploying small to mid-scale applications in any language or stack. 2+ years of recent and active software development experience. \nGood understanding of Golang. Able to use Go concurrency patterns and contribute to building reusable Go components. \nStrong experience in designing loosely coupled, reliable and extensible distributed services. \nGreat understanding of clean architecture, S.O.L.I.D principles, and event-driven architecture. Experience with message broker services like SQS, Kafka, etc.\nStrong data modeling experience in Relational databases.\nStrong cross-team collaboration and communication skills. \nSelf-driven with a passion for learning new things quickly, solving challenging problems, and the drive to get better with the support from the manager. \n\n\nNice To Have\n\n\nA bachelor degree in computer science, information technology, or equivalent education.\nExperience with NoSQL databases.\n\n",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4262800542": {
    "job_url": "https://www.linkedin.com/jobs/view/4262800542",
    "job_summary": "Software Development Engineer in Test\nSoftware Development Engineer in Test with verification\nRazorpay\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nTitle: Senior Software Development Engineer in Test\n\n\n\n\nThe Role:\n\n\n\n\nWe're looking for a highly capable, motivated Senior Software Development Engineer in Test to join us in building world-class customer-focused software.\n\nOur team delivers integrated software and hardware solutions allowing all Razorpay's customers and partners to contact us for assistance as they use online payments. You would be an important part of a growing team using the latest technology to improve our customer experience across web, and mobile platforms, empowering merchants to enjoy flawless online transactions.\n\nIn this role, you will be a leader, and contributor and have the opportunity to make a lasting impact on our entire technology stack.\n\n\n\n\nRoles and Responsibilities:\n\n\n\n\nContribute to robust, scalable, and high-quality test automation solutions.\nLead test reviews, author, and execute test cases.\nCollaborate with business and technical teams to solve complex problems.\nAdvocate and champion quality coding and best practices.\nCommunicate design and test impact based on business requirements.\nCoordinate with EM / PM and understand the gap and plan test strategy for execution\nActively work closely with senior developers and understand the upcoming tasks and plan QA activities\nWork with Business folks and understand the various use cases and keep a constant check on test coverage\nKeep a constant check on the customer experience breakages and provide necessary inputs\nResearching test tools, methodologies, and trends and upgrading existing practices and processes.\nManaging the final quality of the product releases\nBuild Tools to improve productivity\n\n\n\n\nMandatory Qualifications:\n\n\n\n\nBE/ BS/ MS in Computer Science or equivalent.\n2+ years of experience developing and testing software.\nProficient in any programming language Java / Python /Golang\nPassionate about all things automation.\nKnowledge of web service technologies (REST/SOAP).\nExcellent problem-solving skills and attention to detail.\nSelf-starter that enjoys and takes pride in their work.\nAbility to thrive in a dynamic, collaborative, and fast-paced environment\nExperience working in an Agile environment is a plus.\nPassionate about testing, development, and design of the system\nThe ability to keep current with the constantly changing technology industry.\nGood knowledge of infrastructure and tooling\nHands-on experience with Linux / Ubuntu\nGood knowledge of Git / Big Bucket or similar\nAbility to build/modify framework based on the futuristic needs\nGood knowledge of CI/CD process and tools around it\n\n\n\n\nLocation: Bangalore",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4263037931": {
    "job_url": "https://www.linkedin.com/jobs/view/4263037931",
    "job_summary": "Software Engineer\nSoftware Engineer with verification\nPocket FM\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nSoftware Engineer  Generative AI\n\nLocation: Bengaluru \n\n Experience: 1-3 Years\n\n\n\n\n\n\n\nAbout Pocket FM:\n\nAt Pocket FM, were reimagining storytelling through the power of audio. With millions of users across the globe, were on a mission to build the worlds largest audio OTT platform. As we scale, Generative AI is playing a central role in how we create, personalize, and distribute content at scale. Join us to be part of a fast-paced, ambitious team building the future of audio entertainment.\n\n\n\n\n\n\n\nWhat Youll Do:\n\nBuild production-grade systems that integrate LLMs and multimodal GenAI models into Pocket FMs content workflows.\nCollaborate with Product, Data, and ML teams to design systems for AI-powered storytelling, character generation, voice synthesis, and more.\nOptimize performance and inference of large-scale GenAI models across cloud and on-device environments.\nBuild and expose GenAI capabilities as reusable services and APIs for other product teams to consume.\nContinuously explore new models and frameworks (like GPT, TTS models, Whisper, Stable Diffusion, etc.) to keep Pocket FM ahead in the GenAI game.\nContribute to the experimentation stack for prompt engineering, RAG pipelines, fine-tuning, and evaluation.\n\n\n\n\n\n\n\nWhat Were Looking For:\n\n13 years of experience in backend/software development (Python, Go, or similar).\nHands-on experience working with LLMs or GenAI frameworks like OpenAI, HuggingFace, LangChain, or LlamaIndex.\nSolid understanding of cloud infra (AWS/GCP), containerization (Docker/K8s), and scalable service design.\nExperience working with ML engineers or deploying ML models into production.\nFamiliarity with vector databases (FAISS, Pinecone, Weaviate) and retrieval pipelines.\nPassion for building tools that push the boundaries of creative expression.\n\n\n\n\n\n\n\nNice to Have:\n\nExposure to text-to-speech, voice cloning, or audio generation models.\nContributions to open-source GenAI or ML ops tools.\nPrior experience in media, entertainment, or content-tech companies.\nEnthusiastic about storytelling, audio platforms, and immersive content experiences.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4265431476": {
    "job_url": "https://www.linkedin.com/jobs/view/4265431476",
    "job_summary": "Data Engineer\nData Engineer with verification\nHCLSoftware\nGreater Bengaluru Area (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nData Engineer: \n\nAs an experienced Data Engineer, know what it takes to deliver high quality data solutions to an\n\norganization. Skilled in sourcing, extracting, transforming, and loading data, and able to translate\n\nbusiness design into database model. Understand the value and benefit of solid data practices. Enjoy\n\nexploring and learning new technologies in a collaborative environment. Implement best practices\n\nwhen writing code, maps and data flows for automation.\n\nEssential Job Responsibilities:\n\n Be actively involved with the team to design and build new data solutions - OLAP and OLTP\n\n Develop a variety of data workflows, pipelines, and ETL processes using cloud platform\n\nproducts and internal data management tools\n\n Promote data quality and governance automation to ensure the accuracy and quality of the\n\ndata through inspection, validation, processing, anomaly detection and auto-correction\n\n Translate design specifications into working modules with a hands-on approach in the\n\niterative design and development process\n\n Write and maintain efficient and reliable code\n\n Write technical documentation\n\nRequired Experience and Education:\n\n At least 5 years of experience in Data management\n\n Advanced SQL scripting\n\n Knowledge of data transformation tools\n\n Knowledge of algorithms and data structures\n\n Knowledge of any object-oriented programming language\n\n Strong communication and collaboration skills\n\n Experience with agile methodologies\n\n A degree in Computer Science or related field",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4261532618": {
    "job_url": "https://www.linkedin.com/jobs/view/4261532618",
    "job_summary": "Python Developer\nPython Developer\nSarga Consultants\nBengaluru, Karnataka, India (On-site)\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nHiring for one of the top Electronics Companies in Bangalore\n\nFor Developing and maintaining the Library Order Database (LoD) software system.\n\nResponsibilities\n\nResponsible for implementation (new features and bug fixes), test, documentation and support of LoD system.\n\nTech Stack:\n\nFront end: Ruby on Rails\n\nBack end: Python, mysql\n\nOS: Unix\n\nDebug and troubleshoot tool issues as needed and resolve database-related issues.\nAssist in the design and maintenance of relational databases.\nWrite clean, efficient, and maintainable code for various software applications.\nDrive alignment with customers on project requirements and reporting to relevant stakeholders.\nWork on tickets raised by customers on JIRA and respond to them in a timely fashion.\nWork in project scrum team and follow all scrum practices.\n\n \n\nEducation & Experience:  5+ years\n\n\n\n\nSkills:\n\nProficient in SQL and relational databases.\nProficient in Python Programming.\nHands-on experience in web development, with a solid understanding of web development principles, including front-end and back-end development.\nKnowledge of Ruby on Rails is considered an add-on benefit.\nProficient in working with Linux OS and Shell scripting.\nWorking Knowledge of development/process tools like Git-BitBucket, JIRA, Confluence,\nExperience in working in Agile scrum teams\nStrong analytical and reasoning skills with an ability to visualize processes and outcomes.\nExcellent all-round communication skills and ability to work collaboratively.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4262349967": {
    "job_url": "https://www.linkedin.com/jobs/view/4262349967",
    "job_summary": "Software Development Engineer III- Backend Java\nSoftware Development Engineer III- Backend Java with verification\nTesco Bengaluru\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nCompany Description\nTesco Bengaluru: We are a multi-disciplinary team creating a sustainable competitive advantage for Tesco by standardising processes, delivering cost savings, enabling agility, providing cutting-edge technological solutions and empowering our colleagues to do ever more for our customers. With cross-functional expertise in Global Business Services and Retail Technology & Engineering, a wide network of teams and strong governance we reduce complexity thereby offering high quality services for our customers. Tesco Bengaluru, established in 2004 to enable standardisation and build centralised capabilities and competencies, makes the experience better for our millions of customers worldwide and simpler for over 4,40,000 colleagues.\nTesco Technology consists of people from a number of different backgrounds, but having a common purpose to serve our shoppers a little better every day with our retail technological solutions. We shared a common interest in harnessing innovations in technology to enhance their shopping experience at Tesco stores. Whether making products, software or systems, our teams focuses on various aspects from taking strategic ownership of the architecture to delivering technological solutions such as design, testing, deployment, infrastructure, operation and security of the systems to ensure agile, smooth and safe operations. These help us to deliver the maximum business impact. Teams refine their internal processes to best fit their own needs, working to build core capabilities in application and services. We collaborate globally across teams to build end-to-end customer-facing solutions, as well as to share knowledge, experience, tools and techniques.\nAt Tesco, inclusion means that Everyone?s Welcome. Everyone is treated fairly and with respect; by valuing individuality and uniqueness we create a sense of belonging.\nDiversity and inclusion have always been at the heart of Tesco. It is embedded in our values: we treat people how they want to be treated. We always want our colleagues to feel they can be themselves at work and we are committed to helping them be at their best.\nAcross the Tesco group we are building an inclusive workplace, a place to actively celebrate the cultures, personalities and preferences of our colleagues ? who in turn help to build the success of our business and reflect the diversity of the communities we serve.\nJob Description\nAs a Software Development Engineer 3 you are in a senior Individual Contributor engineering role at Tesco. Your proficiency with foundational computer science and software engineering concepts is taken as a given; and you will have proven significant technical depth and breadth. At this level you will be playing an active role in technical leadership; with proven impact across teams and the wider directorate. You take ownership and accountability of the development of the products in your domain. You participate in activities that build capability across the organisation: coaching and mentoring of existing colleagues; and interviewing/hiring of new colleagues. Once you have reached the SDE3 level; progression will vary significantly; and is likely to include more lateral opportunities than vertical promotion. This is also the level of core technical knowledge you must reach before considering a sideways move to the management track.\nFollowing our Business Code of Conduct and always acting with integrity and due diligence and have these specific risk responsibilities:\nMy impact reaches beyond my immediate team; and I provide perspective and context for technology choices across my directorate. The work that I do has foundational impact across teams in my area and the directorate that I am a member of. I am a technical leader for my teams and others will regularly come to me for mentorship and support. I am comfortable both supporting other engineers in their delivery and taking the lead on key features as appropriate. I have delivered multiple projects that move the needle for the business. I have demonstrated technical breadth and depth; I am an expert in my domain. At this level I display a high degree of ownership for the work conducted by the team. I am accountable for the quality of every result; produced by individuals and teams. I am an advocate of best practices across my directorate. I build maturity in the way we develop; deliver and operate services. I ensure that were learning from the best in the industry; designing and implementing appropriate testing and deployment strategies. I can anticipate feature evolution of my product. I utilise this when facilitating design sessions to ensure that the system architecture evolves to support future requirements. I understand the wider Tesco architectural strategy and champion its application to the systems that I work on. At this level my job starts to become just as much about exercising technical judgment as it does about implementation. I am comfortable managing competing priorities and am able to bring order to ambiguous scenarios. I create optimal outcomes combining short-term and long-term goals; utilising data driven decision making techniques to take appropriate trade-offs. I can identify risks and proactively engage with product and programme managers. I am a strong communicator within my team and to my stakeholders. I am a trusted mentor; a role-model for more junior engineers. I am approachable and am frequently asked to mentor those around me. I prioritise sharing skills and technical knowledge across the directorate; both informally in 1:1 discussions and by arranging more formal training opportunities. I build capability and raise the bar by contributing to hiring and interviewing practices. I regularly participate in recruitment assessments. Externally I represent the best of Tesco Technology to attract new talent and encourage interest in our organisation.\nKey people and teams I work with in and outside of Tesco:\n\n All team members\n Product teams\n Engineering leadership\n Programme teams\n Key business stakeholders\n 3rd party engineering;\n product and programme teams when applicable.\n\nExperience relevant for this job:\n\n Successfully had impact on teams of teams.\n Demonstrated experience designing;\n developing and running highly-scalable distributed systems.\n Experience implementing a range of design and architecture patterns.\n Experience of technical leadership within a team.\n Coaching; supporting and mentoring those around me.\n\nQualifications\nJava; RestFul; Spring; Micronaut; SQLite; Jenkins; Eventing; Automated tests; Splunk; Azure besides below\nProgramming\nSystem Design\nDevelopment Practise\nInfrastructure\nSoftware Security\nOperations and Maintenance\nCore Technology\nDevelopment Lifecycle\nProduct Methodologies\nRetail Technology Awareness\nCommunication & Influencing\nData Analytics & Insights\nStrategic Thinking & Problem Solving\nFinance & Procurement\nCuriosity & Learning\nEmbracing and Enabling Change\nAdditional Information\nImportant Notice:\nOn behalf of Tesco Bengaluru, we must caution all job seekers and educational institutions that Tesco Bengaluru does not authorise any third parties to release employment offers or conduct recruitment drives via a third party. Hence, beware of inauthentic and fraudulent job offers or recruitment drives from any individuals or websites purporting to represent Tesco. Further, Tesco Bengaluru does not charge any fee or other emoluments for any reason (including without limitation, visa fees) or seek compensation from educational institutions to participate in recruitment events.\nAccordingly, please check the authenticity of any such offers before acting on them and where acted upon, you do so at your own risk. Tesco Bengaluru shall neither be responsible for honouring or making good the promises made by fraudulent third parties, nor for any monetary or any other loss incurred by the aggrieved individual or educational institution.\nIn the event that you come across any fraudulent activities in the name of Tesco Bengaluru, please feel free report the incident at recruitment_compliance_india@tesco.com",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4251706997": {
    "job_url": "https://www.linkedin.com/jobs/view/4251706997",
    "job_summary": "Back End Developer\nBack End Developer\nOrbitShift.AI\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout OrbitShift\n\nOrbitShift is an AI-led SaaS Product transforming enterprise consultative technology sales. With a top-notch team of leaders from Amazon, McKinsey, IIT, Stanford, weve raised $8.5M from marquee investors like PeakXV (Sequoia Surge) & Stellaris Venture Partners. Were currently expanding our teams across India & USA.\n\n\n\n\nAbout the role\n\nWere looking for a rockstar Engineer looking to join a dynamic, fast-paced environment, work closely with cross-functional teams, and is adept at coming up with real-time solutions to technical challenges and has a strong foundation in software development principles.\n\n\n\n\nResponsibilities\n\nDevelop and maintain scalable, robust, and high-performance systems and services.\nWrite clean, efficient, and maintainable code.\nParticipate in all phases of the software development lifecycle, including design, implementation, testing, and deployment.\nAbility to work independently and as part of a collaborative team.\nEngage in peer code reviews and contribute to team improvement initiatives.\nEnsure the performance, quality, and responsiveness of applications.\n\n\n\n\nRequirements\n\nBachelors degree in Computer Science, Engineering, IT, or a related field.\n4+ years of experience in software development, with a focus on backend technologies.\nStrong proficiency in programming languages - Python or Node.js.\nKnowledge of AWS.\nKnowledge of database technology such as SQL, MySQL, PostgreSQL.\nStrong understanding of object-oriented programming principles and design patterns.\nExcellent problem-solving, analytical, and communication skills.\nPassion for backend development and a continuous learning mindset.\nFamiliarity with frontend technologies such as JavaScript, HTML5, CSS3, and frameworks/libraries like React or Angular is required\n\n\n\n\nWhy choose OrbitShift\n\nWere a lean team with a flat hierarchy\nNow is the best time to join as weve already cracked the code on a product that customers love, but are early-stage enough offering unparalleled learning opportunities\nHigh ownership & transparency\nFast-tracked growth and career progression\nYou get to build for and sell to an international enterprise customer base\nHybrid work setup & flexible work hours\nCompetitive salary & equity\nHealth Insurance for employees & their families\nProfessional Development allowance for online courses\n\n\n\n\n\n\n\n*OrbitShift is an equal-opportunity employer. Candidates will not be discriminated against based on race, ethnicity, color, religion, caste, sex, gender identity, sexual orientation, national origin, veteran, or disability status.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4256740373": {
    "job_url": "https://www.linkedin.com/jobs/view/4256740373",
    "job_summary": "Backend Web Developer\nBackend Web Developer\nGranicus India\nBengaluru, Karnataka, India (Hybrid)\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nThe Company \n\nServing the People Who Serve the People \n\nGranicus is driven by the excitement of building, implementing, and maintaining technology that is transforming the Govtech industry by bringing governments and their constituents together. We are on a mission to support our customers by meeting the needs of their communities and implementing our technology in ways that are equitable and inclusive. Granicus has consistently appeared on the GovTech 100 list over the past 5 years and has been recognized as the best companies to work on BuiltIn. \n\nOver the last 25 years, we have served 5,500 federal, state, and local government agencies and more than 300 million citizen subscribers powering an unmatched Subscriber Network that uses our digital solutions to make the world a better place. With comprehensive cloud-based solutions for communications, government website design, meeting and agenda management software, records management, and digital services, Granicus empowers stronger relationships between government and residents across the U.S., U.K., Australia, New Zealand, and Canada. By simplifying interactions with residents, while disseminating critical information, Granicus brings governments closer to the people they servedriving meaningful change for communities around the globe. \n\nWant to know more? See more of what we do here. \n\n\n\n\n#India\n\n\n\n\nWhat your impact will look like here:\nThe Back-end Web Developer works alongside a team of developers and analysts to provide support for the Simpleview CRM and related products. This position requires an advanced understanding of HTML, JavaScript, ColdFusion, Angular, and SQL. This position is expected to deliver high-quality, error-free work while meeting service level agreements (SLAs). \nWork with a Lead Developer to complete client contracts and projects. \nWork with the project owner to facilitate completion of work. \nWrite SQL scripts for importing and updating data within the Simpleview CRM. \nModify existing templated reports to fit client needs. \nCreate new reports based on client-provided specifications. \nDebug issues in business/application logic and implement a resolution. \nDevelop scripts to update Extranet permissions and send mass emails. \nCustomize FormBuilder forms. \nDebug issues in business/application logic and implement a resolution. \nTroubleshoot Simpleview CRM integrations (e.g. aggregator, act-on, cvent, marketplace). \nTroubleshoot issues with the sync between Simpleview CRM and Simpleview CMS. \nTroubleshoot issues with 3rd-party vendors consuming the Simpleview CRM web API. \nSupport enterprise clients. \nReport issues & errors with the core application. \nBranch updates to the core application for QA/review. \nPeer review the work of other developers. \nTest all completed work to ensure proper and error free functionality. \nComplete all programming tasks while following company code standards. \nComplete and respond to change requests from client, project owner or Lead Developer. \nManage timelines and ticket queues in order to provide timely delivery of tasks. \nMaintain open communication with Lead Developer and/or project owner on all project tasks. \nCommunicating with Lead Developer and/or project owner when timelines or ticket expectations cannot be met. \nUpdate all ticket and project notes and statuses daily within the internal Simpleview ticket system. Maintain accurate time entries. \n\n\n\n\n\nYou will love this job if you have:\n6+ years of professional web development experience with excellent time management and time tracking skills. \nAbility to explain technical concepts to non-technical stakeholders. \nProficiency in providing regular project updates, reporting progress, and communicating effectively about project timelines and any potential challenges. \nStrong problem-solving communication skills, including the ability to articulate challenges, propose effective solutions, and collaborate with team members to implement resolutions. \nFamiliarity with version control software (Git and/or SVN). \nDemonstrated ability to produce clear and thorough documentation, including writing well-commented. \nExperience with Jira, SCRUM/Agile development. \nDemonstrated commitment to staying up to date with relevant trends, tools, best practices, and changes in your field. \nDemonstration of innovative thinking and problem-solving skills. \nExperience with branching, merging, and resolving conflicts to maintain codebase integrity. \nPreferred working knowledge of coding best practices and design patterns. \nExperience with SQL, HTML, CSS, and JavaScript/jQuery. \nDemonstrated ability to troubleshoot and debug code efficiently using debugging tools and techniques. \nKnowledge of Asynchronous JavaScript and XML/JSON (AJAX) to improve user experience and application responsiveness. \nKnowledge of object-oriented programming principles for building scalable and maintainable applications. \nDemonstrated ability to write complex SQL queries to extract, manipulate, and analyze data. \nExperience with ColdFusion. \nExperience developing on a large scale web application. \nUnderstanding of functional programming paradigms for creating reusable and modular code. \nExperience in building and consuming RESTful APIs for seamless communication with external systems. \nKnowledge of creating and managing stored procedures and triggers to automate database tasks. \nFamiliarity with Internet Information Services (IIS) for hosting and deployment of web applications. \nFamiliarity with scripting languages like Python for automating tasks, data processing, and system integrations. \nExperience in query optimization and performance tuning for efficient database operations. \nExpertise in isolating, troubleshooting, and resolving issues related to bad, missing, or incorrect data within the SQL/database environment. \nExperience with the AngularJS (Angular 1.x) framework including services, controllers, directives, and modules. \nPreferred\nDemonstrated ability to identify bottlenecks in database operations and propose solutions for enhancement. \n\n\n\n\n\n\n\n\nSecurity and Privacy Requirements\n\n Responsible for Granicus information security by appropriately preserving the Confidentiality, Integrity, and Availability (CIA) of Granicus information assets in accordance with the company's information security program.\n\n Responsible for ensuring the data privacy of our employees and customers, their data, as well as taking all required privacy training in a timely manner, in accordance with company policies. \n\n\n\n\nDont have all the skills/experience mentioned above? At Granicus, we are trying to build diverse, inclusive teams. We do not have degree requirements for most of our roles. If you dont meet every requirement above but are excited to learn more, we encourage you to apply. We might just be able to find another role that could be a perfect fit! \n\n\n\n\nThe Team\n\n- We are a remote-first company with a globally distributed workforce across the United States, Canada, United Kingdom, India, Armenia, Australia, and New Zealand.\n\n\n\n\nThe Culture\n\n- At Granicus, we are building a transparent, inclusive, and safe space for everyone who wants to be\n\na part of our journey.\n\n- A few culture highlights include  Employee Resource Groups to encourage diverse voices\n\n- Coffee with Mark sessions  Our employees get to interact with our CEO on very important and\n\nsometimes difficult issues ranging from mental health to work-life balance and current affairs. \n\n- Microsoft Teams communities focused on wellness, art, furbabies, family, parenting, and more.-=- - We bring in special guests from time to time to discuss issues that impact our employee\n\npopulation \n\n\n\n\nThe Impact\n\n- We are proud to serve dynamic organizations around the globe that use our digital solutions to make the world a better place  quite literally. We have so many powerful success stories that illustrate how our solutions are impacting the world. See more of our impact here.\n\n\n\n\nGranicus is committed to providing equal employment opportunities. All qualified applicants and employees will be considered for employment and advancement without regard to race, color, religion, creed, national origin, ancestry, sex, gender, gender identity, gender expression, physical or mental disability, age, genetic information, sexual or affectional orientation, marital status, status regarding public assistance, familial status, military or veteran status or any other status protected by applicable law.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4267648268": {
    "job_url": "https://www.linkedin.com/jobs/view/4267648268",
    "job_summary": "Python Developer with Azure\nPython Developer with Azure\nTeam Geek Solutions\nBengaluru, Karnataka, India (On-site)\n\u20b91M/yr - \u20b92M/yr\nViewed\nEasy Apply",
    "job_details": "About the job\n\nAbout The Opportunity\n\nIn the dynamic tech and software development sector, we are at the forefront of digital transformation, delivering innovative solutions and robust cloud applications. Our focus on leveraging cutting-edge technology and cloud platforms sets us apart. This competitive role, based on-site in India, offers an opportunity to collaborate within a forward-thinking and agile environment, driving impactful projects in the cloud space.\n\nRole & Responsibilities\n\n\nDesign, develop and maintain high-quality Python applications tailored for Azure cloud infrastructure.\nImplement and optimize solutions using Azure services, including Azure Functions, App Services, and cloud databases.\nCollaborate closely with cross-functional teams to architect scalable solutions and integrate RESTful APIs.\nDevelop and manage CI/CD pipelines using Azure DevOps to streamline deployments and updates.\nEngage in debugging, performance tuning, and code reviews to ensure product excellence and maintainability.\nAdopt Agile practices and actively participate in sprint planning, daily stand-ups, and retrospectives.\n\n\nSkills & Qualifications\n\nMust-Have\n\n\nProven expertise in Python development with a strong understanding of modern frameworks.\nHands-on experience with Microsoft Azure services, including Azure Functions and Azure App Services.\nSolid understanding of cloud computing, REST APIs, and web service integration.\nExperience in building and maintaining CI/CD pipelines with Azure DevOps.\nFamiliarity with Agile software development methodologies and version control systems.\n\n\nPreferred\n\n\nKnowledge of containerization technologies such as Docker and Kubernetes on Azure.\nExperience with microservices architecture and serverless computing paradigms.\n\n\nBenefits & Culture Highlights\n\n\nCompetitive salary and comprehensive benefits package.\nVibrant on-site work environment fostering innovation and professional growth.\nCommitment to continuous learning, teamwork, and career progression in a leading tech setting.\n\n\nJoin us to push the boundaries of cloud technology and be part of an exciting journey of innovation and success. If you are passionate about coding, cloud-based solutions, and continuous improvement, we encourage you to apply and bring your expertise to our dynamic team.\n\nSkills: ci/cd pipelines,rest apis,azure app services,web service integration,agile methodologies,azure,python,azure devops,azure functions",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4265863832": {
    "job_url": "https://www.linkedin.com/jobs/view/4265863832",
    "job_summary": "Software Development Engineer - 2\nSoftware Development Engineer - 2\nLinkEye\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout Us \n\nWe are a Bangalore/ San Franscisco based networking startup building network observability and co-pilot system to improve the network reliability and reduce the time to action for our customers. The founding team has a cumulative 45 years of experience in the networking industry. \n\n\n\n\nRole Overview \n\nAs a Web Backend Engineer - SDE-2, you will play a crucial role in designing, developing, and maintaining the back-end systems and APIs that power our network observability and co-pilot platform. You will be responsible for building scalable, secure, and high-performance web services that meet the stringent requirements of enterprise customers. \n\n\n\n\n\n\n\nResponsibilities \n\nDesign, develop, and maintain robust and scalable back-end APIs with low latency response time using technologies that helps you to achieve it. \nImplement enterprise-grade authentication and authorization mechanisms to ensure the security and integrity of our platform and enable seamless adoption by enterprise clients. \nDesign and integrate all APIs with an API Gateway to enforce security policies, manage traffic, monitor performance, and ensure fine-grained control. \nEnsure compliance with third-party audits (SOC2, ISO 27001) and implement security best practices (OWASP Top 10). \nDesign and implement back-end system that can be deployed using CI/CD pipelines to enable seamless updates and deployment of new features with minimal disruption. \nUsing Application performance Monitoring (APM), analyze performance insights, identify bottlenecks and implement necessary optimizations proactively. \nDesign and implement proper access controls and data protection mechanisms to safeguard customer data and ensure compliance with relevant regulations. \nMentor and guide junior engineers, conduct code reviews etc. \n\n\n\n\n\n\n\nRequirements \n\nBachelor's or Master's degree in Computer Science or a related field. \n4 to 7 years of experience in building scalable back-end web services. \nStrong proficiency in at least one major back-end programming language (e.g., Python, Java, Go, Rust) and one or more web-frameworks. \nExperience with building and consuming RESTful or GraphQL, gRPC etc. \nExperience implementing enterprise grade authentication and authorization mechanisms (e.g with keycloak, Kanidm, Authelia etc). \nHands-on experience working with API Gateways (e.g., Kong, APISix, AWS API Gateway). \nStrong grasp of security protocols, CI/CD tools, and monitoring systems. \nKnowledge of database systems, both relational(MySQL/PostgreSQL), analytical(Clickhouse/Druid etc), other NoSQL(such as MongoDB etc) and data modeling. \nSolid understanding of architectural design patterns, domain driven design, micro-services etc. \nExcellent problem-solving and analytical skills \n\n\n",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4269596102": {
    "job_url": "https://www.linkedin.com/jobs/view/4269596102",
    "job_summary": "Software Engineer\nSoftware Engineer\nARK Solutions, Inc.\nIndia (Remote)\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nKey Responsibilities:\n\nSoftware Development: Write clean, efficient, and maintainable code in programming languages such as Java, C++, Python, or others as required by the project.\nSystem Design: Participate in designing scalable and robust software architectures that align with business requirements.\nTesting and Debugging: Develop and execute test cases to ensure software functionality, reliability, and performance. Identify and fix bugs or issues in the software.\nDocumentation: Create and maintain comprehensive documentation for code, APIs, and software functionalities to facilitate collaboration and future maintenance.\nCollaboration: Work closely with other team members using Agile methodologies to ensure timely and efficient delivery of software projects.\nContinuous Improvement: Stay updated with emerging technologies and industry trends to incorporate best practices into the development process.\n\nRequired Skills and Qualifications:\n\nEducational Background: Bachelors degree in Computer Science, Information Technology, or a related field.\nProgramming Proficiency: Strong knowledge of programming languages such as Java, C++, Python, or others relevant to the project.\nProblem-Solving Skills: Ability to analyze complex problems and devise effective solutions.\nUnderstanding of Software Development Life Cycle (SDLC): Familiarity with various stages of SDLC, including planning, design, development, testing, and deployment.\nVersion Control Systems: Experience with version control tools like Git for collaborative development.\nCommunication Skills: Strong verbal and written communication abilities to effectively convey ideas and collaborate with team members.\nAdaptability: Willingness to learn new technologies and adapt to changing project requirements.\n\nPreferred Qualifications:\n\nExperience with Agile Methodologies: Understanding of Agile frameworks like Scrum or Kanban.\nDatabase Management: Knowledge of SQL and experience with database design and management.\nDevOps Practices: Familiarity with continuous integration and continuous deployment (CI/CD) pipelines.\nCloud Services: Experience with cloud platforms such as AWS, Azure, or Google Cloud.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4266431604": {
    "job_url": "https://www.linkedin.com/jobs/view/4266431604",
    "job_summary": "Data Engineer\nData Engineer\nPredigle\nChennai, Tamil Nadu, India (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout the Role\n\nWe are seeking an experienced Data Engineer with deep hands-on expertise in AWS, Azure Databricks, Snowflake, and modern data engineering practices to join our growing Data & AI Engineering team. The ideal candidate is a strategic thinker who can design scalable platforms, drive robust data solutions, and support high-impact AI/GenAI projects from the ground up.\n\nKey Responsibilities\n\n Working experience of 3 years in Data engineering.\n\n Design, build, and optimize scalable data pipelines using modern frameworks and orchestration tools.\n\n Develop and maintain ETL/ELT workflows using AWS, Azure Databricks, Airflow, and Azure Data Factory.\n\n Manage and model data in Snowflake to support advanced analytics and machine learning use cases.\n\n Collaborate with analytics, product, and engineering teams to align data solutions with business goals.\n\n Ensure high standards for data quality, governance, and pipeline performance.\n\n Mentor junior engineers and help lead a high-performing data and platform engineering team.\n\n Lead and support GenAI platform initiatives, including building reusable libraries, integrating vector databases, and developing LLM-based pipelines.\n\n Build components of agentic frameworks using Python, Spring AI, and deploy them on AWS EKS.\n\n Establish and manage CI/CD pipelines using Jenkins.\n\n Drive ML Ops and model deployment workflows to ensure reliable and scalable AI solution delivery.\n\nRequired Qualifications\n\n Proven hands-on experience with Azure Databricks, Snowflake, Airflow, and Python.\n\n Strong proficiency in SQL, Spark, Spark Streaming, and modern data orchestration frameworks.\n\n Solid understanding of data modeling, ETL best practices, and performance optimization.\n\n Experience in cloud-native environments (AWS and/or Azure).\n\n Strong hands-on expertise in AWS EKS, CI/CD (Jenkins), and ML Ops/model deployment workflows.\n\n Ability to lead, mentor, and collaborate effectively across cross-functional teams.\n\nPreferred Qualifications\n\n Experience with Search Platforms such as Elasticsearch, SOLR, OpenSearch, or Vespa.\n\n Familiarity with Spring Boot microservices and EKS-based deployments.\n\n Background in Recommender Systems, with leadership roles in AI/ML projects.\n\n Expertise in GenAI platform engineering, including LLMs, RAG architecture, Vector Databases, and agentic design.\n\n Proficiency in Python, Java, Spring AI, and enterprise-grade software development.\n\n Ability to build platform-level solutions with a focus on reusability, runtime libraries, and scalability.\n\nWhat We Offer\n\n A unique opportunity to build and scale cutting-edge AI and data platforms that drive meaningful business outcomes.\n\n A collaborative, growth-oriented work culture with room for ownership and innovation.\n\n Competitive compensation and a comprehensive benefits package.\n\n Flexible hybrid/remote work model to support work-life balance.\n\n\n\n\nWork Location - Chennai -Hybrid /Remote\n\n\n\n\nAbout Predigle:\n\nPredigle, an EsperGroup company, is an American multinational organization focused on building a disruptive technology platform that revolutionizes the way businesses conduct their daily operations.\n\n\n\n\nPredigle has grown rapidly to offer multiple products and services,As a growing startup, we offer an entrepreneurial work environment where ideas are valued, creativity is encouraged, and learning opportunities are immense.\n\nhttps://espergroup.com\n\n/ https://predigle.com/\n\nhttps://www.linkedin.com/company/predigle/",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4264074519": {
    "job_url": "https://www.linkedin.com/jobs/view/4264074519",
    "job_summary": "Python Developer - SDE-2\nPython Developer - SDE-2\ngreytHR\nIndia (Remote)\nActively reviewing applicants\nViewed\nEasy Apply",
    "job_details": "About the job\n\nResponsibilities\n\n Lead the design, development, and deployment of critical backend features using Python and Django\n\n Design and implement scalable and efficient database solutions using PostgreSQL\n\nCollaborate effectively with cross-functional teams (design, product, QA) to deliver high-quality software on time and within budget\n\n Write clean, maintainable, well-documented, and testable code\n\n Conduct code reviews and mentor junior engineers on best practices\n\n Proactively identify and implement improvements to the codebase\n\n Stay up-to-date on the latest technologies and best practices in backend development and cloud computing\n\n (Plus) Leverage Google Cloud Platform (GCP) services to build, deploy, and manage scalable and reliable systems.\n\n\n\n\nQualifications\n\n Bachelor's degree in Computer Science, Information Technology, or a related field (or equivalent experience)\n\n 3+ years of experience in software development\n\n In-depth expertise in Python and Django\n\n Solid understanding of object-oriented programming (OOP) concepts and design patterns\n\n Proven experience with relational databases (PostgreSQL preferred)\n\n Experience with building and maintaining APIs\n\n Strong problem-solving and analytical skills\n\n Excellent communication, collaboration, and leadership skills\n\n A passion for building high-quality software and a continuous learner\n\n\n\n\nBenefits\n\n Competitive salary and benefits package\n\n Opportunity to work on challenging and impactful projects\n\n Collaborative and supportive work environment\n\n Continuous learning and development opportunities",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4261890876": {
    "job_url": "https://www.linkedin.com/jobs/view/4261890876",
    "job_summary": "Python Developer\nPython Developer\nSmartQ\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout SmartQ\n\nWe are a leading B2B Food-Tech company built on 4 pillars-great people, great food, great experience, and greater good. Solving complex business problems with our heart and analyzing possible solutions with our mind lie in our DNA. We are on the perpetual route of serving our clients wholeheartedly. Armed with the stability of an MNC and the agility of a start-up, we have spread across 19 countries, having collaborated and executed successfully with 600 clients. We have grown from strength to strength with a blend of exuberant youth and exceptional experience. Bengaluru, being our headquarters, is known as the innovation hub and we have grown up to be the global leader in the institutional food tech space. We were recently acquired by the world's largest foodservice company  Compass group which has an annual turnover of 20 billion USD.\n\nTo know more about the 5 key pillars that surround our culture check out our LinkedIn Life page. You will be amazed to be a part of our growth story - https://www.linkedin.com/company/smartq-bottlelabs/life/cdc290f8-ff81-4e7f-9c96-37d842f936c4/?viewAsMember=true\n\n\n\n\nAre you excited to join our team as Python Developer?\n\nAre you passionate about leveraging the Python programming language to design, develop, test, and maintain software applications? If your response is a resounding yes, then we are hunting for you.\n\nAs a Python Developer at SmartQ, your primary role will be to contribute to the entire software development life cycle, including requirements analysis, design, implementation, testing, and maintenance. In addition, writing code to implement software solutions, create algorithms, functions, and features that meet the project requirements, scripting and writing automation scripts for repetitive processes, and much more.\n\nIf you are a dynamic, results-oriented Python Developer with a proven track record in steering MNCs toward unprecedented success, we invite you to seize this opportunity to make a profound impact on our global presence. Do you possess all these skills and wish to make a difference in the world of food and technology? Join us now!\n\n\n\n\n\n\n\nKey roles and responsibilities:\n\nIntegration of user-facing elements developed by a front-end developer with server-side logic\nBuilding backend for Mobile application\nBuilding reusable code and libraries for future use\nOptimization of the application for maximum speed and scalability\nImplementation of security and data protection to ensure the user's data is always safe\nDesign and implementation of data storage solutions\nDesign and implement Lambda functions for the project as per the requirement\nUser authentication and authorization between multiple systems, servers and environments\nIntegration of multiple data sources and databases into one system\nManagement of hosting environment, including database administration and scaling an application to support load changes\nData migration, transformation, scripting and Data output in different formats\nSetting up the administration of backups for future needs\nUnderstanding differences between multiple delivery platforms such as mobile vs desktop, and optimizing output to match the specific platform\nCreating database schemas that represent and support business processes\nImplementing automated testing platforms and unit tests\nComputer Science fundamentals in data structures, algorithm design, problem solving & distributed computing\n\n\n\n\nQualifications:\n\nGood understanding of popular AWS services and components\nExcellent Proficiency & hands-on experience in Python programming (3+ years)\nKnowledge on writing restful APIs as per the project\nProfound knowledge in Serverless design pattern (Lambda, API gateway etc)\nFamiliarity with Django or Webapp2 or Flask or similar web app frameworks\nGood to have experience in working with NoSQL DB\nExperience in implementing Lambda functions\nFamiliarity with Node JS (Good to have), which will be plus to understand the front end\nAWS Certification (good to have), exposure to GCP or Azure\nKnowledge of Google App engine (Good to have)\nEducational background includes a degree (B.E/B.Tech/M.Tech) in Computer Science, Engineering, or a related field.\n2-4+ years experience as a backend/cloud developer\n\n\n\n\nMessage from CEO:\n\nWe've come to realize that we're not merely in the B2B Food service industry; we're in the business of 'Capturing Hearts.' We find ourselves in a unique position to turn ordinary, mundane corporate cafeterias into places of pure delight, where individuals can freely express themselves, find inspiration, and share happiness. Such a profound transformation opportunity is a rare gift, where the purpose of our enterprise transcends the ordinary. If this vision resonates with you, we invite you to join us in our mission to spread joy and happiness in a world weighed down by stress and pressure. Together, let's play our part in making this world a more beautiful place.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4262381078": {
    "job_url": "https://www.linkedin.com/jobs/view/4262381078",
    "job_summary": "Python Developer\nPython Developer with verification\nInfosys Finacle\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob description  Python Developer \n\nFinacle is looking for candidates with relevant Python Developer experience (Looking for immediate joiners).\n\nWork Location\n\nBangalore\n\nExperience range\n\n4 years to 6 years\n\nResponsibilities\n\n1) Strong programming skills and ability to write clean code.\n\n2) Hands on Python programming, Shell Scripting, AngularJS and REST APIs development.\n\n3) Experience with popular Python frameworks such as Django, Flask, Pyramid or FastAPI.\n\n4) Write clean and reusable code that can be easily maintained and scaled. You will be responsible for developing and implementing high-quality software solutions, creating complex applications using cutting-edge programming features and frameworks and collaborating with other teams in the firm to design and ship new features.\n\n5) Hands on experience with Continuous Integration, Continuous Deployment, Maven/Gradle Builds, Container image Builds, Jenkins Pipelines\n\n6) Hands-on programming experience with relation databases, document-oriented databases\n\n7) Hands on experience with Containers, Container-Orchestration engine, code quality check tools.\n\nAbout Finacle\n\nFinacle(Edgeverve) is the Leading Banking Product , providing financial institutions, of any size, anywhere in the world, the software to thrive in the digital banking age. We are an exciting place to work and our biggest asset is our talented workforce - what we create and achieve is a result of the aspirations of the 10,000+ employees that make up Edge Verve today\n\n\n\n\nDisclaimer: EdgeVerve Systems does not engage with external manpower agencies or charge any fees from candidates for recruitment. If you encounter such scams, please report them immediately",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4256746862": {
    "job_url": "https://www.linkedin.com/jobs/view/4256746862",
    "job_summary": "Software Engineer CVP - Backend\nSoftware Engineer CVP - Backend with verification\nArista Networks\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nEasy Apply",
    "job_details": "About the job\n\nCompany Description\n\nArista Networks is an industry leader in data-driven, client-to-cloud networking for large data center, campus and routing environments. Arista is a well-established and profitable company with over $8 billion in revenue. Aristas award-winning platforms, ranging in Ethernet speeds up to 800G bits per second, redefine scalability, agility, and resilience. Arista is a founding member of the Ultra Ethernet consortium. We have shipped over 20 million cloud networking ports worldwide with CloudVision and EOS, an advanced network operating system. Arista is committed to open standards, and its products are available worldwide directly and through partners.\n\nAt Arista, we value the diversity of thought and perspectives each employee brings. We believe fostering an inclusive environment where individuals from various backgrounds and experiences feel welcome is essential for driving creativity and innovation.\n\nOur commitment to excellence has earned us several prestigious awards, such as the Great Place to Work Survey for Best Engineering Team and Best Company for Diversity, Compensation, and Work-Life Balance. At Arista, we take pride in our track record of success and strive to maintain the highest quality and performance standards in everything we do.\n\nJob Description\n\nWho Youll Work With\n\nCloudVision is Aristas enterprise network management and streaming telemetry SaaS offering, serving the worlds largest Financials, Media and Entertainment, Health Care, and Cloud companies. As we continue to scale the service and expand into new markets, were looking to grow the team with experienced Software Engineers anchored by our Bangalore and Pune team.\n\nCloudVisions core infrastructure is a scale-out distributed system providing real-time and historical access to the full network state, along with frameworks for building advanced analytics. Its written in go and leverages open source technologies like HBase, ClickHouse, ElasticSearch, and Kafka under the covers. Were constantly investing in scaling out the platform and building out richer analytics capabilities in the infrastructure.\n\nOn top of this core platform we are building network management and analytics applications to fully automate todays enterprise network, from CI/CD pipelines for network automation, to advanced analytics and remediation for network assurance.\n\nWhat Youll Do\n\nAs a backend software engineer at Arista, you own your project end to end. You and your project team will work with product management and customers to define the requirements and design the architecture. Youll build the backend, write automated tests, and get it deployed into production via our CD pipeline. As a senior member of the team youll also be expected to help mentor and grow new team members. This role demands a strong and broad software engineering background, and you wont be limited to any single aspect of the product or development process.\n\nQualifications\n\n\nBS/MS degree in Computer Science and 5+ years of relevant experience.\nStrong knowledge of one or more of programming languages (Go, Python, Java)\nExperience developing distributed systems or scale out applications for a SaaS environment\nExperience developing scalable backend systems in Go is a plus\nExperience with network monitoring, network protocols, machine learning or data analytics is a plus\n\n\nAdditional Information\n\nArista stands out as an engineering-centric company. Our leadership, including founders and engineering managers, are all engineers who understand sound software engineering principles and the importance of doing things right.\n\nWe hire globally into our diverse team. At Arista, engineers have complete ownership of their projects. Our management structure is flat and streamlined, and software engineering is led by those who understand it best. We prioritize the development and utilization of test automation tools.\n\nOur engineers have access to every part of the company, providing opportunities to work across various domains. Arista is headquartered in Santa Clara, California, with development offices in Australia, Canada, India, Ireland, and the US. We consider all our R&D centers equal in stature.\n\nJoin us to shape the future of networking and be part of a culture that values invention, quality, respect, and fun.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4259212381": {
    "job_url": "https://www.linkedin.com/jobs/view/4259212381",
    "job_summary": "Back End Developer (Golang)\nBack End Developer (Golang)\nVisionPlus\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nApplied",
    "job_details": "About the job\n\nPosition Overview:\n\n\n\n\nWe are seeking a Senior Golang Developer  API Development to join our Bangalore office. This individual will play a key role in developing, maintaining, and scaling the APIs that power VisionPlus crypto payment system. You will ensure our APIs are secure, scalable, and high-performing while adhering to best practices. The role requires expertise in both Python and Golang for backend development, strong experience with API design, and an ability to communicate effectively within the team and with external partners.\n\n\n\n\nKey Responsibilities:\n\n API Development: Design, build, and maintain APIs for VisionPlus' crypto payment system, ensuring high performance, scalability, and reliability.\n\n API Security: Implement robust security measures for the APIs, ensuring they are protected against vulnerabilities and follow industry best practices for data protection.\n\n Scalable Architecture: Build APIs and services that can scale seamlessly as the platform grows, optimizing for both performance and cost-efficiency.\n\n Documentation: Maintain clear, up-to-date API documentation for both internal developers and external partners, ensuring ease of use and clear communication of system features and security protocols.\n\n Collaboration: Work closely with cross-functional teams (backend, frontend, product, and operations) to deliver high-quality, fully integrated solutions.\n\n Code Reviews: Lead by example in writing clean, maintainable code and conduct regular code reviews to ensure the overall quality of the teams work.\n\n Continuous Improvement: Stay current with the latest trends in API development, blockchain, and crypto technologies, and continuously improve the architecture, security, and performance of our platform.\n\n External Communication: Act as a point of contact for external API integrations, liaising with third-party partners and service providers when necessary to ensure smooth integration.\n\n Technical Leadership: Mentor and guide junior developers, promoting knowledge sharing and fostering a collaborative development environment.\n\n Agile Development: Participate in sprint planning, retrospectives, and daily standups.\n\nHelp define and execute the technical roadmap in collaboration with the product and leadership teams.\n\n\n\n\nRequirements:\n\n Experience: 5+ years of experience in backend development with a focus on API design, development, and maintenance.\n\no Strong experience with Golang for building scalable, secure, and high-performance APIs. o Expertise in building APIs for complex, distributed systems, with a focus on high availability and scalability.\n\n\n\n\nTechnical Expertise:\n\no Extensive experience in API design and development (REST, GraphQL, gRPC, etc.).\n\no In-depth knowledge of security best practices for API development (e.g., OAuth, JWT, rate limiting, and encryption).\n\no Strong understanding of scalable architecture, including experience with cloud infrastructure (AWS, GCP, Azure) and containerization (Docker, Kubernetes).\n\no Experience with crypto payment systems and blockchain technology is highly desirable, though not mandatory.\n\no Proficient in working with databases such as PostgreSQL, MySQL, and NoSQL databases (e.g., MongoDB).\n\no Familiarity with CI/CD pipelines and automated testing frameworks. o Knowledge of microservices architecture and its implementation in real-world production environments.\n\n Start-Up Mindset: o Strong sense of ownership and the ability to work independently while collaborating effectively within a small, agile team.\n\no Ability to thrive in a fast-paced, dynamic startup environment where priorities can shift rapidly.\n\no High agency and the ability to make decisions and take action in uncertain situations.\n\n\n\n\nCommunication Skills:\n\no Excellent verbal and written communication skills. Ability to communicate effectively with both technical and non-technical stakeholders.\n\no Comfort with external communication, including liaising with third-party service providers and external developers.\n\n\n\n\n Problem-Solving:\n\no Ability to troubleshoot complex technical issues, quickly identify root causes, and implement effective solutions.\n\no A passion for optimizing code, improving architecture, and refining APIs to meet evolving product and business needs.\n\n\n\n\nNice-to-Have Skills: \n\n Experience in blockchain technologies, specifically in cryptocurrency payment systems.\n\n Knowledge of modern authentication mechanisms like OAuth 2.0, OpenID Connect, or JWT.  Familiarity with the Web3 ecosystem and decentralized finance (DeFi) protocols.\n\n Experience working with event-driven architectures and message queues (e.g., Kafka, RabbitMQ).  Contribution to open-source projects related to fintech or crypto payment systems.\n\n\n\n\nWhat We Offer:\n\n\n\n\n Ownership & Impact: This is a high-impact role where youll have significant ownership over the platforms core architecture and API development, directly influencing the products success.\n\n Growth Opportunities: As a key member of a rapidly growing startup, youll have ample opportunities for career advancement, technical leadership, and personal growth.\n\n Collaborative Culture: Work alongside passionate, motivated, and talented individuals in a collaborative environment that values transparency, innovation, and accountability.\n\n Competitive Salary & Benefits: Receive a competitive salary and equity in a high growth fintech startup with the potential for substantial financial upside.\n\n\n\n\nThis role is Purely an Office-Based Role in Bangalore: Join a dynamic, office-based team in our Bangalore office and be a part of building something transformative in the fintech space.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": true,
    "easy_apply": false
  },
  "https://www.linkedin.com/jobs/view/4263018930": {
    "job_url": "https://www.linkedin.com/jobs/view/4263018930",
    "job_summary": "Backend Engineer \u2013 Golang\nBackend Engineer \u2013 Golang\nNubra\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nApplied",
    "job_details": "About the job\n\nExperience: 3  7 Years\n\nLocation: Bengaluru \n\nAbout the Role:\n\nWere seeking an experienced Backend Engineer with strong expertise in Golang to design, build, and optimize scalable backend systems powering fintech and high-throughput applications. You will own critical services, drive architectural improvements, and collaborate cross-functionally to deliver robust, production-ready solutions.\n\nResponsibilities:\n\nArchitect and develop scalable, highly concurrent backend microservices in Golang.\nDesign APIs, manage data storage with PostgreSQL, and implement caching strategies using Redis.\nBuild and maintain event-driven systems using Kafka or similar messaging platforms.\nCollaborate with DevOps to containerize applications (Docker) and orchestrate deployments on Kubernetes (preferably EKS).\nDrive performance tuning, memory profiling, and debugging in production environments.\nOwn CI/CD pipelines (GitHub Actions, Jenkins, ArgoCD) ensuring smooth releases and rollback strategies.\nParticipate actively in system design, focusing on fault tolerance, resiliency, and scaling.\nMentor junior engineers and contribute to improving coding standards and best practices.\n\nQualifications:\n\n3+ years of professional experience primarily using Golang for backend development.\nStrong knowledge of Go concurrency (goroutines, channels, mutexes) and Go runtime internals.\nHands-on experience with microservices architecture, API design, and distributed systems.\nExpertise with relational databases (PostgreSQL/MySQL) and caching systems like Redis.\nExperience with Kafka or other message brokers for asynchronous processing.\nProficient in containerization (Docker) and orchestration using Kubernetes (EKS preferred).\nExperience building and maintaining CI/CD pipelines (GitHub Actions, Jenkins, ArgoCD).\nSolid understanding of networking protocols (HTTP/2, gRPC) and security practices (JWT, OAuth).\nDemonstrated experience owning production services with on-call support, incident management, and monitoring (Prometheus, Grafana).\n\nBonus:\n\nExperience in fintech, payments, or trading systems.\nKnowledge of protobuf, eBPF, advanced caching or performance benchmarking tools.\nExposure to cloud platforms like AWS.\n\n\n\n\nReady to build high-impact backend systems with Golang? Apply now!",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": true,
    "easy_apply": false
  },
  "https://www.linkedin.com/jobs/view/4265142270": {
    "job_url": "https://www.linkedin.com/jobs/view/4265142270",
    "job_summary": "Python Backend Engineer \u2013 ML\nPython Backend Engineer \u2013 ML\nCloudSEK\nBengaluru, Karnataka, India (On-site)\nViewed\nEasy Apply",
    "job_details": "About the job\n\nWHO ARE WE?\n\nWe are a bunch of super enthusiastic, passionate, and highly driven people, working to achieve a common goal! We believe that work and the workplace should be joyful and always buzzing with energy!\n\nCloudSEK, one of Indias most trusted Cyber security product companies, is on a mission to build the worlds fastest and most reliable AI technology that identifies and resolves digital threats in real-time. The central proposition is leveraging Artificial Intelligence and Machine Learning to create a quick and reliable analysis and alert system that provides rapid detection across multiple internet sources, precise threat analysis, and prompt resolution with minimal human intervention.\n\nFounded in 2015, headquartered at Singapore, we are proud to say that weve grown at a frenetic pace and have been able to achieve some accolades along the way, including:\n\nCloudSEKs Product Suite:\n\n\nCloudSEK XVigil constantly maps a customers digital assets, identifies threats and enriches them with cyber intelligence, and then provides workflows to manage and remediate all identified threats including takedown support.\nA powerful Attack Surface Monitoring tool that gives visibility and intelligence on customers attack surfaces. CloudSEK's BeVigil uses a combination of Mobile, Web, Network and Encryption Scanners to map and protect known and unknown assets.\nCloudSEKs Contextual AI SVigil identifies software supply chain risks by monitoring Software, Cloud Services, and third-party dependencies.\n\n\nKey Milestones:\n\n\n2016: Launched our first product.\n2018: Secured Pre-series A funding.\n2019: Expanded operations to India, Southeast Asia, and the Americas.\n2020: Won the NASSCOM-DSCI Excellence Award for Security Product Company of the Year.\n2021: Raised $7M in Series A funding led by MassMutual Ventures.\nAwards & Recognition: Won NetApp Excellerator's \"Best Growth Strategy Award,\" CloudSEK XVigil joined NVIDIA Inception Program, and won the NASSCOM Emerge 50 Cybersecurity Award.\n2025: Secured $19 million in funding led by Tenacity Ventures, Commvault.\n\n\nRoles and Responsibilities:\n\n\nWriting clean, efficient, and well-documented Python code\nDevelop back-end components to improve overall performance and system robustness. \nMaintaining and updating existing systems\nCollaborating with team members to identify, design, and implement new features\nParticipating in code reviews to ensure code quality and consistency\n\n\nRequired Skills:\n\n\nGreat programming skills with expertise in Python\nSkills to build highly scalable and efficient backend services\nGood knowledge of SQL and experience in working with relational databases.\nExperience in working with NoSQL database programs such as MongoDB.\nHands-on experience in at least one Python web framework such as FastAPI or Flask.\nWorking knowledge of a message queuing system like RabbitMQ/ SQS? Kafka\nExperience with Docker \n\n\nGood to Have:\n\n\nExperience working with kubernetes\nExperience with AWS cloud services.\nHands on skills in Applied-ML \n\n\nBenefits of Joining CloudSEK\n\nWe provide an environment where you can develop and enhance your skills while delivering meaningful work that matters. Youll be rewarded a competitive salary as well as a full spectrum of generous perks and incentives which include:\n\n\nFlexible working hours.\nFood, unlimited snacks and drinks are all available while at office.\n\n\nAnd, the finest part is yet to come! Every now and then we ensure to unwind and have a good time together, which involves games, fun, and soulful music. Feel free to show off your artistic side here!",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4256439473": {
    "job_url": "https://www.linkedin.com/jobs/view/4256439473",
    "job_summary": "Data Engineer\nData Engineer with verification\nEXL\nIndia (Remote)\nActively reviewing applicants\nViewed\nEasy Apply",
    "job_details": "About the job\n\nAbout the Role\n\nWe are seeking a highly skilled and motivated Senior Data Engineer with hands-on experience across AWS, Azure, and GCP data ecosystems. The ideal candidate will be responsible for designing, building, and maintaining scalable data pipelines and architectures that support advanced analytics and real-time data processing.\n\n\n\n\nKey Responsibilities\n\nTechnical Responsibilities\n\nData Pipeline Development: Design and implement robust ETL/ELT pipelines using cloud-native tools.\nCloud Expertise:\nAWS: EMR, Kinesis, Redshift, Glue\nAzure: HDInsight, Synapse Analytics, Stream Analytics\nGCP: Cloud Dataproc, Dataflow, Composer\nData Modeling: Develop and optimize data models for analytics and reporting.\nData Governance: Ensure data quality, security, and compliance across platforms.\nAutomation & Orchestration: Use tools like Apache Airflow, AWS Step Functions, and GCP Composer for workflow orchestration.\nMonitoring & Optimization: Implement monitoring, logging, and performance tuning for data pipelines.\n\nCollaboration & Communication\n\nWork closely with data scientists, analysts, and business stakeholders to understand data needs.\nTranslate business requirements into scalable technical solutions.\nParticipate in code reviews, architecture discussions, and agile ceremonies.\n\n\n\n\nRequired Qualifications\n\nTechnical Skills\n\nStrong programming skills in Python, SQL, and optionally Scala or Java.\nDeep understanding of distributed computing, data warehousing, and stream processing.\nExperience with data lake architectures, data mesh, and real-time analytics.\nProficiency in CI/CD practices and infrastructure as code (e.g., Terraform, CloudFormation).\n\nCertifications (Preferred)\n\nAWS Certified Data Analytics  Specialty\nMicrosoft Certified: Azure Data Engineer Associate\nGoogle Professional Data Engineer\n\n\n\n\nSoft Skills & Attributes\n\nAnalytical Thinking: Ability to break down complex problems and design scalable solutions.\nCommunication: Strong verbal and written communication skills to explain technical concepts to non-technical stakeholders.\nCollaboration: Team player with a proactive attitude and the ability to work in cross-functional teams.\nAdaptability: Comfortable working in a fast-paced, evolving environment with shifting priorities.\nOwnership: High sense of accountability and a drive to deliver high-quality solutions.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4263990911": {
    "job_url": "https://www.linkedin.com/jobs/view/4263990911",
    "job_summary": "Software Development Engineer-II\nSoftware Development Engineer-II\nBright Money\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nApplied",
    "job_details": "About the job\n\nAbout Bright Money\n\n\n\n\nBright is a consumer fintech that helps Americans get out of debt, with the power of data science and machine learning. It is a mobile app that combines all the tools and tech needed to manage and get rid of debt.\n\n\n\n\nBrights tools include credit score building, automated debt paydown plans, financial planning, budget planning tools, and refinance loans. It works with credit cards, student loans and car loans.\n\nBright has had 6x growth in the last year, with 300,000 users, and more than 100,000 ratings and reviews.\n\n\n\n\nBright is backed by three major venture capital funds (Sequoia, Falcon Edge and Hummingbird) and with top angel investors from the US, UK and India, Bright has raised +$40 million in funding to date.\n\n\n\n\nBright has recently raised $50M in debt funding from Encina Lender Finance, for its credit business growth. Encina Lender Finance provides lending solutions to consumer and commercial speciality finance companies across the U.S. and Canada.\n\n\n\n\nToday we are among the top 8 US FinTech companies. We will become a top-100 US financial institution, with the unique strength of data science and predictive modelling to enhance financial products for a users life outcomes.\n\n\n\n\nWe will be the first at-scale Consumer Tech company, built in India for Global markets.\n\n\n\n\nAbout Our Founders:\n\n\n\n\nBright was founded in 2019 by a founding team from McKinseys Banking Practice (Petko Plachkov and Avi Patchava) and InMobi Data Scientist (Avi Patchava, Varun Modi, Avinash Ramakath, Jayashree Merwade)\n\n\n\n\nKey Responsibilities:\n\n\n\n\nDesign, Develop, Test and Deploy scalable components for Bright's Smart Banking Platform in Django / Python\nDevelop Smart Algorithms and Sub Systems for Lending and Financial Communications to the User\nCome up with quick and simple design solutions to complex engineering problems\nData Driven Decisions\nAnalytical Skills\nE2e ownership of tech systems and microservices.\n\n\n\n\nRequired Skills:\n\n\n\n\nStrong First Principles Problem Solver (https://jamesclear.com/first-principles)\nExperience with integration and development of REST services over back-end frameworks (such as Django, Node.js)\nStrong Algorithm and Data Structures skillset\nDemonstrated ability to share knowledge via formal mentoring, reviewing code, reviewing design documents, providing technical talks, teaching classes, or as a consultant on projects\nExperience in HLD, LLD design and developing scalable software systems\nSome previous experience in Python based frameworks\n3-5 years of demonstrated software development experience\nExperience with developing upon Relational or NoSQL Databases at scale.\n\n\n\n\nPreferred Skill Sets:\n\n\n\n\nBachelor's degree in Computer Science, or related technical field, or equivalent work experience\n3+ years of Django development experience\nExperience with CI/CD frameworks\nDeployment experience with AWS, GCP or Azure\nDemonstrated Competitive Programming excellence\n\n\n\n\nWhat is in it for you?\n\nYou will build the cross-functional skills to one day become a Start-up Founder, building your own company\nYou will build advanced skills in A.I. and Finance  trained by Tech founders who have this expertise\nYou will build a deep end to end understanding of building a customer focused financial product from scratch.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": true,
    "easy_apply": false
  },
  "https://www.linkedin.com/jobs/view/4263374286": {
    "job_url": "https://www.linkedin.com/jobs/view/4263374286",
    "job_summary": "Back End Developer\nBack End Developer with verification\nColorTokens Inc.\nGreater Bengaluru Area (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob Description: Software Engineer (MTS 2)\n\nYOE: 13 years, Startups preferred\n\nLocation: Bangalore\n\nSkills: Go and PostgreSQL\n\n\n\n\nAbout ColorTokens:\n\n\n\n\nAt ColorTokens, we empower businesses to stay operational and resilient in an increasingly complex cybersecurity landscape. Breaches happenbut with our cutting-edge ColorTokens Xshield platform, companies can minimize the impact of breaches by preventing the lateral spread of ransomware and advanced malware. We enable organizations to continue operating while breaches are contained, ensuring critical assets remain protected.\n\nOur innovative platform provides unparalleled visibility into traffic patterns between workloads, OT/IoT/IoMT devices, and users, allowing businesses to enforce granular micro-perimeters, swiftly isolate key assets, and respond to breaches with agility. Recognized as a Leader in the Forrester Wave: Microsegmentation Solutions (Q3 2024), ColorTokens safeguards global enterprises and delivers significant savings by preventing costly disruptions.\n\n\n\n\nJoin us in transforming cybersecurity. Learn more at www.colortokens.com.\n\n\n\n\nOur Culture\n\n\n\n\nWe foster an environment that values customer focus, innovation, collaboration, mutual respect, and informed decision-making. We believe in alignment and empowerment so you can own and drive initiatives autonomously.\n\nSelf-starters and high-motivated individuals will enjoy the rewarding experience of solving complex challenges that protect some of worlds impactful organizations  be it a childrens hospital, or a city, or the defense department of an entire country.\n\n\n\n\nAbout the Role:\n\n\n\n\nWe are looking for a motivated and disciplined Software Engineer (MTS 2) with working experience in Go and PostgreSQL who is eager to build reliable and scalable backend systems. While prior experience with React or cybersecurity principles is a plus, the key requirement is a strong foundation in backend development and a willingness to grow. The ideal candidate is a team player who communicates clearly, takes ownership of their tasks, and is eager to learn in a fast-paced environment.\n\n\n\n\nResponsibilities\n\n\n\n\nDevelop and maintain backend services using Go and PostgreSQL.\nWork closely with senior engineers and cross-functional teams to implement features and fixes.\nParticipate in code reviews and follow best practices to ensure high-quality code.\nFocus on writing performant, maintainable, and secure code.\nCommunicate progress and blockers clearly with teammates and leads.\nLearn and grow into broader responsibilities such as architecture and system design over time.\nAssist in front-end development using React as needed.\nStay curious and up-to-date with emerging technologies and good engineering practices.\n\n\n\n\nQualifications\n\n\n\n\nRequired Skills:\n\n13 years of hands-on experience with Go, or strong familiarity through personal or academic projects.\nBasic to intermediate experience with PostgreSQL, including writing queries and understanding schemas.\n\n\n\n\nBonus Skills:\n\nExposure to React or interest in learning front-end technologies.\nUnderstanding of basic cybersecurity concepts or best practices.\n\n\n\n\nOther Skills:\n\nStrong willingness to learn and grow under mentorship.\nGood problem-solving and debugging skills.\nAbility to manage tasks with guidance and deliver consistently.\nClear communication and eagerness to collaborate in a team environment.\n\n\n\n\nThis role is ideal for early-career engineers who are proactive, eager to learn from experienced peers, and want to make a meaningful impact while growing their skills in a supportive and high-performance environment.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4264724880": {
    "job_url": "https://www.linkedin.com/jobs/view/4264724880",
    "job_summary": "Software Development Engineer II (Machine Learning)\nSoftware Development Engineer II (Machine Learning) with verification\nMedia.net\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nSDE II  Machine Learning\n\nLocation: Bangalore\n\nExperience: 36 years\n\n\n\n\nAbout Media.net\n\nMedia.net is a global leader in ad tech, powering billions of ad impressions across web and mobile formats. Our proprietary contextual advertising and machine learning technologies serve major global publishers and advertisers.\n\nWe focus on building intelligent systems that solve complex optimization and targeting problems at scale. If you thrive in a fast-paced, data-driven environment and are excited to work on products that impact millions of users daily, Media.net is the place for you.\n\n\n\n\nRole Overview\n\nAs an SDE II  Machine Learning, you will be a core contributor in designing, building, and scaling ML-driven systems that power our real-time ad platforms. You'll be responsible for full-stack ML developmentfrom data engineering and model development to scalable deploymentworking closely with product, data science, and engineering teams.\n\n\n\n\nWhat You'll Do\n\n Build and deploy machine learning models for ranking, bid optimization, and click-through rate prediction.\n\n Design scalable and fault-tolerant data pipelines and services that serve real-time and batch ML workloads.\n\n Work with large volumes of structured and unstructured data to extract meaningful patterns.\n\n Collaborate with data scientists to convert prototypes into production-ready systems.\n\n Build systems to intelligently target ads and content by combining contextual and behavioral signals.\n\n Use LLM learning to improve ad relevance, page understanding, and user targeting.\n\n Continuously experiment and optimize models based on user feedback and system performance.\n\n\n\n\nSome Interesting Challenges You'll Solve\n\n Predicting CTRs and revenue across millions of unique URLs and topics in real-time.\n\n Solving cold-start problems with sparse data using explore-exploit frameworks.\n\n Matching contextual and behavioral data for enhanced user targeting.\n\n Designing real-time bidding systems that optimize for revenue and win rate.\n\n Leveraging LLMs/NLP to extract intent and context from web content.\n\n\n\n\nTech Stack You'll Work With\n\n Languages: Python, Java, Node.js\n\n ML/Big Data: Apache Spark, Hadoop, TensorFlow/PyTorch, Kafka\n\n Databases: SQL, MongoDB, Redis, Elasticsearch\n\n Cloud: GCP or similar\n\n\n\n\nWhat We're Looking For\n\n 36 years of hands-on experience in software development and ML engineering.\n\n Strong programming and debugging skills, preferably in Python and Java.\n\n Experience building and deploying ML models in production environments.\n\n Solid understanding of ML algorithms (e.g., decision trees, gradient boosting, deep learning).\n\n Hands-on experience with large-scale data processing tools (e.g., Spark, Hadoop).\n\n Ability to design low-latency, high-throughput systems.\n\n Strong problem-solving and analytical skills.\n\n\n\n\nBonus Points\n\n Prior experience with ad tech, recommender systems, or real-time bidding.\n\n Publications or contributions to ML research or open-source projects.\n\n Experience with NLP, LLMs, or Information Retrieval.\n\n Exposure to auction theory or game-theoretic modeling.\n\n\n\n\nWhy Join Us?\n\n Work on high-impact problems that power ad delivery at scale.\n\n Flexible work hours, modern office spaces, and supportive teams.\n\n Full-stack ownership and end-to-end involvement in projects.\n\n Culture that values innovation, autonomy, and deep tech.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4259989602": {
    "job_url": "https://www.linkedin.com/jobs/view/4259989602",
    "job_summary": "Backend Developer - SDE 2\nBackend Developer - SDE 2 with verification\nGroww\nGreater Bengaluru Area (On-site)\nActively reviewing applicants\nApplied",
    "job_details": "About the job\n\nAbout Groww\n\nWe are a passionate group of people focused on making financial services accessible to every Indian through a multi-product platform. Each day, we help millions of customers take charge of their financial journey.\n\nCustomer obsession is in our DNA. Every product, every design, every algorithm down to the tiniest detail is executed keeping the customers needs and convenience in mind.\n\nOur people are our greatest strength. Everyone at Groww is driven by ownership, customer-centricity, integrity and the passion to constantly challenge the status quo.\n\nAre you as passionate about defying conventions and creating something extraordinary as we are? Lets chat.\n\n\n\n\nOur Vision\n\nEvery individual deserves the knowledge, tools, and confidence to make informed financial decisions. At Groww, we are making sure every Indian feels empowered to do so through a cutting-edge multi-product platform offering a variety of financial services.\n\nOur long-term vision is to become the trusted financial partner for millions of Indians.\n\n\n\n\nOur Values\n\nOur culture enables us to be what we are  Indias fastest-growing financial services company. It fosters an environment where collaboration, transparency, and open communication take center-stage and hierarchies fade away. There is space for every individual to be themselves and feel motivated to bring their best to the table, as well as craft a promising career for themselves.\n\n\n\n\nThe values that form our foundation are:\n\nRadical customer centricity\nOwnership-driven culture\nKeeping everything simple\nLong-term thinking\nComplete transparency\n\n\n\n\nAs a Backend Engineer, you will:\n\nThe Software Development Engineer's core responsibilities include working on highly maintainable and unit-tested software components/systems that address real-world problems.\nYou will be working in a fast-paced and agile work environment delivering quality solutions that have an immediate business impact.\nComplete ownership of the projects you deliver while collaborating with technical and non-technical stakeholders on all elements of the development process.\n\n\n\n\nWhat are we looking for :\n\n3+ years experience.\nStrong problem-solving skills.\nGood understanding of data structures & algorithms and their space & time complexities.\nHands-on solid and practical working experience with Java.\nExcellent coding skills - should be able to convert the design into code fluently.\nStrong technical aptitude and a good knowledge of CS fundamentals.\nB Tech in Computer Science or equivalent from a reputed college.\nYou are expected to demonstrate good learnability and adopt technologies that help build large-scale, performant, reliable and sustainable systems.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": true,
    "easy_apply": false
  },
  "https://www.linkedin.com/jobs/view/4261920245": {
    "job_url": "https://www.linkedin.com/jobs/view/4261920245",
    "job_summary": "Python Data Developer\nPython Data Developer with verification\nExplore Group\nIndia (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob Description\n\nWe are urgently seeking a skilled Data Engineer with expertise in DBT, Databricks, and Python to design, build, and maintain scalable data transformation pipelines. The ideal candidate will have a strong understanding of modern data architectures and hands-on experience with cloud-based tools and frameworks.\n\n\n\n\nResponsibilities\n\nDesign and implement robust and scalable data models using DBT\nBuild and maintain efficient data pipelines for transformation and integration\nWork with multiple data sources, ensuring seamless ingestion and transformation\nCollaborate closely with data analysts, data scientists, and data quality teams\nEnsure best practices in code versioning, testing, and documentation\n\n\n\n\nRequired Skills\n\nStrong experience with DBT (Data Build Tool)\nHands-on experience with Databricks\nProficiency in Python for data engineering tasks\nExperience integrating and transforming data from various sources\nGood communication and collaboration skills",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4259179561": {
    "job_url": "https://www.linkedin.com/jobs/view/4259179561",
    "job_summary": "Full Stack Engineer\nFull Stack Engineer with verification\nRazorpay\nGreater Bengaluru Area (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\n Title: Senior Software Development Engineer (Full Stack)\n\n\n\nAbout the Role:\n\nAt Razorpay, a Senior Full Stack Engineer is not just a coder  you're a product thinker, systems architect, and business-aware problem solver. Youll be deeply involved in building and scaling systems that power seamless online payments across India and beyond. This role requires someone equally comfortable crafting intuitive user experiences and architecting resilient backend systems.\n\nYou will work closely with product managers, designers, backend/frontend developers, and stakeholders to build high-impact features across the stack. Youll shape not only code but also team culture, product direction, and technical standards.\n\n\n\n\n\n\n\nRoles and Responsibilities:\n\nDrive and participate in product and design discussions, influencing both backend architecture and frontend user experience.\nDesign, build, and maintain scalable, reliable, and performant APIs and web applications.\nDevelop and optimize responsive, accessible, and pixel-perfect UIs using modern JavaScript frameworks.\nOwn features end-to-end  from conception to deployment  and ensure they work well across platforms and devices.\nCollaborate with cross-functional teams to translate requirements into technical solutions.\nEnsure seamless integration of frontend with backend systems, REST APIs, and third-party services.\nWrite clean, modular, and maintainable code following best engineering practices.\nConduct thorough testing, debugging, and code reviews to ensure high code quality.\nKeep up with industry trends, and proactively suggest improvements to our stack, process, or product.\nMentor and guide junior engineers, fostering growth within the team.\nParticipate in or lead open-source projects and contribute to the broader engineering community.\n\n\n\n\n\n\n\nMandatory Qualifications:\n\n3+ years of experience building full stack applications in a product-driven environment.\nStrong command over frontend technologies like HTML, CSS, JavaScript, and frameworks like React, Angular, or Vue.\nProficiency in backend programming with one or more languages such as Python, Django, Go, Java, PHP, or C++.\nDeep understanding of REST APIs, and how the web works under the hood.\nDemonstrated experience building features from scratch and taking ownership of modules or systems.\nProduct-first mindset with a strong sense of design and usability.\nComfort working in agile teams, collaborating across product, design, and engineering.\nWillingness to learn and adopt new tools, languages, or technologies as needed.\n\n\n\n\n\n\n\nGood to Have:\n\nA portfolio of side-projects or GitHub contributions.\nExperience contributing to or maintaining open-source projects.\nPrior experience working in fast-paced product startups.\nFamiliarity with tools like SASS/Stylus, Jade, Grunt/Gulp, etc.\nBasic understanding of DevOps and CI/CD pipelines.\nWorking knowledge of web accessibility (WCAG) and performance optimization.\nExposure to cloud infrastructure (AWS, GCP) is a plus.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4258649269": {
    "job_url": "https://www.linkedin.com/jobs/view/4258649269",
    "job_summary": "Cloud Engineer\nCloud Engineer with verification\nSmarsh\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nCompany Description\n\nSmarsh is the leader in communications compliance, archiving, and analytics. We provide compliance across the broadest set of communications channels with insights on whats being captured. Smarsh customers manage over 500 million daily conversations across 80 channels and growing. Customers include the top 10 U.S., top 8 European, top 5 Canadian, and top 3 Asian banks. The Smarsh advantage is customers stay ahead of compliance and uncover patterns and relationships hidden within their data.\n\n\n\n\nRole Overview\n\n\n\n\nWe are seeking a talented Engineer to join our team, focusing on developing scalable integrations, APIs, and open-source solutions that contribute to our Internal Developer Portal (IDP) ecosystem. As a key team member, you will collaborate with cross-functional teams to design, implement, and maintain APIs and data pipelines that enable seamless data flow into our IDP. If you are passionate about clean code, open-source contributions, and building developer-centric tools, we want to hear from you.\n\n\n\n\nKey Responsibilities\n\n\n\n\nAPI Development:\n\nDesign, develop, and maintain robust APIs to push data into the IDP.\nEnsure high performance, scalability, and security in API implementations.\nCollaborate with teams to integrate APIs with existing systems.\n\n\n\n\nIntegration Development:\n\nBuild and maintain open-source integrations for third-party tools (e.g., monitoring systems, CI/CD pipelines, container registries).\nWrite reusable, testable, and efficient Python code to bridge systems with the IDP.\n\n\n\n\nData Processing and Transformation:\n\nDevelop data pipelines to process, transform, and push data into the IDP.\nImplement error handling and logging mechanisms to ensure reliability.\nDesign systems for data parsing and transformation, including robust handling of YAML, JSON, and other serialisation formats to normalise inputs from disparate sources.\n\n\n\n\nOpen-Source Contribution:\n\nContribute to open-source projects that enhance the IDP ecosystem.\nActively participate in the developer community by publishing and maintaining open-source tools.\n\n\n\n\nCollaboration and Communication:\n\nWork closely with DevOps, Platform Engineering, and Security teams to understand data requirements.\nDocument APIs, integrations, and workflows for internal and external stakeholders.\n\n\n\n\nCode Quality and Testing:\n\nWrite unit and integration tests to ensure code reliability.\nPerform code reviews and enforce best practices in Python development.\n\n\n\n\nRequired Skills and Qualifications\n\n\n\n\nEducation & Expereince\n\nBachelors degree in Computer Science, Engineering, or a related field (or equivalent experience).\nMinimum 4 yrs of relevant experience is needed\n\n\n\n\nTechnical Expertise:\n\nProficiency in Python with a focus on building scalable applications.\nExperience with API frameworks such as FastAPI, Django Rest Framework, or Flask.\nKnowledge of data serialisation formats (e.g., JSON, YAML).\nKnowledge of event-driven architecture.\nKnowledge of queuing system like Kafka, RabbitMQ and SQS.\nKnowledge of Role-Based Access Control (RBAC) and least-privilege principles to secure all IDP interactions.\n\nIntegration Experience:\n\nExperience building integrations with third-party tools like Jenkins, GitLab, Prometheus, or AWS.\nFamiliarity with APIs for monitoring tools, container registries, and CI/CD systems.\n\nDevOps and Cloud:\n\nUnderstanding of Kubernetes, Docker, and cloud platforms (AWS, GCP, Azure).\nFamiliarity with GitOps practices and tools like ArgoCD.\n\nData Processing:\n\nExperience with data pipelines and ETL workflows.\nKnowledge of PostgreSQL, MongoDB, or other relational/non-relational databases.\nDesign systems for data parsing and transformation, including robust handling of YAML and JSON.\n\nOpen Source:\n\nProven experience contributing to or maintaining open-source projects.\nFamiliarity with Git and GitHub workflows.\n\n\n\n\nSoft Skills:\n\nStrong communication skills and the ability to work in a collaborative environment.\nAnalytical mindset with attention to detail and problem-solving skills.\n\n\n\n\nPreferred Qualifications\n\nFamiliarity with Port or other Internal Developer Portal (IDP) tools.\nExperience with security practices, including API authentication and data encryption.\nUnderstanding of AWS, Kubernetes and DevOps practices.\nKnowledge of DORA metrics and CI/CD pipeline observability.\nExposure to Infrastructure-as-Code tools (e.g., Terraform, Pulumi).\nFamiliarity with testing frameworks like pytest or unittest.\n\n\n\n\nWhy Smarsh?\n\nReady to join a thriving tech company thats redefining digital archiving and business intelligence?\n\nSmarsh is the leading comprehensive archiving platform. Recognized as one of todays fastest growing companies in the U.S., Smarsh delivers innovative cloud-based solutions that help organizations manage and enforce flexible and secure records retention and compliance strategies for electronic communications, including social media and enterprise social networks (Yammer, Chatter, Facebook, LinkedIn and more).\n\nOur motto is People First. Inspire Confidence. Embrace the Impossible. We hire lifelong learners who have a passion for their discipline and a track record of excellence. To learn more about us, visit www.smarsh.com/careers",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4257677711": {
    "job_url": "https://www.linkedin.com/jobs/view/4257677711",
    "job_summary": "Data Engineer\nData Engineer with verification\nEssentiallySports\nIndia (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nFull Time Role at EssentiallySports for Data Growth Engineer\n\nEssentiallySports is the home for the underserved fan, delivering storytelling that goes beyond the headlines. As a media platform, we combine deep audience insights with cultural trends, to meet fandom where it lives and where it goes next.\n\nValues\n\nFocus on the user and all else will follow\nHire for Intent and not for Experience\nBootstrapping gives you the freedom to serve the customer and the team instead of investor\nInternet and Technology untap the niches\nAction oriented, integrity, freedom, strong communicators, and responsibility\nAll things equal, one with high agency wins\n\nEssentiallySports is a top 10 sports media platform in the U.S., generating over a billion pageviews a year and 30m+ monthly active users per month. This massive traffic fuels our data-driven culture, allowing us to build owned audiences at scale through organic growtha model we take pride in, with zero CAC.\n\nThe next phase of ES growth is around newsletter initiative, in less than 9 months, weve built a robust newsletter brand with 700,000+ highly engaged readers and impressive performance metrics:\n\n5 newsletter brands\n700k+ subscribers\nOpen rates of 40%-46%.\n\nThe role is for a data engineer with growth and business acumen, in the permissionless growth team. Someone who can connect the pipelines of millions of users, but at the same time knit a story of the how and why. \n\nResponsibilities\n\nOwning Data Pipeline from Web to Athena to Email, end-to-end\nYoull make the key decisions and see them through to successful user sign up\nUse Data Science to find real insights, which translates to user engagement\nPushing changes every week day\nPersonalization at Scale: Leverage fan behavior data to tailor content and improve lifetime value.\n\nWho are you?\n\n2+ years of professional data engineering experience\nSomeone who spends time thinking about business insights as much as they do on engineering\nIs a self-starter, and drives initiatives\nIs excited to pick up AI, and integrate it at various touch points\nYou have strong experience in data analysis, growth marketing, or audience development (media or newsletters? Even better).\nHave an awareness about Athena, Glue, Jupyter, or intent to pick them up\nYoure comfortable working with tools like Google Analytics, SQL, email marketing platforms (Beehiiv is a plus), and data visualization tools.\nCollaborative and want to see the team succeed in its goals\nProblem solving, proactive and solution oriented mindset, to spot opportunities and translate into real growth\nAbility to thrive in startups with a fast-paced environment and take ownership for working through ambiguity\nExcited to join a lean team in a big company that moves quickly\n\nVery flexible and open, can ask anything anytime. Real mentorship and coaching. Superb energy in whole ES team. - when team was asked how would you describe ES to a friend after a round of beers\n\nWhat do you get?\n\n\n\n\nFully Remote Job\nFlexible Working Hours\nFreedom to own the Problem Statements, and make your own solutions\nPlay with the biggest dataset, as a function of working in a media org.\nWork directly with the founding team\nRelease features at scale to Millions of Users on Day 1\nFreedom to work on multiple and new technologies\nBi-annual offsites which are coined epic by the team!\n\nThe permissionless growth team is small, which means your impact on the companys success will be huge. Youll have the chance to work with experienced leaders/founders who have built and led multiple product, tech, data and design teams, and grown EssentiallySports to a global scale.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4260043021": {
    "job_url": "https://www.linkedin.com/jobs/view/4260043021",
    "job_summary": "Python Developer (AI/ML)\nPython Developer (AI/ML) with verification\nAccolite\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nApplied",
    "job_details": "About the job\n\nSkill: Python (AI/ML)\n\nExp: 6 to 15 Yrs\n\nLocation: Bangalore/Gurgaon\n\n\n\n\nJob Description:\n\n\n\n\nKey Responsibilities:\n\nDevelop, optimize, and deploy machine learning models using Python.\nDesign and implement end-to-end ML pipelines, from data ingestion to model deployment.\nWork with large-scale datasets (structured and unstructured), conduct data preprocessing, feature engineering, and exploratory data analysis (EDA).\nApply deep learning techniques (CNNs, RNNs, Transformers) as needed for NLP, image, or video-based use cases.\nCollaborate with data scientists, MLOps engineers, and product teams to build production-grade AI solutions.\nUse version control systems (e.g., Git), model tracking tools (MLflow, Weights & Biases), and containerization (Docker, Kubernetes).\nContinuously improve models using retraining and performance evaluation.\nContribute to architectural discussions and strategic decisions on AI/ML initiatives.\n\n\n\n\nRequired Skills and Experience:\n\n1012 years of total experience in Python development, with at least 68 years in AI/ML.\nStrong knowledge of Python libraries: scikit-learn, pandas, NumPy, TensorFlow, PyTorch, Keras.\nSolid understanding of ML algorithms: regression, classification, clustering, time-series forecasting.\nHands-on experience with deep learning, NLP, or computer vision models.\nExperience working with cloud ML platforms: AWS SageMaker, GCP AI Platform, or Azure ML.\nProficiency in deploying ML models in real-time or batch production environments.\nGood understanding of CI/CD for ML, MLOps best practices, and data versioning.\nStrong problem-solving, system design, and debugging skills.\n\n\n\n\nGood to Have:\n\nExperience with big data tools: Spark, Hadoop.\nExposure to LLMs, generative AI, or Reinforcement Learning.\nFamiliarity with REST APIs, Flask/FastAPI for model serving.\nContributions to open-source ML frameworks or research papers.\n\n\n\n\nEducational Qualifications:\n\nBachelors or Masters degree in Computer Science, Data Science, Artificial Intelligence, or a related field.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": true,
    "easy_apply": false
  },
  "https://www.linkedin.com/jobs/view/4260682547": {
    "job_url": "https://www.linkedin.com/jobs/view/4260682547",
    "job_summary": "Back End Developer - E4 (Analytics)\nBack End Developer - E4 (Analytics) with verification\nWhatfix\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nEasy Apply",
    "job_details": "About the job\n\nWho are we ?\n\nFounded in 2014 by Khadim Batti and Vara Kumar, Whatfix is a leading global B2B SaaS provider and the largest pure-play enterprise digital adoption platform (DAP). Whatfix empowers companies to maximize the ROI of their digital investments across the application lifecycle, from ideation to training to the deployment of software. Driving user productivity, ensuring process compliance, and improving user experience of internal and customer-facing applications.\n\nSpearheading the category with serial innovation and unmatched customer-centricity, Whatfix is the only DAP innovating beyond the category, positioning itself as a comprehensive suite for GenAI-powered digital adoption, analytics, and application simulation. Whatfix product suite consists of 3 products - DAP, Product Analytics, and Mirror. This product suite helps businesses accelerate ROI on digital investments by streamlining application deployment across its lifecycle.\n\nWhatfix has seven offices across the US, India, UK, Germany, Singapore, and Australia and a presence across 40+ countries.\n\nCustomers: 700+ enterprise customers, including over 80 Fortune 500 companies such as Shell, Microsoft, Schneider Electric, and UPS Supply Chain Solutions. \n\nInvestors: Raised a total of ~$270 million. Most recently Series E round of $125 Million led by Warburg Pincus with participation from existing investor SoftBank Vision Fund 2. Other investors include Cisco Investments, Eight Roads Ventures (A division of Fidelity Investments), Dragoneer Investments, Peak XV Partners, and Stellaris Venture Partners.\n\n\n\n\nWith over 45% YoY sustainable annual recurring revenue (ARR) growth, Whatfix is among the Top 50 Indian Software Companies as per G2 Best Software Awards. \nRecognized as a Leader in the digital adoption platforms (DAP) category for the past 4+ years by leading analyst firms like Gartner, Forrester, IDC, and Everest Group.\nThe only vendor recognized as a Customers Choice in the 2024 Gartner Voice of the Customer for Digital Adoption Platforms has once again earned the Customers Choice distinction in 2025. We also boast a star rating of 4.6 on G2 Crowd, 4.5 on Gartner Peer Insights, and a high CSAT of 99.8%\nHighest-Ranking DAP on 2023 Deloitte Technology Fast 500 North America for Fourth Consecutive Year\nWon the Silver for Stevie's Employer of the Year 2023  Computer Software category and also recognized as Great Place to Work 2022-2023 \nOnly DAP to be among the top 35% companies worldwide in sustainability excellence with EcoVadis Bronze Medal\nOn the G2 peer review platform, Whatfix has received 77 Leader badges across all market segments, including Small, Medium, and Enterprise, in 2024, among numerous other industry recognitions.\n\n\n\n\nRoles and Responsibilities\n\nDesign, develop, test, ship, and maintain backend features independently, adhering to high engineering standards.\nBreak down features into executable tasks, ensuring timely delivery within sprint cycles \nWrite clear, concise, and well-tested code using Java and Spring Boot, aligned with platform capabilities.\nEnsure end-to-end ownership of features, including design documentation, testing, deployment, monitoring, and post-release improvements.\nMonitor production behavior of owned features and proactively address issues with appropriate automation and runbooks.\nParticipate in and conduct code reviews that are constructive, standards-compliant, and improve team code quality.\nCollaborate closely with customer-facing teams to debug production issues and improve overall system stability.\nAlign with other teams on design and integration points when touching external codebases.\nLeverage generative AI tools to improve productivity and accelerate development tasks.\nActively contribute to sprint demos and team discussions, sharing progress and insights.\n\n\n\n\nRequirements:\n\n47 years of professional backend development experience, ideally in product-based internet companies or startups.\nStrong hands-on experience with Java, Spring Boot, and web services.\nProven expertise with relational and/or NoSQL databases such as SQL, MongoDB, or Cassandra.\nExperience designing and developing scalable, distributed, and high-availability systems.\nSolid understanding of backend design principles and ability to apply them effectively.\nStrong debugging, problem-solving, and code optimization skills with a focus on performance.\nFamiliarity with CI/CD, monitoring, and alerting practices for production systems.\nExposure to or active use of generative AI tools for coding tasks.\nFast learner with a self-starter attitude, and a strong focus on code quality and customer impact.\nExcellent written and verbal communication skills, with the ability to collaborate effectively in a team environment.\n\n\n\n\nNote: \n\nWe strive to live and breathe our Cultural Principles and encourage employees to demonstrate some of these core values - Customer First; Empathy; Transparency; Fail Fast and scale Fast; No Hierarchies for Communication; Deep Dive and innovate; Trust, Do it as you own it; \nWe are an equal opportunity employer and value diverse people because of and not in spite of the differences. We do not discriminate on the basis of race, religion, color, national origin, ethnicity, gender, sexual orientation, age, marital status, veteran status, or disability status",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4260857397": {
    "job_url": "https://www.linkedin.com/jobs/view/4260857397",
    "job_summary": "Engineer I - Data Scientist [T500-18941]\nEngineer I - Data Scientist [T500-18941] with verification\nlululemon\nBengaluru, Karnataka, India (On-site)\n2 school alumni work here\n2 Indian Institute of Technology (Banaras Hindu University), Varanasi school alumni work here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout lululemon:\n\nlululemon is an innovative performance apparel company for yoga, running, training, and other athletic pursuits. Setting the bar in technical fabrics and functional design, we create transformational products and experiences that support people in moving, growing, connecting, and being well. We owe our success to our innovative products, commitment to our people, and the incredible connections we make in every community we're in. As a company, we focus on creating positive change to build a healthier, thriving future. In particular, that includes creating an equitable, inclusive and growth-focused environment for our people. As we continue to elevate our shopping experience, our India Tech Hub plays a key role in expanding our technology capabilities in Product Systems, Merchandising and Planning, Digital Presence, distribution and logistics, and corporate systems. Our team in India works as an extension of the global team on projects of strategic importance.\n\n\n\n\nAbout the team:\n\nThe opportunity is for a role in the Content team. Our team is fast-paced and taking on exciting new initiatives to support a fast-growing business. We strive to adopt leading-edge technology and seek to continuously improve on the solutions we have. We are not afraid to try new things, have fun, and encourage each other to take on new challenges. We support each other in growing professionally and personally. We fail forward and learn from our mistakes, thus creating a better path ahead. We create space for team members to share feedback and ideas that can help us continually grow as an organization.\n\nWe operate in agile methodology and contribute to product teams across our various functions as well as a core commerce platform team. We institute a culture of fun and lightheartedness to enjoy work each day. We are inclusive and know that we are stronger as a team than as an individual.\n\n\n\n\nResponsibilities:\n\nDevelop Statistical/Machine Learning models / analysis for Merchandising and Planning Business problems\nPlay a key role in all stages of the Data science project life cycle\nCollaborate with Product Management, Business teams to gain Business understanding, Collect requirements\nIdentify data sources required, automate collection process\nPerform pre-processing, exploratory data analysis\nEvaluation / Interpretation of results and presentation to Stakeholders, Business leaders\nCollaborate with engineering and product development teams for deploying models into production systems, when applicable\n\n\n\n\nRequirements and skills:\n\nProven experience in technical delivery of solutions with Time Series / Machine Learning techniques\nStrong applied Statistical skills, including knowledge of Statistical tests, distributions etc.\nStrong applied Machine Learning skills (Time Series, Regression Analysis, Supervised and Unsupervised Learning)\nStrong Programming Skills in Python and database query languages like SQL . Familiarity with Snowflake & Databricks is an added advantage\nExperience with time series forecasting techniques such ARIMA, Prophet, Deep AR\nExperience with data visualization libraries like Plotly, Business intelligence tools (e.g. PowerBI, Tableau)\nExcellent communication and presentation skills\nExperience in Retail industry\n\n\n\n\nResponsibilities:\n\nIdentify valuable data sources and automate collection processes\nUndertake preprocessing of structured and unstructured data\nAnalyze large amounts of information to discover trends and patterns\nBuild predictive models and machine-learning algorithms\nCombine models through ensemble modeling\nPresent information using data visualization techniques\nPropose solutions and strategies to business challenges\nCollaborate with engineering and product development teams",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4263512255": {
    "job_url": "https://www.linkedin.com/jobs/view/4263512255",
    "job_summary": "SDE-3 Backend\nSDE-3 Backend with verification\nJupiter\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nApplied",
    "job_details": "About the job\n\nWho we are\n\nMoney. A subject thats always on our mind. We go through a rollercoaster of emotions when it comes to money. Thats why at Jupiter, our mission is to enable people to improve their relationship with money.\n\n\n\n\nWe are a financial services platform that leverages technology to offer our customers seamless and user-friendly products related to banking, loans, and investments. So whether its a savings account, credit cards, investment and payments, it's all on Jupiter. We also help users cut through the banking jargons, offer smart insights based on spending and provide users with a range of new age features to enable and make sense of their finances.\n\n\n\n\nOur journey so far\n\nJupiter was founded in 2019 by Jitendra Gupta. Best known as Citrus Pays founder, Jiten found himself wondering why personal finance experiences were not customer-centric when everything else like food ordering and entertainment were. Thats how our journey began in 2019, with a simple, powerful idea: to create a modern, customer-centric experience that empowers individuals when it comes to their money.\n\n\n\n\nFrom our humble beginnings, we've strived relentlessly to make managing money easier. In 2021 when we launched we had a waitlist with over 100,000 people eager to experience the world of Jupiter  and within 10 months we crossed 1 million users. Today, we have 2.7 million+ happy users on Jupiter.\n\n\n\n\nOur Insights feature today tells how much and where youve been spending automatically, even on your other savings accounts! Our Edge CSB Bank RuPay credit card is getting a lot of love for its head-turning transparent design, not to mention it being a rewarding experience. Our No-Penalty SIP and Daily SIP at Rs 10/- has helped scale our investments business and we have over 100,000 users investing on our platform to fulfill their money aspirations.\n\n\n\n\nWe've embraced cutting-edge technology, harnessed the power of data analytics, and assembled a diverse team of creative thinkers and industry experts who share our vision for a more accessible, transparent, and inclusive financial ecosystem. Were now looking for like-minded folks to join the crew.\n\n\n\n\nRoles and responsibilities:\n\nDesign & build backend systems with high reliability and availability\nAbility to work independently and in a team with least supervision\nCollaborate with Product, Design, and other Engineering teams\nOwn services end-to-endfrom planning to monitoring & scaling\nMentor junior engineers and elevate the tech bar\n\n\n\n\nWhat were looking for\n\n6+ years of backend experience in Java/Python/Golang\nStrong background in distributed systems, REST APIs, microservices\nSolid experience with SQL & NoSQL databases\nHands-on experience with AWS\nProduct-thinking mindset & experience owning production systems\nAbility to solve complex problems & keen attention to detail\nAgile, fast-paced environment comfort\n\n\n\n\nWhy you should work with us\n\nWe like people who behave like owners, and we place a high regard on those who take ownership and see projects through to completion.\nWe take pleasure in tackling meaningful problems by understanding pain points and developing intuitive experiences that delight customers.\nWe appreciate those who can participate in healthy conflict and are able to commit to every decision as if it were their own. We value consent, over consensus.\nIn our relentless pursuit of excellence, we consistently set higher standards. If you crave continuous learning, growth, and improvement in a dynamic environment, choosing Jupiter is the right move.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": true,
    "easy_apply": false
  },
  "https://www.linkedin.com/jobs/view/4261884795": {
    "job_url": "https://www.linkedin.com/jobs/view/4261884795",
    "job_summary": "Software Engineer\nSoftware Engineer\nNexthop AI\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nEasy Apply",
    "job_details": "About the job\n\nCompany Description: \n\nAs an AI infrastructure startup, we are developing innovative systems to enable large-scale AI deployments. Our team comprises industry veterans who are passionate about building the sophisticated systems that support the next generation of computing in a fast-paced startup environment.\n\n\n\n\nAbout the Role: \n\nAs a Software Engineer, you wont just write code, youll architect systems, work closely with customers, own products end-to-end and help shape both our tech stack and culture. From early design to production support, youll have visibility, impact and ownership every step of the way. \n\n\n\n\nJob Responsibilities:\n\nParticipate in all parts of software engineering, ranging from design and implementation of software solutions to testing and peer review\nCollaborate with engineers on building and optimising our core systems\nSupport customers at various stages of development through involvement in project scoping, proof of concept, early trials, and production/escalation support\nBe a part of shaping a startup - define company culture, challenge and change the ways things are done, and contribute to determining the future of the company\n\n\n\n\nQualifications: Strong problem-solving skills, quick learning and excitement for a collaborative startup environment are the most important things we're looking for. The list below are some of the qualifications that will help but arent essential to thriving here.\n\n \n\nBachelors degree in Computer Science, Software Engineering, Electrical Engineering or a related field with a minimum of 5 years of industry experience\nProficiency in the following languages: Python, C, or C++\nSolid understanding of systems software, including embedded systems and distributed systems\nFamiliarity with container technologies (e.g., Docker) and databases (e.g., SQL, NoSQL) is a plus\nGood communication skills and ability to work collaboratively in a team\nConfidence to both ask questions and take ownership of your project(s)",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4250524996": {
    "job_url": "https://www.linkedin.com/jobs/view/4250524996",
    "job_summary": "Generative AI Engineer\nGenerative AI Engineer with verification\nToddle - Your Teaching Partner\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nToddle is a teacher-built, AI-first teaching and learning platform that goes beyond a typical LMS. We help educators streamline their entire workflow  from curriculum planning and assessments to student portfolios, gradebook, progress reports and family communication  all from one intuitive interface.\n\n\n\n\nIn the past two years, weve deeply embedded AI across our entire platform to reduce teachers administrative workload and help them focus on what really matters: delivering meaningful, personalised instruction. Whether its planning lessons, assessing student work, or writing report cards, Toddle AI is built to support teachers in all their work.\n\n\n\n\nToday, 2,000+ schools and districts across 100+ countries use Toddle to simplify and elevate their teaching. We are backed by leading global investors, including GSV and Sequoia Capital.\n\n\n\n\nHeres what youll be doing\n\nWe are seeking a talented and mission-driven Generative AI Engineer to join our growing team. In this role, you will play a central part in architecting and building next-generation AI-powered tools for education using cutting-edge technologies such as large language models (LLMs), agentic systems, and multimodal AI.\n\n\n\n\nYoull work on designing intelligent, adaptive systems that can reason, plan, and interact in dynamic educational settings. This role is deeply interdisciplinary and impact-focused: youll collaborate with educators, curriculum designers, and product teams to develop AI that is useful, safe, and truly supportive of learning.\n\n\n\n\nYoull also have the unique opportunity to test and iterate on these tools directly in genuine educational environments, gathering real feedback from teachers, students, and parents to continuously improve the product experience.\n\n\n\n\nMust-have Skills:\n\nAbility to design scalable, modular, and secure AI system architectures that can support real-world use in production.\nExperience with cloud based model providers and their APIs (AWS, GCP, Azure) \nStrong knowledge of LLM prompt design patterns, prompt chaining and failure handling.\nStrong debugging, testing, and optimization skills for LLM-based applications.\nProficient in Python and Node.js\n\n\n\n\nGood to Have:\n\nHands-on expertise in architecting complex agentic systems such as tool-using agents, memory-augmented workflows, or multi-agent coordination\nUnderstanding of Model context protocols and how to integrate them into multi-agent LLM stacks\nFamiliarity with ethics in AI, explainability, and responsible deployment in sensitive domains like education.\nFamiliarity with AIOps workflows and tools\n\n\n\n\nIs this someone that looks like you?\n\nEducation: B.E/B.Tech degree\nExperience: 2+ years of relevant working experience (SaaS preferred)\nSoft Skills: Having a bias towards action, a good sense of design, empathy, and good communication skills\nWe deeply value building the right culture at Toddle, and these are a few things that we look for in each hire - Coach-ability, Curiosity, Ownership, Hustle, and Humility \nLocation: Bangalore, Onsite\n\n\n\n\nExcited about the role?\n\nHere are some more benefits:\n\n\n\n\n1) Flexibility at work\n\nWork from anywhere  home, co-working space, cafe or even the hills\nBlock no-meeting hours to enable uninterrupted focused work\n\n\n\n\n2) Exposure to diverse learning opportunities\n\nWork across different projects & teams to develop skills outside of your core expertise\nAccess to a small budget towards learning (e.g. books, online courses, substacks)\n\n\n\n\n3) Industry best leave policy\n\nWe trust you fully on your commitment to our mission and your judgement on planning your time and taking leaves:\n\nNo cap on the number of sick or casual leaves\nSpecial paid leaves for childbirth, wedding etc.\n\n\n\n\n4) No bell curve performance evaluations\n\nWe put in a lot of work to hire the best, and therefore we dont expect anyone to deliver less than the best!\n\n\n\n\n5) And yes, a super fun and diverse group of folks to collaborate and grow with\n\n\n\n\nStill with us? Heres the process:\n\n1) Shortlisting:\n\nComplete the form on this page\nWell check out your application and assess it for a fit\nYou will hear back from us within 2-3 days of the submission if shortlisted\n\n\n\n\n2) Once shortlisted, we usually do about 2-3 rounds of interviews, a written assignment, and deep reference checks\n\n\n\n\n3) We value everyones time hence we make it a point to communicate proactively at all stages of your application. You can always reach out to us for any questions",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4257108080": {
    "job_url": "https://www.linkedin.com/jobs/view/4257108080",
    "job_summary": "Data Engineer(Treasure data)\nData Engineer(Treasure data)\nupGrad\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nApplied",
    "job_details": "About the job\n\nKey Result Areas and Activities:\n\n1. Technical Leadership\n\no Lead data engineering efforts in acquisition, transformation, and distribution across multiple projects and squads.\n\no Ensure technical excellence and innovation in data engineering practices.\n\n2. Framework and Product Evolution\n\no Drive the adoption and evolution of data management technologies, including ETL/ELT tools, open-source frameworks, and workflow management tools.\n\no Implement best-in-class solutions to enhance data engineering capabilities.\n\n3. Architectural Improvement\n\no Provide strategic recommendations to improve the overall data engineering architecture.\n\no Focus on creating a scalable and cost-effective data ecosystem.\n\n4. Knowledge Sharing\n\no Continuously learn from peers and industry trends.\n\no Share expertise across teams and clients to foster a culture of knowledge exchange.\n\n5. Support for Cloud and Data Engineering COE Initiatives\n\no Actively engage in initiatives led by the Cloud and Data Engineering Center of Excellence (COE).\n\no Contribute to COE projects, research, and innovation efforts.\n\n\n\n\nWork and Technical Experience:\n\nEssential Skills:\n\n Excellent understanding of enterprise data warehousing principles of ETL/ELT and the tools/technologies used to implement them\n\n Proven experience with Treasure Data, including designing and maintaining complex workflows.\n\n Strong knowledge of Dig Dag files\n\n Strong knowledge of Presto SQL and Optimisation techniques\n\n Experience with Python and relational databases\n\n Familiarity with cloud platforms (e.g., AWS) and their data services\n\n\n\n\nDesirable Skills:\n\n Experience with version control systems such as Git\n\n knowledge of Airflow or other orchestration tool\n\n\n\n\n\n\n\nQualifications:\n\n Overall work experience 7+ years good focus on Treasure data\n\n Experience with or knowledge of Agile Software Development metodologies\n\n Technical certifications that attribute to continuous learning aspirations\n\n\n\n\nQualities:\n\n Inherent curiosity and empathy for customer success\n\n Obsessive about solving customer problems\n\n Think long and act short\n\n Collaborative with your peers, partners and your team\n\n Excited about the mission and milestones not titles and hierarchies\n\n Nurture an environment of experimentation and learning\n\n Strong problem-solving skills and attention to detail\n\n Excellent communication and collaboration skills",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": true,
    "easy_apply": false
  },
  "https://www.linkedin.com/jobs/view/4259143190": {
    "job_url": "https://www.linkedin.com/jobs/view/4259143190",
    "job_summary": "Python Cloud Engineer (ML)\nPython Cloud Engineer (ML)\nTorry Harris Integration Solutions\nGreater Bengaluru Area (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob Description\n\nWe are looking for a Senior Software Engineer who is passionate about writing clean, scalable, and secure code. If you take pride in building sustainable applications that meet customer needs and thrive in a collaborative, agile environment, this role is for you. Youll work with experienced engineers across the enterprise and gain exposure to a variety of automation and cloud technologies.\n\nAs a Python developer, you will contribute to complex assignments involving cloud-native architectures, automation pipelines, serverless computing, and object-oriented programming.\n\nTechnical Skills:\n\nProficiency in Python and cloud platforms (AWS, Azure)\nExperience with MLFlow, Kubernetes, Terraform, AWS SageMaker, Lambda, Step Functions\nFamiliarity with configuration management tools (Terraform, Ansible, CloudFormation)\nExperience with CI/CD pipelines (e.g., Jenkins, Groovy scripts)\nContainerization and orchestration (Docker, Kubernetes, ECS, ECR)\nUnderstanding of serverless architecture and cloud-native application design\nKnowledge of infrastructure as code (IaC), IaaS, PaaS, and SaaS models\nExposure to AI/ML technologies and model management is a plus\nStrong verbal and written communication skills\n\nQualifications:\n\nBachelors degree in Computer Science, Information Systems, or a related field\n4+ years of experience in architecting, designing, and implementing cloud solutions on AWS and/or Azure\nProven experience with both relational and non-relational database systems\nExperience leading data architecture or cloud transformation initiatives\nStrong troubleshooting and analytical skills\nRelevant certifications in AWS or Azure preferred\n\n\n\n\nRoles & Responsibilities\n\n\n\n\nAnalyze and translate business requirements into scalable and resilient designs\nOwn and continuously improve parts of the application in an agile environment\nDevelop high-quality, maintainable products using best engineering practices\nCollaborate with other developers and share design philosophies across the team\nWork in cross-functional teams including DevOps, Data, UX, and QA\nBuild and manage fully automated build/test/deployment environments\nEnsure high availability and provide rapid response to production issues\nContribute to the design of useful, usable, and desirable products\nAdapt to new programming languages, platforms, and frameworks as needed\n\n\n\n\nMandatory Skills\n\nPython, AWS, Azure Cloud, ML & Model Management",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4265315333": {
    "job_url": "https://www.linkedin.com/jobs/view/4265315333",
    "job_summary": "Software Engineer\nSoftware Engineer\nTEKsystems\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nEasy Apply",
    "job_details": "About the job\n\nKey Responsibilities:\n\nSoftware Development:\n\nDesign and develop a C++ framework for controlling various systems in IC manufacturing equipment.\n\nCollaborate with cross-functional teams to integrate hardware and software components seamlessly.\n\nEnsure the framework is scalable, reliable, and efficient for industrial applications.\n\nControl Systems Programming:\n\nDevelop and optimize software for robotic systems such as wafer handlers.\n\nProgram control logic for vacuum, mechanical, and chemical chambers.\n\nTroubleshooting and Testing:\n\nDebug and resolve software issues in hardware-software integration.\n\nConduct functional and performance testing to ensure system reliability.\n\nCollaborate with QA teams to validate the framework against specifications.\n\nStakeholder Collaboration:\n\nInteract with domestic and international stakeholders to understand requirements and ensure project alignment.\n\nProvide regular updates on project progress to the leadership team.\n\n \n\nTechnical Skills:\n\nStrong proficiency in C++ (experience with VC++ is acceptable).\n\nHands-on experience with control systems and industrial automation.\n\nFamiliarity with developing desktop applications on Windows (Linux experience is a plus).\n\nExperience with hardware-software integration.\n\nPreferred Experience:\n\nBackground in medical devices, semiconductor equipment, or companies such as Samsung, Intel, Honeywell, or Siemens.\n\nKnowledge of robotic systems and real-time software development.\n\nSoft Skills:\n\nExcellent problem-solving and logical reasoning abilities.\n\nStrong communication skills for stakeholder interaction.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4264475055": {
    "job_url": "https://www.linkedin.com/jobs/view/4264475055",
    "job_summary": "Data Engineer\nData Engineer\nStealth Startup\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nLocation: Preferred: Bangalore (On-site); Alternatives: Mumbai, Kathmandu (On-site)\n\nType: Contract work, with potential for conversion to full time.\n\nDuration: August - December 2025\n\n\n\n\nWho We Are:\n\nWe are recent MIT graduates experienced in digital transformation and AI, with expertise in various sectors including consulting, energy, healthcare, tech and operations. We are looking to build tailored solutions for companies looking to leverage the latest developments in agentic AI, LLMs and optimization tools. To this end, we are contracting high-skilled individuals to help us with project execution. As we develop a pipeline of projects, there is potential for applicants to convert to a full-time role within the company.\n\nRole Summary:\n\nWe are hiring two Data Engineers to support infrastructure, data pipeline development, and deployment of pricing logic for a data-rich e-commerce platform serving the life sciences sector. Beyond data processing, this role emphasizes usability and interface design for internal tools that enable experimentation, pricing configuration, and real-time monitoring.\n\nKey Responsibilities:\n\nBuild and maintain ETL pipelines for pricing, shipping, and behavioral datasets\nCollaborate with data scientists and product managers to support model development and experimentation\nDevelop APIs or backend logic to implement dynamic pricing algorithms\nCreate internal dashboards or tools with a focus on usability and performance\nEnsure data quality, reliability, and documentation across systems\nPerform feature engineering to feed predictive and optimization algorithms\nAggregate and transform high-dimensional datasets at scale to ensure modeling efficiency and robustness\nOptimize algorithm performance for real-time and large-scale deployment\n\nRequirements:\n\nFlexibility in working with young, startup-like environments. The role is dynamic, and will require an ability to adapt to various tasks and come up with creative solutions to unforeseen challenges\n3+ years of experience in data engineering or backend development\nStrong hands-on experience with Databricks and distributed data processing frameworks\nStrong Python and SQL expertise; experience with cloud-based platforms (e.g., AWS, BigQuery, Snowflake)\nDemonstrated ability to design and develop user-friendly internal tools or interfaces\nFamiliarity with experimentation systems and monitoring infrastructure\nExperience handling large-scale, high-dimensional datasets efficiently\nDomain experience in e-commerce is preferred; knowledge of the pharmaceutical or scientific supply sector is a strong advantage\n\n\n\n\n\n",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4256056173": {
    "job_url": "https://www.linkedin.com/jobs/view/4256056173",
    "job_summary": "Needed Python Developer\nNeeded Python Developer\neProSoft\nIndia (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob Title: Python Developer  (LLM/Lang chain)\n\nCompany: eProSoft Inc.\n\nLocation: Remote\n\nJob Type: Full-time\n\nAbout Us\n\neProSoft Inc. is a cutting-edge technology company specializing in language processing and block chain solutions. We are dedicated to pushing the boundaries of innovation to create transformative products that revolutionize industries. Our team consists of highly skilled professionals who are passionate about leveraging technology to solve complex problems.\n\nJob Description\n\nWe are seeking a talented Python Developer with a minimum of 3+ years of experience and expertise in either LLM (Large Language Models) or Lang chain (Language-based block chain solutions) to join our dynamic team. As a Python Developer, you will play a crucial role in developing and implementing advanced algorithms and solutions that leverage language processing and block chain technologies. You will collaborate with cross-functional teams to design, build, and deploy innovative products that address real-world challenges.\n\nResponsibilities\n\n\nDesign, develop, and maintain scalable Python-based applications and systems.\nImplement algorithms and data structures for language processing and block chain solutions.\nCollaborate with data scientists, engineers, and other stakeholders to translate requirements into technical specifications.\nConduct code reviews, testing, debugging, and troubleshooting to ensure high-quality software delivery.\nStay updated with the latest advancements in LLM, Lang chain, and related technologies.\nParticipate in architectural design discussions and contribute to technical decision-making processes.\nDocument code, processes, and best practices for knowledge sharing and future reference.\n\n\nRequirements\n\n\nBachelor's or Master's degree in Computer Science, Engineering, or related field.\nMinimum of 3+ years of experience as a Python Developer with a focus on LLM or Langchain development.\nStrong proficiency in Python programming language and its libraries/frameworks.\nExperience with natural language processing (NLP) techniques and tools (for LLM role).\nFamiliarity with blockchain concepts, protocols, and development tools (for Langchain role).\nSolid understanding of software development principles, algorithms, and data structures.\nExcellent problem-solving skills and attention to detail.\nAbility to work independently and in a team environment.\nEffective communication skills and the ability to collaborate with cross-functional teams.\nExperience with agile development methodologies is a plus.\n\n\nJoin our team and contribute to building groundbreaking solutions at the intersection of language processing and block chain technology. If you are passionate about innovation and enjoy solving complex challenges, we'd love to hear from you. Apply now!\n\nIf interested, Please share your resume with Dkadam@eprosoft.com",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4268780691": {
    "job_url": "https://www.linkedin.com/jobs/view/4268780691",
    "job_summary": "Software Engineer\nSoftware Engineer\nBU Consultants\nBengaluru, Karnataka, India (On-site)\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nBU Consultants is an IT Consulting Company focused on providing Software Development and IT Enabled Services to FAANG Companies in the USA, Canada & APAC regions. \n\n We are Hiring: Software Developer/SDE1\n\n : Software Developer/SDE1\n\n Company: BU Consultants (Working Amazon Projects)\n\n Location: BLR\n\n Compensation: 10-20 LPA\n\n Type: Full Time\n\n\n\n\n\n\n\n  :\n\n- Assist in developing scalable software solutions and services\n\n- Participate in the full software development lifecycle\n\n- Write clean, maintainable code following team standards\n\n- Collaborate with senior developers and team members\n\n- Contribute to testing and debugging processes\n\n- Learn and implement best practices in software development\n\n\n\n\n  :\n\n- Experience with software development life cycle\n\n- Familiarity with code review processes and source control management\n\n- Basic understanding of AWS services\n\n- Strong problem-solving skills & DSA\n\n- Good communication and teamwork abilities\n\n- Selenium knowledge is plus",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4266680703": {
    "job_url": "https://www.linkedin.com/jobs/view/4266680703",
    "job_summary": "Python/React Full stack developer\nPython/React Full stack developer with verification\nSopra Steria\nBengaluru, Karnataka, India (On-site)\n1 school alum works here\n1 Indian Institute of Technology (Banaras Hindu University), Varanasi school alum works here\nViewed\nEasy Apply",
    "job_details": "About the job\n\nCompany Description\n\nAbout Sopra Steria\n\nSopra Steria, a major Tech player in Europe with 50,000 employees in nearly 30 countries, is recognised for its consulting, digital services and solutions. It helps its clients drive their digital transformation and obtain tangible and sustainable benefits. The Group provides end-to-end solutions to make large companies and organisations more competitive by combining in-depth knowledge of a wide range of business sectors and innovative technologies with a collaborative approach. Sopra Steria places people at the heart of everything it does and is committed to putting digital to work for its clients in order to build a positive future for all. In 2024, the Group generated revenues of 5.8 billion.\n\nJob Description\n\nThe world is how we shape it.\n\nPrimary: \n\nPython, React, HTML, CSS, FastAPI\n\nGood knowledge of Agile/SAFe.\n\nSecondary: \n\nMicroservice, Full stack frameworks\n\nGood to have:\n\nKnowledge on AWS (lamda & API gateway), Pytest is an advantage\n\nTotal Experience Expected: 04-06 years\n\nQualifications\n\nB.Tech\n\nAdditional Information\n\nAt our organization, we are committed to fighting against all forms of discrimination. We foster a work environment that is inclusive and respectful of all differences.\n\nAll of our positions are open to people with disabilities.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4268281876": {
    "job_url": "https://www.linkedin.com/jobs/view/4268281876",
    "job_summary": "Sr Software Engineer- 9910- GOLANG, GNMI, YANG, OPENCONFIG, MICROSERVICE\nSr Software Engineer- 9910- GOLANG, GNMI, YANG, OPENCONFIG, MICROSERVICE with verification\nExtreme Networks\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nOver 50,000 customers globally trust our end-to-end, cloud-driven networking solutions. They rely on our top-rated services and support to accelerate their digital transformation efforts and deliver unprecedented progress. With double-digit growth year over year, no provider is better positioned to deliver scalable outcomes than Extreme.\n\n\n\n\nInclusion is one of our core values and in our DNA. We are committed to fostering an inclusive workplace that embraces our differences and creates an atmosphere where all our employees thrive because of their differences, not in spite of them.\n\n\n\n\nBecome part of Something big with Extreme! As a global networking leader, learn why theres no better time to join the Extreme team.\n\n\n\n\n\n\n\nPOSITION : Sr Software Engineer\n\nEXPERIENCE : 4+ to 8 years\n\nLOCATION : BANGALORE\n\nKEYWORDS : GOLANG, GNMI, YANG, OPENCONFIG, MICROSERVICE, NATS, JETSTREAM, REDIS, VALKEY, GIT\n\n\n\n\nDescription\n\n\n\n\nWe are seeking a highly skilled Engineer to design and develop management infrastructure software for Switching and Routing products with a 4-8+ years track record of relevant work experience.\n\n\n\n\nSkill required:\n\n\n\n\nRoles & Responsibilities\n\n\n\n\nDesign and develop Management Infrastructure software solutions for Switching and Routing products\n\nAnalyze technical feasibility of requirements and deliver release features\n\nWrite detailed Design specs, conduct design reviews, code, unit-test in Agile development environment\n\nParticipate in strategic and tactical product initiatives\n\nQuickly troubleshoot customer escalations and provide solutions on time\n\nParticipate in design reviews, architecture discussions, implementation, unit-testing, and maintenance\n\n\n\n\n\n\n\nQualifications:\n\n\n\n\nEducation qualification must include BE/BTech in Computer Science or related areas\n\nOverall, 5-8 years of software development experience\n\nProficiency in programming languages such as GoLang, C, C++ or similar\n\nStrong problem-solving skills, with ability to navigate and resolve complex technical issues\n\nSolid understanding of microservices architecture and API design\n\nFamiliarity with CI/CD pipelines, git and agile methodologies\n\nExcellent communication skills, both verbal and written\n\n\n\n\nPreferred skills:\n\n\n\n\nExperience in GoLang programming language\n\nKnowledge of YANG, OpenConfig, RPCs, GNMI\n\nWork experience in Databases (Redis, Postgres) , Message bus (NATS, RabbitMQ, etc)\n\nGood understanding of microservice architecture\n\nExperience using Git, JIRA, Jenkins, Confluence",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4270227960": {
    "job_url": "https://www.linkedin.com/jobs/view/4270227960",
    "job_summary": "SDE III Backend\nSDE III Backend\nSuperAGI\nBangalore Urban, Karnataka, India (On-site)\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout Us:\n\nSuperAGI is pioneering the future of Artificial General Intelligence with groundbreaking research and innovative AI products. Our mission is to transform the future of applications through intelligent, autonomous solutions that drive unparalleled efficiency and growth. We are building a world where AI and human intelligence collaborate seamlessly to achieve extraordinary outcomes. If you are passionate about AI and eager to be part of a team that is shaping the future, SuperAGI is the place for you.\n\n\n\n\nJob description:\n\nAs a Software Development Engineer III, you'll be integral in developing, testing, and deploying high-quality software solutions. With expertise in multiple programming languages and best practices, you'll ensure scalable and maintainable code.\n\n\n\n\nDesired Background:\n\nYou can design & implement scalable, resilient backend microservices\nYou can implement reliable monitoring stack for your services\nYou are familiar with AWS cloud ecosystem\nYou can plan, estimate, and own the deliveries of your project\nYou can collaborate with the engineering and product teams to deliver the right strategic and tactical goals for the business\n\n\n\n\nRequired Skills:\n\n3-6 years of experience building backend micro-services in a production environment.\nAdvanced proficiency in working with managed cloud providers, particularly AWS, and have experience designing, deploying, and maintaining cloud-native applications.\nDeep expertise in backend development with the JVM stack, using Java, Kotlin, or other relevant technologies. You are also capable of guiding the team on architectural decisions, optimizing for performance, scalability, and maintainability.\nStrong knowledge of monitoring stacks (Prometheus, Grafana, NewRelic, etc.), and the ability to design and implement effective observability strategies for large-scale distributed systems.\nExtensive experience with the Kubernetes ecosystem, and the ability to manage, scale, and troubleshoot complex microservice architectures.\nExpertise in selecting the right data structures, algorithms, and design patterns based on business requirements and system constraints, with a strong emphasis on optimization and efficiency.\nIn-depth experience working with relational and NoSQL databases (e.g., PostgreSQL, Redis, MySQL, DynamoDB), and designing robust, scalable data storage solutions.\nHands-on experience with messaging systems like Apache Kafka, and you are capable of designing and implementing event-driven architectures that scale.\nStrong problem-solving and debugging skills, especially in production environments, with a focus on resilience and fault tolerance.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4261135251": {
    "job_url": "https://www.linkedin.com/jobs/view/4261135251",
    "job_summary": "Azure Data Engineer\nAzure Data Engineer with verification\nHDFC Bank\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nGood Understanding of Azure Cloud Engineering  ADLS, Iceberg, Databricks, AKS, RHEL\nFundamentals of DevOps, DevSecOps, CD / CI Pipeline using ADO\nGood understanding of MPP Architecture, MySQL, RDS, MS-SQL DB, Oracle ,Postgres DB\nWould need to interact with Software Integrators on a day-to- day basis.\nDeployment and testing skills  Strong communication skills\nELT - Trino, Azure Data factory, Azure Databricks, PySpark, Python, Iceberg, Parquet\nCDC Tool like Qlik/ Golden Gate/Dbsium/IBM CDC, Kafka/ Solace\nScripting  Shell, Python, Java,\nGood understanding of MS- Project Development skill using Trino, PySpark and Databricks2 or more years of experience of software or application development and implementation\nExperience with data integration concepts",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4190227572": {
    "job_url": "https://www.linkedin.com/jobs/view/4190227572",
    "job_summary": "Back End Developer\nBack End Developer with verification\nHGS\nBengaluru, Karnataka, India (On-site)\n1 school alum works here\n1 Indian Institute of Technology (Banaras Hindu University), Varanasi school alum works here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nWant to join a startup, but with the stability of a larger organization? Join our innovation team at HGS that's focused on building SaaS products. If you are highly driven & passionate person who'd like to build highly scalable SaaS products in a startup type of environment, you're welcome to apply.\n\nThe HGS Digital Innovation Team is designed to create products and solutions relevant for enterprises, discover innovations and to contextualize and experiment with them within a specific industry. This unit provides an environment for the exploration, development, testing and solutions of Cloud-based Contact Center As A Service (CCaaS). In addition to that it also looks at rapid deployment at scale and sustainability of these solutions for target business impacts.\n\nResponsibilities: \n\nAs a core member of our development team, you will design and develop new product ideas and features from conception to final implementation that improve business operations and manage the complexity inherent in technology upgrades and changes.\nDesign and develop server-side applications while leveraging cloud infrastructure to ensure scalability, security, and high performance using Node.js, Express.js, or other relevant JavaScript frameworks.\nDeploy, manage, and optimize backend applications on AWS, leveraging services such as EC2, Lambda, S3, RDS, Elastic Beanstalk, and ECS.\nIntegrate Azure OpenAI services, such as GPT, Codex, and other language models, into backend systems to power AI-driven features (e.g., natural language processing, automated code generation, AI-powered chatbots).\nDevelop RESTful and GraphQL APIs for efficient data exchange between frontend applications and backend services.\nImplement best practices for API security, including JWT, OAuth, and token-based authentication.\nDesign, manage, and optimize databases such as MongoDB, MySQL, PostgreSQL, or Redis. Write efficient queries, manage schema design, and ensure data consistency and security.\nDevelop scalable and maintainable backend systems following microservices or serverless architecture patterns when applicable.\nAnalyzing complex project-related problems and creating innovative solutions involving, discovery, scheduling, technology, methodology, tools, and solution components.\nWork with sales, product, and operations teams to build solutions that are well-planned and delivered on-time.\n\nQualifications: Bachelor's degree or equivalent in information systems or related field. \n\n6+ years of product development experience building large-scale web applications.\nProfessional level understanding of web front-end and back-end languages and technologies (e.g. React, Node, JavaScript, and TypeScript)\nExpertise in development of RESTful APIs using message formats such as JSON or XML\nExpertise in designing serverless and microservices architectures using AWS Lambda, API Gateway, ECS, EC2, S3, DynamoDB and SQS.\nHands-on experience integrating Azure OpenAI services like GPT, Codex, and Azure Cognitive Services into backend applications.\nExperience with relational databases like MySQL, PostgreSQL, and NoSQL databases such as MongoDB, DynamoDB, and Azure Cosmos DB.\nActively participate in Design, Code review, Backlog grooming, Agile ceremonies, and work with peers to meet team's sprint commitments.\nExcellent communication and collaboration skills, with the ability to work effectively in a team environment.\nStrong analytical and problem-solving skills, with the ability to identify issues and develop solutions quickly.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4263897589": {
    "job_url": "https://www.linkedin.com/jobs/view/4263897589",
    "job_summary": "Data Engineer\nData Engineer with verification\nNP Group\nIndia (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nData Engineer - Python, Pyspark & Palantir Foundry\n\n\n\n\nFully Remote \n\n\n\n\nLong Term Contract \n\n\n\n\nRate: $10-13 ph ($1,600 - $2,000 per month)\n\n\n\n\nWe have an immediate requirement for an experienced Data Engineer to join the global engineering team for a International Enterprise Organisation.\n\n\n\n\nYou will bring Data Engineering expertise onto greenfield multi year project initiative.\n\n\n\n\nYou should offer at least 5-8 years exp. as a Data Engineer with strong experience of the following technologies:\n\n\n\n\nPython\nPySpark\nSQL\nPalantir Foundry - highly advantageous",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4266680995": {
    "job_url": "https://www.linkedin.com/jobs/view/4266680995",
    "job_summary": "Senior Data Engineer [T500-19181]\nSenior Data Engineer [T500-19181] with verification\nFM\nBengaluru, Karnataka, India (On-site)\n1 company alum works here\n1 Walmart Global Tech India company alum works here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout FM:\n\nFM is a 190-year-old, Fortune 500 commercial property insurance company of 6,000+ employees with a unique focus on science and risk engineering. Serving over a quarter of the Fortune 500 and major corporations globally, they deliver data-driven strategies that enhance resilience, ensure business continuity, and empower organizations to thrive. \n\nFM India located in Bengaluru is a strategic location for driving FM's global operational efficiency that allows them to leverage the countrys talented workforce and advance their capabilities to serve their clients better.\n\n\n\n\nRole Title: Senior Data Engineer\n\nPosition Summary:\n\nThis role is responsible for analysis, data modeling, data collection, data integration, and preparation of data for consumption. It is responsible for creating and managing data infrastructure, data pipeline design, implementation and data verification. Along with the team, it is responsible for ensuring the highest standards of data quality, security and compliance. Displays personal accountability for successful outcomes and support quality efforts within the team. Interfaces with colleagues and other stakeholders to evaluate defined business requirements and processes. Uses available approved technologies. This role will implement methods to improve data reliability and quality, combine raw information from different sources to create consistent data sets. It will need to be well versed in DataOps and have learned, and are capable of using, relevant technologies. This is the second level position in the Data Engineer job family. Those holding this position are typically assigned to lead small scale projects and participate as part of a development team on larger projects.\n\n\n\n\nJob Responsibilities:\n\nData Acquisition:\n\nDevelop solid knowledge of structured and unstructured data sources within each product journey (Underwriting and Risk; Client Service, Sales and Marketing; Claims; Account and Location Engineering) as well as emerging data sources (purchased data sets; external data; etc.)\nPartner with team members, product owners, developers, solution architects, business analysts, data engineers, data analysts, data scientists and others to understand data needs\nDevelop solutions using data modelling techniques and using technologies such as ER-Studio, Postgres, SQL Server, Azure Data Factory, Kakfa, SSIS, and others as required\nValidate code through detailed and disciplined testing\nParticipate in peer code review to ensure solutions are accurate\nEnsure tables and views are designed for data integrity, efficiency and performance, and are easy to comprehend\n\n\n\n\nMove and Store Data:\n\nData flow, infrastructure pipelines, ETL/ELT, structured and unstructured data movement and storage solutions.\nDesign data models and data flows into and out of databases\nUnderstand and design data relationships between business and data subject areas\nFollow standards for naming conventions, code documentation and code review\n\n\n\n\nSupport data exploration and transformation needs:\n\nSupport team members with data cleansing tasks\nConduct data profiling to identify data anomalies\nAssist team members with data preparation tasks\n\n\n\n\nSupport users and production applications:\n\nSupport developers, data analysts and data scientists who need to interact with data in either data warehouse\nAnalyze and assess reported data quality issues, quickly identifying root cause\nConsult dba(s) and team members on configuration and maintenance of the warehouse infrastructure\nMonitor system performance and identify opportunities for optimization\nMonitor storage capacity and reliability\nAddress production issues quickly, with appropriate validation and deployment steps\nProvide clear and professional communication to users, management, and teammates\nProvide ad hoc data extracts and analysis to respond to tactical business needs\n\n\n\n\nParticipate in effective execution of team priorities:\n\nIdentify work tasks and capture them in the team backlog\nOrganize known tasks, following provided prioritization\nEscalate colliding priorities\nProvide production support\nNetwork with product teams to keep abreast of database changes as well as business process changes which result in data interpretation changes.\n\n\n\n\nSkill and Experience:\n\n3-5 years of Experience Required to Perform Essential Job Functions\nData modeling abilities\nRelational (3rd Normal Form) and non-relational (Kimball / Inmon) database theory\nDesign, build, maintain data solutions\nUnderstanding of database clustering\nExpertise with databases including Postgres, SQL Server, and Data Lake\nKnowledge of Azure Cloud applications\nETL design\nProgramming languages (SQL, C#, Python, Powershell, KSQL)\nCollaboration & Standards: Experience with GraphQL, peer reviews, and adherence to coding and quality standards.\n\n\n\n\nMust Have Skills:\n\nData Engineering Tools: Proficiency in SQL, ADO, Azure Data Factory (ADF), Kafka, Azure Service Bus (ASB), and both stream and batch processing.\nCI/CD & Quality Assurance: Experience with continuous integration / deployment pipelines and implementing data quality checks.\nCloud & Storage Technologies: Familiarity with unstructured data storage, data lakes, cloud-native development, and containerization.\nSoftware Quality & Security: Strong understanding of software quality practices, security principles, and API integration.\n\n\n\n\nEducation and Certifications:\n\n4 Year / Bachelors Degree\nBachelor's Degree, preferably in Computer Science, Information Technology, Computer Engineering, or equivalent experience\n\nWork location: Bengaluru",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4268753995": {
    "job_url": "https://www.linkedin.com/jobs/view/4268753995",
    "job_summary": "SDE 3 (B.Tech Tier 1 + FinTech)\nSDE 3 (B.Tech Tier 1 + FinTech)\nTime Hack Consulting\nBengaluru, Karnataka, India (On-site)\n\u20b94M/yr - \u20b94.5M/yr\nViewed\nBe an early applicant\nEasy Apply",
    "job_details": "About the job\n\nAbout Us\n\nWe are on a mission to create India's largest fully automated financial inclusion organization, offering a range of financial services including micro-loans to serve the vast underserved middle/lower-income segment. Recognized as one of the Top 10 Google Launchpad-backed AI/ML Tech startups, you will experience firsthand challenges and opportunities to contribute towards building and scaling our business. Collaborate with brilliant minds driven by the goal of solving macro issues related to financial inclusion.\n\nOur services span over 17,000 pin codes in India, having positively impacted over 5.5 million users. Our user profile ranges from micro-entrepreneurs and small retailers to blue-grey-collar workers and salaried employees across various sectors. As part of our team, you'll manage Petabytes of data and contribute to organizational growth by deriving and applying data-driven insights, alongside opportunities to innovate and patent AI/ML technologies.\n\nWhat Can You Expect?\n\n\nOwnership of the company's success through ESOPs for high performers.\nMarket-leading competitive salaries (in the 90th percentile).\nAn open culture that encourages expressing opinions freely.\nOpportunities to learn from industry experts.\nA chance to positively impact billions of lives by enhancing financial inclusion.\n\n\nBe part of our journey to re-imagine solutions, delivering world-class, best-of-breed services to delight our customers and make a significant impact on the FinTech industry.\n\nRoles & Responsibilities\n\n\nDevelop and extend our backend platform, processing terabytes of data to deliver unique, personalized financial experiences.\nCollaborate directly with tech-focused founding team members and IIT graduates with expertise in designing scalable and robust system architectures.\nDesign systems from scratch with scalability and security front of mind.\nDemonstrate deep knowledge of design patterns in Java, DS, and algorithms.\nMonitor and optimize MySQL database queries for peak performance.\nExperience with tools like Scala, Kafka, Bigtable, and BigQuery is beneficial but not mandatory.\nMentor junior team members by providing regular feedback and conducting code reviews.\n\n\nSkills: data structures,mysql,bigquery,bigtable,code,hld,ds,design patterns,kafka,scala,fintech,algorithms,java,architecture",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4269415022": {
    "job_url": "https://www.linkedin.com/jobs/view/4269415022",
    "job_summary": "Software Development Engineer I\nSoftware Development Engineer I\nUmanist NA\nBengaluru, Karnataka, India (On-site)\n\u20b91.8M/yr - \u20b91.9M/yr\nViewed\nEasy Apply",
    "job_details": "About the job\n\nJob Title: Software Development Engineer I\n\nLocation: Bangalore (Remote  Laptop pickup required)-142344\n\nEmployment Type: 6-Month Contract\n\nExperience Required: 12 Years\n\nNotice Period: Immediate Joiners Only\n\nInterview Process: Online Assessment (Glider) + Virtual Interviews\n\nRole Overview\n\nWe are looking for a motivated and detail-oriented Software Development Engineer I to join an advanced AI-focused engineering team. In this role, you will evaluate and improve code generated by large language models (LLMs), ensuring alignment with industry standards, coding best practices, and practical usability. This is a unique opportunity to directly contribute to the development of next-generation AI tools that support software engineering tasks at scale.\n\nKey Responsibilities\n\n\nAnalyze and critically assess code responses produced by LLMs across various programming languages and paradigms \nUse expert judgment to select optimal solutions from multiple AI-generated outputs \nMake decisions with customer-centric thinking to ensure selected code is production-ready, secure, and efficient \nWrite and develop clear, high-quality coding demonstrations that represent ideal solutions \nProvide actionable feedback to improve the LLMs code generation capabilities and accuracy \nWork closely with AI researchers and software engineers to enhance model performance \nRemain up to date with trends in software development, code review practices, and AI tooling \n\n\nRequired Skills & Qualifications\n\n\nBachelors or Masters degree in Computer Science, Software Engineering, or a related field \nMinimum 1 year of hands-on experience in software development with exposure to multiple programming paradigms \nProficiency in at least two programming languages (Python and JavaScript are preferred) \nStrong ability to assess code quality, maintainability, and adherence to best practices \nExcellent analytical, critical thinking, and decision-making skills under ambiguity \nStrong communication skills, both verbal and written, with the ability to explain technical concepts clearly \nExperience in technical writing, especially involving code samples, tutorials, or documentation \n\n\nPreferred Qualifications\n\n\nPrior exposure to evaluating or working with AI/ML systems related to code generation or NLP \nFamiliarity with various software design methodologies, architectural patterns, and testing frameworks \nUnderstanding of core machine learning principles and how they intersect with software engineering \nExperience contributing to coding standards, style guides, or internal developer tools \nPassionate about code quality, developer productivity, and the future of AI-assisted development \n\n\nSkills: llm,python,artificial intelligence,javascript",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4261674035": {
    "job_url": "https://www.linkedin.com/jobs/view/4261674035",
    "job_summary": "Software Development Engineer\nSoftware Development Engineer with verification\nAeva\nBengaluru, Karnataka, India (On-site)\n1 company alum works here\n1 Walmart Global Tech India company alum works here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout us:\n\nAevas mission is to bring the next wave of perception to a broad range of applications from automated driving to industrial robotics, consumer electronics, consumer health, security, and beyond. Aeva is transforming autonomy with its groundbreaking sensing and perception technology that integrates all key LiDAR components onto a silicon photonics chip in a compact module. Aeva 4D LiDAR sensors uniquely detect instant velocity in addition to 3D position, allowing autonomous devices like vehicles and robots to make more intelligent and safe decisions.\n\n \n\nRole Overview:\n\nWe are looking for Software Development Engineer with emphasis on systems. You are a self-starter and comfortable working on designs from initial architecture through production.\n\n\n\n\nWhat you'll do\nContribute to Aevas SW infrastructure, APIs and SDKs that will deployed in production\nOpportunity to work on product features, software tools, and sensor emulation from ideation, implementation and all the way to deployment\nEnsure code is optimized for performance and scalability\nAdhere to coding standards and best practices to ensure consistency and quality in all code\nCollaborate with cross-functional teams to deliver successful and high-impact projects\nTake ownership of assigned tasks and ensure timely and accurate completion with documentation and tests\nActively participate in team meetings and design discussions\nTake initiative and contribute ideas to improve processes, tools, and techniques within the team\n\n\n\n\n\n What you have\n2-4 years of relevant experience with graduation in a relevant engineering program such as Computer Science, Computer Engineering, Electronics and Communications Engineering, etc\nHighly skilled in C++ development and experience with the Linux environment\nSkilled in scripting languages such as Python and Bash\n\n\n\n\n\nNice-to-haves\nExperience with robotics or autonomous vehicle software frameworks such as ROS/ROS2\nBackground in fundamentals of linear algebra and 3D geometry\nExperience with modern build systems such as Bazel or similar\nExperience with basics of networking stack and communication protocols\nExperience with automation frameworks such as Jenkins or similar\n\n\n\n",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4260105654": {
    "job_url": "https://www.linkedin.com/jobs/view/4260105654",
    "job_summary": "Data Engineer\nData Engineer with verification\nFiserv\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nData Infrastructure Engineer\n\n\n\n\n*Work Location: Bangalore or Pune*\n\n*Experience Required: 5 to 10 Years*\n\n\n\n\nWe're Clover, the largest cloud-based integrated commerce operating system for small and medium businesses in the United States. Our presence is in many industries including restaurants and shops; we support over 1M+ merchants worldwide and in 2022 processed over $240 billion card transactions. Clover enables merchants to accept payments, run their business and sell more. Come help us transform the way merchants do business, join Clover.\n\n---\n\nAbout the Team\n\nOur Data Platform team unlocks new potential for the organization by providing a pathway for analytical insights; We provide great support to merchants in providing valuable business insights in helping them with their business at every step. We are also responsible for Data Governance and Data Democratization helping teams all the way to production.\n\n---\n\nAbout the Role: What You Will Do\n\nAs a Staff Data Infrastructure Engineer, you will be a technical leader responsible for shaping the future of data at Clover. You will tackle our most complex data challenges, setting the technical vision for a platform that handles petabytes of data with high reliability and performance.\n\nArchitect and Lead: Spearhead the design, evolution, and implementation of our core data infrastructure, centered around Snowflake, Kafka, and Google Cloud Platform. You will be the go-to expert for scalable and resilient data solutions.\nDrive Strategic Initiatives: Own and deliver on critical platform initiatives that reduce friction in data access, improve data quality, and enable self-service analytics, directly impacting product development and business strategy.\nMentor and Elevate: Act as a force multiplier for the team. Mentor senior and junior engineers, establish best practices through code reviews and design discussions, and foster a culture of engineering excellence.\nAutomate at Scale: Champion an \"automation-first\" mindset. Lead the development of sophisticated automation and Infrastructure as Code (IaC) to manage our complex data ecosystem, enhancing reliability, security, and performance.\nSolve a New Level of Challenges: Troubleshoot and resolve our most complex and critical data systems issues, ensuring the integrity and availability of data that powers our business.\nInnovate and Influence: Stay at the forefront of data engineering technologies and trends. Evaluate and prototype new tools and frameworks to continuously innovate and steer the technical direction of Clover's data platform.\n\n\n\n\nWhat You'll Need to Succeed (Required Qualifications):\n\nA proven track record with 5+ years of experience in building and managing large-scale data infrastructure.\nDeep, hands-on expertise with cloud-native data warehouses, especially Snowflake, BIG query and Amazon Redshift. \nExtensive experience with at least one major cloud provider (GCP, AWS, or Azure) and its data services.\nStrong command of event-driven architecture and hands-on experience with data streaming technologies like Kafka.\nDemonstrable experience in designing and implementing robust, petabyte-scale ELT/ETL solutions.\nProficiency with Infrastructure as Code (Terraform is highly preferred) and configuration management tools (e.g., Puppet, Ansible).\nA bachelors or masters degree in Computer Science, a related technical field, or equivalent practical experience.\n\n\n\n\nWho You Are (Preferred Qualifications & Attributes):\n\nYou have experience with a broader set of data tools and technologies, such as Airflow, BigQuery, CloudSql, GKE, or other streaming solutions (e.g., Striim, Flink).\nYou possess a strong understanding of cloud networking principles (VPC, firewalls, peering) within GCP.\nYou are passionate about data governance and have experience implementing data quality frameworks and best practices in a production environment.\nYou are a natural leader who enjoys mentoring others and can drive technical decisions across multiple teams.\nYou have excellent communication skills and can articulate complex technical concepts to both technical and non-technical audiences.\n\n\n\n\nWhy Join Clover?\n\nImpact: You'll build the data foundation for a platform that millions of merchants rely on to run their business.\nChallenge: You'll solve complex, large-scale data problems that will stretch your skills and expertise.\nGrowth: We invest in our engineers with opportunities for continuous learning, professional development, and career advancement.\n\n\n\n\nBe a part of a team that's passionate about helping businesses thrive. Apply today.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4260864622": {
    "job_url": "https://www.linkedin.com/jobs/view/4260864622",
    "job_summary": "GraphDB+Python Developer\nGraphDB+Python Developer with verification\nBounteous\nIndia (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nWe are looking for a skilled GraphDB + Python Developer to join our team to design, develop, and maintain graph database solutions and integrate them with Python applications. The ideal candidate will have hands-on experience working with graph databases (such as GraphDB, Neo4j, or similar RDF/triple stores) and strong Python programming skills to build scalable, efficient, and robust data-driven applications.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4268193496": {
    "job_url": "https://www.linkedin.com/jobs/view/4268193496",
    "job_summary": "Software Engineer\nSoftware Engineer\nWorko\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nThis role is for one of worko's clients, a leading E-commerce platform:\n\nRole Overview\n\nAs a Software Development Engineer - IV, you will solve real-life complex problems and create compelling experiences for our users, suppliers and other stakeholders across the country. In this role, you will make sure that the solutions and processes that we create are of the highest quality. If you are excited by the idea of building world-class systems that empower millions and want to work on cutting-edge technology at scale, our journey has only just begun, and were looking for top engineering talent to help shape the future of commerce in India.\n\nKey Responsibilities\n\nTechnical Expertise & Ownership: Serve as the primary authority on your team's core tech stack, own and improve your services/frameworks, and ensure they meet SLAs on uptime, latency, cost, and reliability.\nProject & Workstream Leadership: Guide and prioritize multiple projects and workstreams, delivering large-scale initiatives while providing clear, cross-team status updates and proactive issue communication.\nAdvanced Problem Solving & Code Excellence: Utilize strong debugging, analysis, and instrumentation skills to write clean, maintainable code, perform peer reviews, and innovate with the right tools and algorithms.\nArchitectural Design & Collaboration: Lead critical design decisions across interdependent modules, participate in architecture discussions, and contribute to feature design reviews and PRD preparation.\nQuality Assurance, Testing & Security: Master testing guidelines to ensure bug-free, scalable builds, drive improvements in testing standards, and independently manage application security fundamentals.\nOperational Excellence & Best Practices: Oversee key tech metrics and documentation, participate in on-call rotations, drive root cause analyses and operational projects, and continuously establish and mentor others on best practices.\n\nRequirements\n\nB.Tech/B.E. in Computer Science or a related field, preferably from premier institutions.\nExperience in one or more programming languages, with an emphasis on Java and Golang (experience in these is appreciated, though not mandatory).\nStrong proficiency with databases such as MySQL, NoSQL or PostgreSQL. Understanding of open source technologies like Kafka, Mongo, Redis etc is appreciated.\nFamiliarity with scripting languages like Python, PHP, etc.\nExposure to modern development frameworks, tools, and continuous integration/continuous deployment (CI/CD) pipelines. Running scalable services in a containerised environment is a plus.\nExcellent problem-solving abilities and strong analytical skills.\n69 years of relevant experience as a Software Development Engineer or in a similar role.\nEffective communication and teamwork skills, with a track record of mentoring or leading engineering teams.\n\nMandatory Requirements\n\nB.Tech/B.E. in Computer Science or a related field\n69 years of relevant experience as a Software Development Engineer or in a similar role\n\nPreferred Requirements\n\nExperience in one or more programming languages, with an emphasis on Java and Golang\nStrong proficiency with databases such as MySQL, NoSQL or PostgreSQL\nUnderstanding of open source technologies like Kafka, Mongo, Redis etc\nFamiliarity with scripting languages like Python, PHP, etc\nExposure to modern development frameworks, tools, and continuous integration/continuous deployment (CI/CD) pipelines\nRunning scalable services in a containerised environment is a plus\nExcellent problem-solving abilities and strong analytical skills\nEffective communication and teamwork skills, with a track record of mentoring or leading engineering teams\n\nSalary \n\n60-89 lpa",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4271167138": {
    "job_url": "https://www.linkedin.com/jobs/view/4271167138",
    "job_summary": "Data Engineer\nData Engineer\nValiance Solutions\nBengaluru, Karnataka, India (On-site)\n1 company alum works here\n1 Walmart Global Tech India company alum works here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout Us\n\nValiance is a global AI & Data analytics firm helping clients build cutting-edge technology solutions for digital transformation. We work with some of the marquee brands across India, US and APAC to build transformative solutions for Credit Risk, Fraud, Predictive Maintenance, Quality Inspection, Data lake, IOT analytics etc.\n\n\n\n\nWe are looking to hire cloud data engineers who will be working with our global clientele to help architect & develop data ingestion, transformation, and storage solutions on on-premise and cloud infrastructure. Below are important responsibilities and skills for this role\n\n\n\n\nResponsibilities\n\nWork with the business & technical team to understand customer's data requirements. Help with creation of technical docs like architecture diagram, and implementation roadmap.\nDevelop scalable, robust solutions for data ingestion & data processing using various cloud and open-source tools.\nIngest data from multiple data sources including relational databases, on-premise Hadoop, file systems into cloud storage and databases.\nDevelop data storage model in cloud storage for optimal and secure querying of data.\nDevelop a data model in relational/no-sql databases to ingest and store transformed data. The data model should be optimized for query performance.\nWrite product & code documentation.\nReport project status by way of daily/weekly email summary on project tasks\nConstantly strive to improve project outcomes by bringing more efficiencies through automation\nHelp build the team by conducting interviews and coaching the team on google cloud.\n\n\n\n\nTechnical Skills:\n\nAt least 3 years of experience with Python, SQL, PySpark\nMinimum 1 years Experience as a cloud data engineer in Azure environment.\nData engineer certification on Azure/Databricks is desired.\nHands-on knowledge of Cloud data engineering services like Azure Data factory, Data bricks is required.\n\n\n\n\nSoft Skills\n\nExcellent communication skills - both oral and written\nDemonstrated ability to work in dynamic and high-expectations work environment\nShould be a team player\nShould have their own viewpoint about a problem and being able to propose a solution\nLastly should enjoy what they do and be ambitious about their career growth",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4269117594": {
    "job_url": "https://www.linkedin.com/jobs/view/4269117594",
    "job_summary": "Python Data Engineer\nPython Data Engineer\nK&K Talents - India\nIndia (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nK&K Talents is an international recruiting agency that has been providing technical resources globally since 1993. This position is with one of our clients in India, who is actively hiring candidates to expand their teams.\n\n\n\n\nTitle: Python Data Engineer\n\nLocation: PAN India - Hybrid (3 days/week Onsite Mandatory)\n\nEmployment Type: Contract \n\n\n\n\nProject Duration: 1 Year + Extension \n\nNotice Period: Immediate Joiner only\n\n\n\n\nRole:\n\nWe are looking for an experienced Data Engineer to join our team and contribute to building robust, scalable, and high-performance data solutions. This role requires deep technical expertise, strong problem-solving skills, and a passion for working in complex data environments.\n\n\n\n\nResponsibilities:\n\nDesign, build, and maintain reliable data pipelines using Python and PySpark\nWrite and optimize complex SQL queries for analytics and operational use cases\nDevelop and implement efficient data models to support scalable data architecture\nUse version control tools such as Git and GitHub to manage code and collaborate effectively\nOptimize query performance and processing workflows across large-scale datasets\nLeverage modern cloud data platforms such as AWS Redshift and Databricks\nCollaborate closely with cross-functional teams in an agile development environment\n\n\n\n\nRequired Skills:\n\n5+ years of experience in data engineering with a strong track record in large-scale data systems\nExpert-level proficiency in Python, PySpark, and SQL\nIn-depth understanding of data modelling principles and best practices\nExperience with code management tools (e.g., Git, GitHub)\nStrong skills in query optimization and performance tuning\nExtensive experience with cloud-based data platforms, particularly AWS Redshift and Databricks\nComfortable working in fast-paced, agile teams and contributing to iterative development cycles",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4250142579": {
    "job_url": "https://www.linkedin.com/jobs/view/4250142579",
    "job_summary": "Data Engineer\nData Engineer\nTEKsystems\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nTEKsystems is seeking a Senior AWS + Data Engineer to join our dynamic team. The ideal candidate should have expertise Data engineer + Hadoop + Scala/Python with AWS services. This role involves designing, developing, and maintaining scalable and reliable software solutions.\n\n\n\n\nJob Title: Data Engineer  Spark/Scala (Batch Processing)\n\nLocation: Manyata- Hybrid\n\nExperience: 7+yrs\n\nType: Full-Time\n\nMandatory Skills:\n\n\n\n\n7-10 years experience in design, architecture or development in Analytics and Data Warehousing.\nExperience in building end-to-end solutions with the Big data platform, Spark or scala programming.\n5 years of Solid experience in ETL pipeline building with spark or sclala programming framework with knowledge in developing UNIX Shell Script, Oracle SQL/ PL-SQL.\nExperience in Big data platform for ETL development with AWS cloud platform.\nProficiency in AWS cloud services, specifically EC2, S3, Lambda, Athena, Kinesis, Redshift, Glue, EMR, DynamoDB, IAM, Secret Manager, Step functions, SQS, SNS, Cloud Watch.\nExcellent skills in Python-based framework development are mandatory.\nShould have experience with Oracle SQL database programming, SQL performance tuning, and relational model analysis.\nExtensive experience with Teradata data warehouses and Cloudera Hadoop. Proficient across Enterprise Analytics/BI/DW/ETL technologies such as Teradata Control Framework, Tableau, OBIEE, SAS, Apache Spark, Hive\nAnalytics & BI Architecture appreciation and broad experience across all technology disciplines.\nExperience in working within a Data Delivery Life Cycle framework & Agile Methodology.\nExtensive experience in large enterprise environments handling large volume of datasets with High SLAs\nGood knowledge in developing UNIX scripts, Oracle SQL/PL-SQL, and Autosys JIL Scripts.\nWell versed in AI Powered Engineering tools like Cline, GitHub Copilo\n\n\n\n\nPlease send the resumes to nvaseemuddin@teksystems.com or kebhat@teksystems.com",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4261898021": {
    "job_url": "https://www.linkedin.com/jobs/view/4261898021",
    "job_summary": "Backend Developer\nBackend Developer\nAprecomm\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout Aprecomm:\n\n\n\n\nAprecomm is a pioneer in AI-driven network intelligence, enabling ISPs and enterprises to proactively manage and optimize network performance. Our solutions are deployed globally, empowering customers with deep insights and automation capabilities.\n\n\n\n\nJob Summary:\n\nWe are looking for an experienced Backend Developer to join our growing engineering team. The ideal candidate will be responsible for developing scalable backend services and APIs, maintaining high performance and responsiveness, and integrating with front-end components and third-party systems.\n\n\n\n\nKey Responsibilities:\n\nDesign and develop robust, scalable backend applications and APIs\nOptimize application performance and scalability\nCollaborate with product, frontend, and DevOps teams to deliver end-to-end solutions\nMaintain code quality, organization, and automation\nEnsure security and data protection best practices\nWrite unit and integration tests for reliability\nParticipate in code reviews and design discussions\n\n\n\n\nRequired Skills:\n\nStrong proficiency in one or more backend languages: Node.js, Python Go, or Java\nExperience with RESTful APIs, microservices architecture\nProficient in working with databases (SQL and NoSQL  e.g., PostgreSQL, MongoDB, Redis)\nExperience with containerization and orchestration tools (Docker, Kubernetes)\nFamiliarity with CI/CD tools and cloud services (AWS, GCP, Azure)\nKnowledge of network protocols and system design is a plus\n\n\n\n\nQualifications:\n\nBachelors or Masters degree in Computer Science, Engineering, or related field\n5+ years of hands-on experience in backend development\nMandatory 3+ experience in Nodejs\nExcellent problem-solving and debugging skills\nStrong communication and team collaboration skills\n\n\n\n\nPreferred:\n\nExperience working in a product-based or networking domain\nExposure to AI/ML integration with backend systems is a plus",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4264046538": {
    "job_url": "https://www.linkedin.com/jobs/view/4264046538",
    "job_summary": "Python Developer\nPython Developer with verification\nRecro\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nRole - Python Developer\n\nExperience - 4 - 7 yrs\n\nLocation - Bangalore \n\n\n\n\nMinimum Qualifications\n\nProficiency in backend software development using Python, Golang, or similar object-oriented languages.\nStrong understanding of RESTful APIs, service-oriented architecture (SOA), and microservice architectures.\nHands-on experience with MySQL databases (schema design and query optimization).\nExperience deploying and managing services on AWS/GCP platforms.\nFamiliarity with containerization tools like Docker and CI/CD pipelines.\nSkilled in performance optimization and debugging within distributed systems.\nProven ability to lead technical projects and mentor junior team members effectively.\n\n\n\n\nPreferred Qualifications\n\nExperience implementing design patterns and writing modular, maintainable code.\nExposure to AI/ML pipelines and Elasticsearch integration.\nHands-on experience with Postgres, MongoDB, DynamoDB, or Elasticsearch within distributed ecosystems.\nKnowledge of web servers and distributed system architectures.\nExperience coordinating frontend-backend workflows during feature development.\nFamiliarity with data pipeline technologies or AI-powered search workflows.\nProficiency with Git/GitHub workflows, code review processes, and CI/CD pipelines.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4268094710": {
    "job_url": "https://www.linkedin.com/jobs/view/4268094710",
    "job_summary": "Data Scientist - Product and Growth\nData Scientist - Product and Growth\nVola Finance\nBengaluru, Karnataka, India (On-site)\nCompany review time is typically 1 week\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nWho are we?\n\n\n\n\nVola Finance is a fast-growing fintech company revolutionizing the way people access and manage their finances. Our platform empowers individuals to improve their financial health and gain control over their spending with innovative tools and solutions. We are backed by industry-leading investors and are committed to building products that make a meaningful impact on our users' lives.\n\n\n\n\nWho are the founders?\n\n\n\n\nOur founding team consists of passionate leaders with deep expertise in finance and technology. They bring a wealth of experience from global companies and are dedicated to fostering a culture of innovation, collaboration, and excellence.\n\n\n\n\nRoles and Responsibilities : \n\n\n\n\nDevelopment of churn prediction models using advanced ML algorithms using user transactional data and behavioral data\nRegression model development for users Income and balance prediction using transaction data \nCustomer segmentation and recommendation engine development for cross-sell offerings \nNLP model building to understand the customers sentiment \nPropensity model development and LTV analysis \nCreate modern data pipelines and processing using AWS PAAS components (Glue, Sagemaker studio, etc.) \nExperience with API tools such as REST, Swagger, and Postman\nModel deployment in AWS and management of production environment\nTeam player who can work with cross-functional teams to gather data and derive insights \n\n\n\n\nMandatory Technical skill set : \n\n\n\n\n 1. Previous experience in Fintech product and growth strategy \n\n 2. Python \n\n 3 Linear regression, Logistic regression and tree-based ML algorithms\n\n 4 Statistical analysis and A/B testing\n\n 5 AWS Sagemaker, S3 , Ec2, Dockers \n\n 6 REST API, Swagger and Postman\n\n 7. Excel\n\n 8. SQL \n\n 9. Visualisation tools such as Redash / Grafana \n\n 10.Bitbucket, Githubs and versioning tools\n\n\n",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4266957142": {
    "job_url": "https://www.linkedin.com/jobs/view/4266957142",
    "job_summary": "Data Scientist\nData Scientist with verification\nHCLTech\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nHiring for Data Scientist- AI Developer in HCLTech\n\n\n\n\nInterested candidate share your resume at selvakumari.b@hcltech.com with below format\n\n\n\n\nEXP- 5 to 15Years\n\nLocation- Bangalore, Chennai, Noida, Hyderabad, Pune\n\n\n\n\n\n\n\nName: \n\n\n\n\nContact Number:\n\n\n\n\nEmail ID:\n\n\n\n\nCurrent Location:\n\n\n\n\nPreferred Location:\n\n\n\n\nTotal Experience:\n\n\n\n\nRelevant Experience:\n\n\n\n\nCurrent Organization:\n\n\n\n\nCurrent CTC:\n\n\n\n\nExpected CTC:\n\n\n\n\nNotice Period:\n\n\n\n\nAre you available for Interview this Weekend ?\n\n\n\n\n*Required Skills:*\n\n\n\n\n- *Technical Skills*: Proficiency in programming languages like Python, R, , and experience with machine learning algorithms, Deep learning\n\n-Strong foundation in statistics, mathematics,\n\n- *Communication*: Ability to communicate complex concepts clearly and effectively to stakeholders, and tailor messages for business applicability.\n\n- *Leadership*: Strong leadership and management skills, with the ability to build relationships with stakeholders and advocate for data-driven decision-making.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4264153830": {
    "job_url": "https://www.linkedin.com/jobs/view/4264153830",
    "job_summary": "Data Engineer\nData Engineer with verification\nAMISEQ\nIndia (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nData Engineer \n\nLocation: Remote (Any location within India)\n\n\n\n\n\n\n\nSkills:\n\n5 years Data EngineeringBig Data\nHadoop, HDFS, Hive, Spark SQL\nUnix/Linux Shell Scripting\nETL experiencepreferably Ab Initio",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4267708760": {
    "job_url": "https://www.linkedin.com/jobs/view/4267708760",
    "job_summary": "Full Stack Engineer\nFull Stack Engineer\nTypeface\nBengaluru, Karnataka, India (On-site)\n1 company alum works here\n1 Walmart Global Tech India company alum works here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nABOUT THE JOB\n\n\n\n\nWho are we?\n\n\n\n\nTypeface is on a mission to help everyone express their unique imagination. We believe technology is a creative partner that empowers any company to tell their unique stories faster and easier than ever before. Generative AI platforms represent a major breakthrough to create content at tremendous speed and scale. For enterprises to successfully leverage their potential, they need to include their unique voice and style and ensure responsible AI practices. We unite content velocity with brand personalization and safety, so that every company can achieve its creative potential. We are looking for passionate individuals who want to help build a fast-growing Gen AI company from the ground up.\n\n\n\n\nWhy join us?\n\n\n\n\nBleeding edge technology: We explore uncharted territory at the intersection of art and science. We strive to revolutionize content, amplifying human creativity with cutting-edge AI in a safe and responsible way.\n\n\n\n\nBest-in-class product: We built the leading enterprise-grade generative AI solution, so any business, from startups to Fortune 500 companies, can 10x personalized content at scale. Typeface combines the best-in-class AI platforms across the board with our own brand-personalized AI model to hyper- personalize content at scale with a responsible AI approach.\n\n\n\n\nWorld-class team: Founded by the former CPO & CTO of Adobe, Abhay Parasnis, and a highly experienced team with a proven track record of building revolutionary, long-lasting AI, SaaS, and media technologists that are completely focused on customer impact.\n\n\n\n\nTop-tier Investors: Backed by top-tier venture capital firms: Lightspeed Venture Partners, Salesforce Ventures, GV (Google Ventures), Madrona, Menlo Ventures, and M12 (Microsofts Venture Fund).\n\n\n\n\nCheck out our Series B announcement.\n\n\n\n\nRapid customer traction: Overwhelming demand from Fortune 500 companies and popular digital- native brands from every industry.\n\n\n\n\nAwards & recognition: Honored to be a winner of 10+ industry awards for our unique approach to enterprise GenAI, including Fast Companys Top 5 Next Big Things in Tech and Adweeks AI Company of the Year.\n\n\n\n\n\n\n\nThe Mission\n\n\n\n\nAs a Full-stack Engineer, you will be responsible for building features end-to-end. You will work closely with cross-functional teams including product, design, marketing, and data science to design and develop features.\n\n\n\n\n\n\n\nCore Responsibilities\n\n\n\n\nWe are looking for strong full-stack engineers across multiple levels to join our team and help us build innovative web applications and cloud services that deliver the power of generative AI to our customers.\n\nOwn the delivery of key product and technology initiatives across design, specification, development, testing and launch.\nDelivery high-quality software that can be easily read and leveraged by others.\nCollaborate with designers, product managers, marketing and other engineers. Investigate, prototype, and deliver innovative solutions throughout the stack\nInvestigate, prototype, and deliver innovative solutions throughout the stack\nDefine and drive adoption of best practices for building modern web applications and cloud services.\n\n\n\n\nMinimum Qualifications\n\n\n\n\nB.Tech. in computer science or a related field.\n2-4 years of experience in full-stack development.\nDemonstrated experience with the following: JavaScript frameworks (spring/springboot), Java, Python, Nodejs, Reactjs.\nDemonstrated experience developing on a major cloud platform (AWS/Azure/GCP).\n\n\n\n\nPreferred Qualifications\n\n\n\n\nStrong Experience with database systems (relational or noSQL) and pub/sub systems (Kafka/AWS SNS/Azure EventHub)\nExperience building AI and ML applications and using LLM APIs.\nAny AI, data science, ML experience will be highly valued.\nExperience building data analytics services.\nExperience optimizing performance across the entire stack.\nExperience working at a high-growth startup or tech company.\nEngineering degrees from top universities IITs, BITS, NITs preferred.\n\n\n\n\n\n\n\nBenefits\n\n\n\n\nCompetitive salaries and equity\nComprehensive benefits package (medical, dental, vision)\nOpportunities for professional growth and development\n\n\n\n\nEquality Opportunity Statement\n\n\n\n\nTypeface is an equal opportunity employer and does not discriminate on the basis of race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.\n\n\n\n\n\n\n\nDiversity & Inclusion Statement\n\n\n\n\nAt Typeface, we believe that diversity and inclusion are essential to our success. We are committed to creating a workplace that is welcoming and inclusive for all employees, regardless of their background or identity. We value diversity in all its forms and strive to create a culture of respect, understanding, and collaboration.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4263627886": {
    "job_url": "https://www.linkedin.com/jobs/view/4263627886",
    "job_summary": "Python & Java Developer\nPython & Java Developer with verification\nDBSync\nBengaluru, Karnataka, India (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\n\n\n\nYou\n\nAre passionate about technology, wake up every morning to experiment, learn and develop new solutions!\n\n\nAbout Us\nAt DBSync we provide the opportunity to use technology that creates innovative and next generation data integration products which helps our employees to cultivate their creativity and sense of belonging. DBSync is a leading provider for data integration and Data warehousing services for both cloud/SAAS-based-on-demand applications. We were incubated by Salesforce.com (as a part of Avankia), before getting spunned off as a separate company. DBSync provides data integration as a SaaS-based, Standalone or hosted integration at a competitive price with a plethora of benefits for business users. \n\nOur main motto is to provide a strong foundation for businesses in solving complex problems and automating their workflows while acting as a pillar of support for all their data integrations needs. At DBSync we encourage innovation and creativity and our team is diverse, consisting of a nice mix of cultural blends. We are a family where each talent is recognised and honed for the best of the individual and the company as a whole. We maintain a very professional, learn and excel vision with a hint of a start-up-like environment making each individual feel important and responsible with an equal opportunity to grow to the sky's limit!\n\nIf you have a spirit of enthusiasm to grow beyond horizons, a determination to work hard, confidence to achieve success and influence future visions and products and be a successful part of the next gen trend, DBSync is the place for you!\n\n\nOur Value System \n\n \nWe genuinely care\n \nWe do not waste time on manual or mundane task\n \nWe have a fun environment\n \nWe own it\n \nWe are experts on what we do\n \nWe win together\n \n\n\nDBSync has been:\n\nWe have been rated 4.7 / 5 on G2. We have got around 125 reviews in 2023. \nBased on the reviews G2 has awarded DBSync following badges. \nBest Relationship- Winter 2024\nLeader Americas Winter 2024\nBest Results - Winter 2024\nBest Usability - Winter 2024\n\n\n\nAbout the role:\n\nWe're looking for a passionate and skilled developer with experience in both Python and Java to join our engineering team. In this role, you'll contribute to designing, developing, and maintaining scalable integration solutions and backend services.\n\n\nRoles and Responsibilities:\n\nDevelop and maintain high-quality software in Python and Java\nContribute to integration frameworks and tools for cloud and on-prem systems\nOptimize backend logic, data pipelines, and RESTful services\nCollaborate with QA, product managers, and other developers in agile teams\nParticipate in code reviews and mentor junior developers as needed\nTroubleshoot production issues and contribute to continuous improvement\nDesign and develop intelligent AI agents capable of autonomous decision-making to enhance product functionality\nSeamlessly integrate large language models (LLMs) into existing applications to deliver AI-driven features and user experiences\n\n\n\nSkills and Qualifications:\n\n3-5 years of hands-on experience with Python and Java\nSolid understanding of object-oriented programming and design patterns\nExperience building RESTful APIs and microservices\nFamiliarity with multithreading, concurrency, and performance tuning\nKnowledge of cloud platforms (AWS, Azure) is a plus\nFamiliarity with tools like Git, Maven, Jenkins, and Docker\nStrong problem-solving and analytical mindset\nExperience with LLM development frameworks like LangChain and LangGraph\nExcellent communication and teamwork skills\n\n\n\nWork Shift: 03:00 PM IST to 12:00 AM IST\nJob location: Bangalore (Remote)\n\n\nFor more information about DBSync, visit www.mydbsync.com.\nVideo: https://www.youtube.com/playlist?list=PLJzycdoERLoekPWNkXEsuih807TQAEnnB\n",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4260902649": {
    "job_url": "https://www.linkedin.com/jobs/view/4260902649",
    "job_summary": "Back End Developer\nBack End Developer\nSuperPe\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nApplied",
    "job_details": "About the job\n\nJob Description:\n\nWe are looking for a skilled back-end developer with 5+ plus years of experience to contribute to the development of robust, efficient, and scalable server-side solutions. The ideal candidate will play a pivotal role in shaping our back-end architecture, collaborating with our front-end developers, and ensuring the performance and reliability of our applications.\n\n\n\n\nKey Responsibilities:\n\nDesign, develop, and maintain server-side logic for high-performance web applications.\nCollaborate with front-end developers to integrate user-facing elements with server-side logic.\nOptimize applications for maximum speed and scalability.\nImplement data security and protection measures.\nTroubleshoot and debug issues that arise during development and testing.\nBuild reusable code and libraries for future use.\nStay up to date with the latest industry trends, best practices, and emerging technologies.\nWork closely with cross-functional teams to understand and address business needs.\n\n\n\n\nQualifications:\n\nBachelors degree in computer science, Software Engineering, or a related field (or equivalent work experience).\n5 plus years of experience in back-end web development\nProficiency in one or more server-side programming languages (e.g., Python, Ruby, Java, Node.js, .NET)\nExperience with databases and data modelling (SQL and/or NoSQL databases)\nFamiliarity with RESTful API design and development\nStrong understanding of server-side architecture and microservices.\nKnowledge of version control systems (e.g., Git)\nStrong problem-solving skills and attention to detail\nStrong communication and collaboration skills.\nAbility to work independently and as part of a team.\n\n\n\n\nNice-to-Have Skills:\n\nExperience with cloud platforms (e.g., AWS, Azure, Google Cloud)\nKnowledge of containerization and orchestration technologies (e.g., Docker, Kubernetes)\nSecurity best practices in web application development\nPerformance optimization and scalability techniques\nFamiliarity with message queuing systems (e.g., RabbitMQ, Kafka)\nExperience with DevOps practices and CI/CD pipelines\n\n\n\n\nTo apply, please send your resume to shreya@superpe.in\n\n\n\n\nSuperPe is an equal opportunity employer and welcomes candidates of all backgrounds to apply. We look forward to hearing from you!",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": true,
    "easy_apply": false
  },
  "https://www.linkedin.com/jobs/view/4269455696": {
    "job_url": "https://www.linkedin.com/jobs/view/4269455696",
    "job_summary": "Senior AI Backend Engineer\nSenior AI Backend Engineer\nBonsen AI\nBengaluru, Karnataka, India (Hybrid)\nCompany review time is typically 1 week\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout Us\n\nAt BonsenAI, we redefine AI innovation for enterprise customers across the US, Australia, and New Zealand. As pioneers in secure and scalable AI workflows, we deliver impactful AI solutions rapidly, combining cutting-edge technology with unparalleled efficiency.\n\nWe're assembling an elite engineering team that leverages AI to transform ideas into production-ready software at unprecedented speed. Join us in shaping the future of AI with meaningful solutions for global enterprises.\n\n\n\n\nResponsibilities\n\nAI Solution Architecture & Agentic AI Development: Lead endtoend AI solution architecture and delivery using OpenAI, LangChain, and proprietary frameworks and use it for designing and deploying production-grade RAG systems, chatbots, and dataextraction pipelines optimised for accuracy, latency, and cost. Integrate agentic AI agents that orchestrate RAG workflows which can do planning, retrieving, toolcalling, and refining outputs autonomously within multi-step tasks, while ensuring auditability and continuous improvement.\nBackend Systems & API Development: Develop robust, scalable APIs and microservices using FastAPI to integrate multiple LLM providers (Azure OpenAI, Amazon Bedrock, GCP Gemini). Design high-performance backend services with proper architecture patterns, database optimisation, and caching strategies. Create scalable vector search solutions using Azure AI Search/Vertex AI Vector Search/PgVector, with streaming responses and reliable fallback\nDevOps & Infrastructure Management: Design and implement CI/CD pipelines using Azure DevOps and GitHub Actions. Develop and maintain infrastructure using Terraform for consistent, repeatable deployments across multiple environments. Deploy and monitor AI applications using Docker and Kubernetes/Azure Container Apps with automated deployment strategies and comprehensive observability solutions.\nCode Quality & Engineering Excellence: Implement software engineering best practices including SOLID principles, design patterns (Factory, Strategy, Observer, etc.), and clean architecture principles. Ensure high code quality through automated testing, performance optimisation, and security best practices.\nSystem Architecture & Integration: Design architectures for complex AI applications combining LLMs, embedding models, vector stores, and Agentic AI components. Implement advanced features like semantic caching, hybrid search, and custom routing logic while ensuring security, reliability, and cost optimisation across enterprise workflows.\nTechnical Leadership & Mentoring: Lead code reviews, mentor junior engineers, and drive technical decisions for AI system architecture and implementation. Work closely with cross-functional teams to ensure seamless integration of AI solutions into enterprise workflows.\n\n\n\n\nRequired Skills and Qualifications\n\nAI & LLM Expertise: Hands-on with LLM-driven applications including RAG systems, Agentic AI workflows, chatbots, and summarisation; experience with multi-agent systems.\nVector Databases: Proficient in Azure AI Search, Pinecone, and FAISS for semantic search and retrieval.\nBackend Development: 4+ years of Python experience using Django, FastAPI, or Litestar; strong grasp of design patterns and SOLID principles.\nAPI & Architecture: Expertise in RESTful API design, microservices, and auth mechanisms.\nDatabase & Performance: Skilled in SQL/NoSQL (PostgreSQL, Cosmos DB, Redis) with a focus on performance tuning.\nCloud & Security: Deep understanding of Azure services (AKS, App Services, Key Vault, Azure AD), using Terraform for infrastructure provisioning, and secure coding practices.\nDevOps & Infra: Practical experience with Azure DevOps, GitHub Actions, CI/CD pipelines, Docker, and Kubernetes.\nEngineering Practices: Familiar with unit testing, automated testing, Git workflows, and maintaining clean, high-quality codebases.\nLeadership Experience: Previous experience leading small engineering teams or technical initiatives.\n\n\n\n\nNice-to-Have\n\nAzure Certifications such as Microsoft Certified: Azure AI Engineer Associate, Azure Solutions Architect Expert or Azure DevOps Engineer Expert.\nExperience designing and integrating AI-driven enterprise workflows within the Microsoft ecosystem, including Microsoft Sharepoint, Graph API and Microsoft Teams.\nAdvanced AI Techniques: Experience with reinforcement learning, Multi agentic swarm systems, and custom model training.\nOpen Source Contributions: Active contributions to open-source projects especially focused on AI or DevOps projects.\nMicroservices Architecture: Experience with service mesh technologies, distributed systems, and event-driven architectures.\n\n\n\n\nSoft Skills\n\nAbility to mentor team members, conduct effective code reviews, and drive technical excellence across the team.\nFoster open communication within the team to enhance collaboration and trust, with strong ability to explain complex technical concepts to stakeholders.\nDemonstrate commitment to teamwork by delivering high-quality results consistently.\nApproach challenges with an entrepreneurial mindset to drive innovation and efficiency.\nStrong problem-solving capabilities with ability to balance technical debt, feature delivery, and system reliability.\nAdaptability to a fast-paced, innovation-driven environment.\n\n\n\n\nWhy Join Us?\n\nOwn client solutions from concept to ROI measurement.\nLeadership opportunity to lead technical initiatives and mentor junior engineers in a growing team.\nBe a key player in delivering reliable AI-powered enterprise solutions.\nWork with cutting-edge technology in a collaborative, innovation-driven environment.\nFlexible work environment with hybrid options.\nCompetitive salary and opportunities for career advancement.\n\n\n",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4264465548": {
    "job_url": "https://www.linkedin.com/jobs/view/4264465548",
    "job_summary": "Machine Learning Engineer\nMachine Learning Engineer\nSpydra\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob Summary: We are seeking a talented and motivated Machine Learning Engineer to join our team. The ideal candidate will have a strong background in machine learning algorithms, data analysis, and software development. You will be responsible for designing, developing, and deploying machine learning models and systems that drive our products and services.\n\nKey Responsibilities:\n\nDevelop and implement machine learning algorithms and models.\nDesign and conduct experiments to evaluate the performance of machine learning models.\nCollaborate with cross-functional teams to integrate machine learning solutions into products.\nAnalyze large datasets to extract meaningful insights and patterns.\nOptimize and tune machine learning models for performance and scalability.\nMonitor and maintain deployed models, ensuring their performance in a production environment.\nStay up-to-date with the latest trends and advancements in machine learning and artificial intelligence.\nWrite clean, maintainable, and efficient code.\nDocument processes, experiments, and results comprehensively.\n\nRequirements:\n\nBachelors or Masters degree in Computer Science, Data Science, Machine Learning, or a related field.\nProven experience as a Machine Learning Engineer or similar role.\nStrong understanding of machine learning algorithms and techniques (e.g., supervised and unsupervised learning, reinforcement learning, deep learning).\nProficiency in programming languages such as Python, R, or Java.\nExperience with machine learning frameworks and libraries (e.g., TensorFlow, PyTorch, Scikit-learn).\nFamiliarity with data preprocessing and feature engineering techniques.\nExperience with cloud platforms (e.g., AWS, Google Cloud, Azure) is a plus.\nStrong problem-solving skills and the ability to work independently and as part of a team.\nExcellent communication and collaboration skills.\n\nPreferred Qualifications:\n\nExperience with natural language processing (NLP) and computer vision.\nKnowledge of big data technologies (e.g., Hadoop, Spark).\nFamiliarity with containerization and orchestration tools (e.g., Docker, Kubernetes).\nExperience with version control systems (e.g., Git).\nUnderstanding of DevOps practices and CI/CD pipelines.\n\n\n",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4259552527": {
    "job_url": "https://www.linkedin.com/jobs/view/4259552527",
    "job_summary": "Software Engineer in Test I\nSoftware Engineer in Test I with verification\nQuartic.ai\nIndia (Remote)\nActively reviewing applicants\nViewed\nEasy Apply",
    "job_details": "About the job\n\nAbout\n\n\n\n\nWe are an industrial-AI start-up in the business of accelerating the adoption of Industry 4.0. In other words, we allow manufacturers to extract more value from their legacy infrastructure and build Smart Manufacturing Factories. We do this with our Smart Industry platform which puts power directly into the hands of subject matter experts (SMEs) and solves key challenges faced by process manufacturing industries when implementing digital transformation. Using Quartic Platform, the SMEs are able to create and deploy AI and IIoT applications to significantly increase productivity and operational performance without the need for proficiency in programming or data science. The Quartic Platform is used by Fortune 100 and 500 companies in pharmaceutical, food & beverage, CPG, and other industries for process optimization, predictive maintenance, and energy optimization applications.\n\n\n\n\n\n\n\nResponsibilities:\n\n\n\n\nDevelop and maintain automated test scripts using a programming language, preferably Python, to ensure efficient and effective testing.\nCollaborate with developers and QA engineers to understand product requirements and design appropriate test strategies.\nUtilize Selenium or Playwright automation frameworks to automate web-based application testing.\nPerform API testing using REST Assured tools to ensure the functionality and stability of backend services.\nUse Git and GitHub for version control to manage test scripts and collaborate with the team.\nUtilize JIRA for test case management, defect tracking, and project management.\nWork with Docker containers to set up and manage test environments.\nConduct testing on both Windows and Linux operating systems to ensure cross-platform compatibility.\nApply TDD (Test-Driven Development) and BDD (Behavior-Driven Development) principles to create robust and maintainable test scripts.\nKnowledge and experience with Jenkins for continuous integration and deployment is a plus.\nFamiliarity with performance and security testing concepts and tools is a plus.\nUnderstanding of GraphQL technology is a plus.\nExperience with API automation is a plus.\n\n\n\n\nQualifications:\n\n\n\n\n1-3 years of relevant experience\nBachelors degree in Computer Science, Engineering, or a related field.\nStrong programming skills with hands-on experience in at least one programming language, preferably Python.\nSolid understanding and experience with Playwright automation frameworks.\nProficiency in using REST Assured tools for API testing.\nFamiliarity with Git and GitHub for version control.\nExperience with JIRA for test case management.\nKnowledge of Docker and ability to work with containers.\nFamiliarity with both Windows and Linux operating systems.\nStrong understanding of TDD and BDD methodologies.\nKnowledge and experience with Jenkins is a plus.\nFamiliarity with performance and security testing concepts is a plus.\nUnderstanding of GraphQL technology is a plus.\nExperience in API automation is a plus.\n\n\n\n\nWhat you get:\n\n\n\n\nUnlimited Leaves: We understand the importance of work life balance. Thats why we offer unlimited leaves to our employees.\nCutting Edge Technology: Get a chance to work on technology that is at the forefront of the fourth industrial revolution. Be a part of the future, today.\nCompetitive Compensation: We believe in rewarding our employees for their hard work and dedication. Thats why we offer competitive compensation packages.\nFlexible Work Hours: We value your time and understand that everyone has their own rhythm. Enjoy the freedom of flexible work hours.\nPermanent Work From Home: Say goodbye to the daily commute. We offer permanent work from home options so you can work in the comfort of your own space.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4268179344": {
    "job_url": "https://www.linkedin.com/jobs/view/4268179344",
    "job_summary": "Back End Developer\nBack End Developer with verification\nObjectways\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nBackend Engineer (India)\n\n\nLocation: Bangalore, India \n\nWork Type: Hybrid - 3 days in office \n\nExperience: 8-10 Years\n\n\n\n\nAbout the Role: \n\nWe are looking for a highly experienced Backend Engineer to join our Bangalore-based team. This hybrid role requires you to work 3 days a week from the office as part of a 6-8 member scrum team. You will be responsible for developing and maintaining robust backend solutions, focusing on system design, security, and performance.\n\n\n\n\nKey Responsibilities:\n\nDevelop and implement backend services using Java, Microservices, and Spring Boot, leveraging SpringCloud for cloud integration.\nDesign and build RESTful APIs to support various applications.\nManage and optimize databases including Postgres and SQL, with familiarity with MongoDB.\nImplement CI/CD practices using Maven and Jenkins for automated deployments.\nEnsure high code quality through rigorous unit testing, CodeCoverage, and Junit.\nDeploy and manage containerized applications using Kubernetes and Liquibase.\nIntegrate messaging systems with Kafka for efficient data flow.\nUtilize opentelemetry.io for observability, and JIRA & GitHub for project tracking and version control.\nApply Design Patterns and contribute to system architecture with an understanding of Micro Segmentation.\nConduct thorough code reviews and facilitate debugging processes.\nFocus on Performance Optimization and participate in Pair Programming.\nDocument technical designs and implementations comprehensively.\nContribute to security practices and possess an understanding of network security (Firewall).\nWork collaboratively within an agile scrum environment and adapt to cross-functional team dynamics.\n\n\n\n\nRequired Skills & Experience:\n\nTechnical: Java, MicroService, SpringBoot, SpringCloud, RESTful APIs, Postgres, SQL, Junit & CodeCoverage, Maven, MongoDB, Kubernetes, Liquibase, Kafka, opentelemetry.io, JIRA, GitHub, GitHubActions, Jenkins.\nSoft Skills: Design Patterns, Excellent Communication Skills, Understanding Security Practices, Adaptable (Working across time zones), Understanding of network security (Firewall), Ability to do code reviews, Debugging skills, Performance Optimization, Pair Programming, Unit testing, Documentation, Micro Segmentation.\nExperience: 8-10 years in Backend Engineering.\n\n\n",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4270239377": {
    "job_url": "https://www.linkedin.com/jobs/view/4270239377",
    "job_summary": "SDE 3 (Backend)\nSDE 3 (Backend) with verification\nLicious\nBengaluru, Karnataka, India (On-site)\n1 company alum works here\n1 Walmart Global Tech India company alum works here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout us\n\nWith our de-licious fresh meat and seafood, we are LiciousIndias leading D2C food-tech brand. Founded in 2015 by Abhay Hanjura and Vivek Gupta, we are headquartered in Bengaluru, delivering high-quality, fresh meat and seafood to over 32 lakh customers across 20 cities.\n\n\n\n\nReady to add your unique flavor to Licious? Read on!\n\n\n\n\nRole Overview\n\nAs a Senior Software Engineer  Backend at Licious, you will design, build, and scale high-performance backend systems, migrate applications to microservices, and drive best practices in architecture and coding. If this excites you, we want you on our team!\n\n\n\n\nResponsibilities\n\nScope and create technical documents for reference and reporting.\nDefine High-Level (HLD) and Low-Level Designs (LLD) to guide development.\nBuild, own, and optimize high-scale modules from scratch, while reimagining existing ones for scalability.\nMigrate applications to a Microservices Architecture, ensuring reusable code and libraries.\nReview code, enforce best practices, and mentor SDE-I & SDE-II through continuous collaboration.\nTranslate business requirements into scalable technical solutions.\nImplement DevOps best practices, contribute to CI/CD pipelines, and drive agile development.\n\n\n\n\nWhat makes you a magic ingredient to our recipe?\n\nHave 5-8 years of experience under your belt, preferably in a consumer product company.\nMust be proficient with Java Programming with a strong understanding of MySQL/NoSQL\nDevOps exposure with knowledge of CI/CD, Kubernetes basics, and Horizontal Pod Autoscaler.\nExperience in scalable system design, distributed systems, and design patterns.\nHands-on experience with message brokers, caching, and writing unit test cases.\nStrong communication skills to articulate business and technical ideas effectively.\nBE/BTech or an equivalent degree.\n\n\n\n\nLocation- Onsite, Bengaluru\n\n\n\n\nIf you're excited to be part of Licious, apply through this Form",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4264339930": {
    "job_url": "https://www.linkedin.com/jobs/view/4264339930",
    "job_summary": "Python Developer\nPython Developer\nExpertrons Delhi\nBengaluru, Karnataka, India (Hybrid)\n\u20b9650K/yr - \u20b9850K/yr\nViewed\nEasy Apply",
    "job_details": "About the job\n\nJob Title: Python Developer\n\nLocation: Bangalore (Hybrid  10 days/month WFO, remaining days WFH)\n\nContract Duration: 1 Year\n\nAbout The Role\n\nMantra Labs is seeking a skilled and passionate Python Developer with 45 years of experience to join our dynamic team. This role offers the flexibility of a hybrid work environment and an opportunity to work on impactful backend development projects involving modern frameworks and cloud technologies.\n\nKey Responsibilities\n\n\nDesign, develop, and maintain efficient and scalable backend systems using Python.\nWork extensively with Django or Flask frameworks.\nBuild and integrate RESTful APIs.\nWrite robust, reusable code and ensure high performance and responsiveness.\nCollaborate with cross-functional teams to define system design and architecture.\nImplement and maintain authentication and authorization systems (IAM).\nWork with SQL databases and cloud environments.\nTroubleshoot, test, and maintain the core product software to ensure strong optimization and functionality.\n\n\nRequired Skills & Experience\n\n\n4 to 5 years of hands-on experience in Python backend development.\nStrong proficiency in Django or Flask.\nSolid understanding of relational databases and SQL.\nExperience with building APIs and system integration.\nExposure to cloud platforms (AWS, Azure, or GCP).\nFamiliarity with Identity and Access Management (IAM).\nGood system design and problem-solving skills.\nStrong communication and collaboration skills.\n\n\nEducational Qualification\n\nB.Tech/B.E in Computer Science, Information Technology, or a related field.\n\nWork Arrangement\n\n\nHybrid Work Model: 10 days per month working from the office (Bangalore), remaining days remote.\n\n\nSkills: collaboration,cloud,problem-solving,sql,flask,iam,api,communication,django,backend development,python,restful apis,cloud platforms,system design",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4261409041": {
    "job_url": "https://www.linkedin.com/jobs/view/4261409041",
    "job_summary": "Backend Developer\nBackend Developer with verification\nSigmoid\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nEasy Apply",
    "job_details": "About the job\n\nAs a Backend Developer, you will be primarily responsible for planning and development of SaaS applications for our Product Engineering division \n\n\n\n\nResponsibilities: \n\n Build next-generation web applications which are efficient, reusable and with prime focus on customer delight \n\n Explore and design dynamic and compelling consumer experiences \n\n Architect, develop, and test highly interactive back-end web applications and reusable components using current web technologies and frameworks \n\n Identify and communicate best practices for application architecture \n\n Participate in all phases of the software development cycle as part of a Scrum team \n\n Obsess over quality in the product you create and the code you write \n\n Work closely with the Product Managers, Designers and Backend developers to implement versatile front-end solutions \n\n Actively participate in design and code reviews to build robust applications and prototypes \n\n Work closely with the other team members to implement front end solutions, endorsing upcoming standards, launching, iterating and making a difference.\n\n\n\n\nQualifications: \n\n Should hold a Bachelor's Degree in Technology or a related field with minimum 5+ years of professional experience.\n\n Hands-on experience with NodeJS & Python.\n\n Can design and implement scalable Databases across different platforms (MySQL, MongoDB etc) \n\n Basic knowledge of HTML, CSS, CSS post processors \n\n Ability to write well-abstracted, reusable, highly performant code for backend services \n\n\n\n\nNotice Period: Immediate to 30 Days",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4266275680": {
    "job_url": "https://www.linkedin.com/jobs/view/4266275680",
    "job_summary": "Python Automation with Networking\nPython Automation with Networking with verification\nHARMAN India\nBangalore Urban, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nIntroduction: A Career at HARMAN Digital Transformation Solutions (DTS)\n\nWere a global, multi-disciplinary team thats putting the innovative power of technology to work and transforming tomorrow. At HARMAN DTS, you solve challenges by creating innovative solutions.\n\nCombine the physical and digital, making technology a more dynamic force to solve challenges and serve humanitys needs\nWork at the convergence of cross channel UX, cloud, insightful data, IoT and mobility\nEmpower companies to create new digital business models, enter new markets, and improve customer experiences\n\nWhat You Will Do\n\nDevelop maintainable test automation frameworks, tools, and automated test suites in response to the growing feature set and customer requirements\n\nWork closely with software engineers, test engineers, and product managers from the beginning of the development cycle and be an integral part of the Agile Engineering team\n\nWork in a fast-paced continuous integration and continuous delivery-based engineering environment\n\n\n\n\nWhat You Need\n\nMinimum 5+ years of overall experience\n\nExperience in Agile/Scrum or full software development life cycle, including requirement analysis, design, development, testing, and defect fixing\n\nExperience with automation using Python, Shell, Rest API\n\nKnowledge of Linux environments and general networking concepts\n\nGood understanding of networking, including OSI model, DNS, DHCP etc\n\nWork experience with Jira, GitHub, and Jenkins\n\nLocation:\n\nBangalore only, hybrid.\n\n\n\n\nWhat Makes You Eligible\n\nAny offer of employment is conditioned upon the successful completion of a background investigation and drug screen.\nDedicated performer & team player with the ability to advocate appropriately for product quality.\nRelentless learner with a dedication to learn new technologies and test methods\nSelf-driven and Innovative to drive continuous improvements in Test process\nResourcefulness in triaging problems and coordinating with multiple teams for issue resolution\nStrong written, verbal communication and inter personal relationship skills\n\n\n\n\nYou Belong Here\n\nHARMAN is committed to making every employee feel welcomed, valued, and empowered. No matter what role you play, we encourage you to share your ideas, voice your distinct perspective, and bring your whole self with you  all within a support-minded culture that celebrates what makes each of us unique. We also recognize that learning is a lifelong pursuit and want you to flourish. We proudly offer added opportunities for training, development, and continuing education, further empowering you to live the career you want.\n\n\n\n\nAbout HARMAN: Where Innovation Unleashes Next-Level Technology\n\nEver since the 1920s, weve been amplifying the sense of sound. Today, that legacy endures, with integrated technology platforms that make the world smarter, safer, and more connected.\n\nAcross automotive, lifestyle, and digital transformation solutions, we create innovative technologies that turn ordinary moments into extraordinary experiences. Our renowned automotive and lifestyle solutions can be found everywhere, from the music we play in our cars and homes to venues that feature todays most sought-after performers, while our digital transformation solutions serve humanity by addressing the worlds ever-evolving needs and demands. Marketing our award-winning portfolio under 16 iconic brands, such as JBL, Mark Levinson, and Revel, we set ourselves apart by exceeding the highest engineering and design standards for our customers, our partners and each other.\n\nIf youre ready to innovate and do work that makes a lasting impact, join our talent community today!",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4268100192": {
    "job_url": "https://www.linkedin.com/jobs/view/4268100192",
    "job_summary": "Senior Software Engineer\nSenior Software Engineer\nKhalis Foundation\nIndia (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob Title: Senior FullStack Engineer \n\n\n\n\nLocation: Remote (worldwide) \n\n\n\n\nAbout Khalis Foundation\n\nKhalis Foundation is a techforward nonprofit dedicated to making Sikhi accessible worldwide. Our platforms reach millions of daily users, powering live Gurbani displays and study tools. Almost everything we build is free, open, and communitydriven.\n\n\n\n\nWhy This Role Matters\n\n Youll build and maintain missioncritical, offlinefirst applications that Sikhs rely on every day. Your code will shape how the global sangat reads, learns, and shares Gurbani.\n\n\n\n\nKey Responsibilities\n\n  Build and ship new features for largescale web, desktop, and mobile apps.\n\n  Write highperformance code in React, React Native, TypeScript, Next.js and Nest.js.\n\n  Deliver crossplatform experiences with Electron and React Native.\n\n  Implement realtime functionality using WebSockets; ensure reliability and speed.\n\n  Integrate intelligent search and AI enhancements (experience with retrievalaugmented generation is a plus).\n\n  Manage data storage\n\n\n\n\nQualifications  MustHave\n\n  Strong experience with React, React Native, and TypeScript\n\n  Solid Node.js and WebSockets expertise\n\n  Familiarity with PostgreSQL, MySQL, or SQLite\n\n  Deep understanding of browser internals and performance optimisation\n\n  Ability to work independently and deliver productionready code\n\n\n\n\nNicetoHave\n\n  Experience building desktop apps with Electron\n\n  Exposure to AI and retrievalaugmented generation (RAG)\n\n  Knowledge of Indic/Gurmukhi text rendering\n\n  Track record of opensource contributions\n\n  Interest in multilingual user experience\n\n\n\n\nWhat We Offer\n\n  Work that impacts millions and preserves Sikh heritage\n\n  Fullydistributed, asyncfriendly culture\n\n  A supportive team of engineers, designers, and volunteers\n\n  Opensource ethos: your work is visible and shared\n\n  Competitive nonprofit salary & benefits\n\n\n\n\nHow to Apply\n\n Apply on LinkedIn with your rsum and links to work youre proud of. In your cover note, tell us one feature youd love to build for the Sikh community and why.\n\nLets build the future of Sikh technology together.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4268210370": {
    "job_url": "https://www.linkedin.com/jobs/view/4268210370",
    "job_summary": "Software Engineer(C++,Typescript)\nSoftware Engineer(C++,Typescript) with verification\nAutodesk\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob Requisition ID #\n\n25WD89482\n\nPosition Overview\n\nWe are looking for a highly skilled and motivated Software Engineer to help build our next-generation cloud-based CAD platform. This role is ideal for someone with strong software engineering experience and a solid understanding of mechanical engineering concepts, linear algebra, and CAD workflows, especially with tools like Autodesk Inventor and/or Fusion 360. Experience with finite element analysis (FEA) and Qt is a strong plus.\n\nYoull contribute to the design and development of scalable, collaborative, and high-performance tools that empower engineers and designers to innovate in the cloud.\n\nResponsibilities\n\n\nDevelop Cloud-Based Features: Design and implement robust, scalable software components for 3D modeling, simulation, and collaboration\nCollaborate Across Teams: Work closely with product managers, designers, and fellow engineers to deliver intuitive and powerful CAD tools\nCAD Integration: Leverage your experience with Inventor and/or Fusion 360 to ensure seamless interoperability and user-centric design\nApply Engineering Knowledge: Use your understanding of mechanical engineering and linear algebra to support accurate modeling and simulation\nContribute to UI/UX: Develop cross-platform desktop interfaces using Qt and modern frontend technologies\nMaintain Code Quality: Write clean, maintainable code and participate in code reviews, testing, and continuous integration\n\n\nMinimum Qualifications\n\n\nBachelors or masters degree in computer science, Mechanical Engineering, or a related field\n3+ years of professional software development experience\nStrong C++, Typescript and Data Structures, Object Oriented Programming, Design Patterns, Computer Science fundamental\nExperience with cloud platforms (AWS, Azure, or GCP) and modern backend architectures\nSolid understanding of 3D graphics, computational geometry, and linear algebra\n\n\nPreferred Qualifications\n\n\nBackground in mechanical engineering or experience working with mechanical design teams\nHands-on experience with Autodesk Inventor and/or Fusion 360, including APIs and data formats\nExperience with Qt for desktop application development.\nFamiliarity with WebGL/WebGPU and frontend frameworks (e.g., React, Svelte\nKnowledge of finite element analysis (FEA) concepts and integration with CAD tools\nExperience with collaborative editing technologies (e.g., CRDTs, OT)\nContributions to open-source CAD or simulation projects\nExperience with Autodesk Forge or similar cloud-based CAD platforms\n\n\nLearn More\n\nAbout Autodesk\n\nWelcome to Autodesk! Amazing things are created every day with our software  from the greenest buildings and cleanest cars to the smartest factories and biggest hit movies. We help innovators turn their ideas into reality, transforming not only how things are made, but what can be made.\n\nWe take great pride in our culture here at Autodesk  its at the core of everything we do. Our culture guides the way we work and treat each other, informs how we connect with customers and partners, and defines how we show up in the world.\n\nWhen youre an Autodesker, you can do meaningful work that helps build a better world designed and made for all. Ready to shape the world and your future? Join us!\n\nSalary transparency\n\nSalary is one part of Autodesks competitive compensation package. Offers are based on the candidates experience and geographic location. In addition to base salaries, our compensation package may include annual cash bonuses, commissions for sales roles, stock grants, and a comprehensive benefits package.\n\nDiversity & Belonging\n\nWe take pride in cultivating a culture of belonging where everyone can thrive. Learn more here: https://www.autodesk.com/company/diversity-and-belonging\n\nAre you an existing contractor or consultant with Autodesk? \n\nPlease search for open jobs and apply internally (not on this external site).\n\n",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4252394326": {
    "job_url": "https://www.linkedin.com/jobs/view/4252394326",
    "job_summary": "Software Development Engineer II (Web Extensions)\nSoftware Development Engineer II (Web Extensions) with verification\nQuillBot\nIndia (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout Us\n\nQuillBot was founded in 2017 with the mission of helping students and professionals, especially those learning English, strengthen their writing. Today, QuillBot is on a mission to make written communication better and more efficient. With over 56 million users worldwide, QuillBot empowers people to write without limits. The platform offers a suite of AI-powered tools, including paraphrasing, grammar checking, summarizing, and more to help users communicate more effectively across languages and cultures. With a dedicated team of 190 employees, QuillBot continues to innovate, enabling users to enhance their writing and express themselves with clarity and confidence. \"Write without limits\" is at the core of everything we do at QuillBot.\n\nOverview\n\nThis role is ideal for someone who is proficient in ReactJS, TypeScript, Vanilla JavaScript, and NodeJS and is eager to take ownership of development from concept to production. You'll work closely with engineers, product managers, and designers to launch impactful features in a fast-paced, learning-oriented environment.\n\nResponsibilities\n\n\nYou will be responsible for designing and developing systems and applications with agility and quality.\nEngage in continuous learning and stay updated with frontend technological advancements\nYou will be responsible for end-to-end ownership of tasks from development to production.\nYou will help with the design, implementation, and launch of many key product features.\nParticipate in a culture of code reviews and collaborate closely with other engineers, product managers, and designers.\nDrive best practices and engineering improvements.\nCreate prototypes and proofs-of-concept for iterative development.\n\n\nQualifications\n\n\nSoftware development or programming experience of 3-6 years of working with scalable frontend/fullstack applications.\nExperience in developing stable and performant software at scale.\nGood experience in Vanilla JavaScript, ReactJS, DOM manipulation, HTML parsing, and NodeJS.\nHave experience in owning the quality of developed features and contribute to UI automation for better coverage.\nAbility to communicate effectively with employees in the company in both technical and non-technical roles.\nAggressive problem diagnosis and creative problem-solving skills.\nShould have a startup mentality and a high willingness to learn with a growth mindset.\nHands-on experience with web browser extensions is a plus.\n\n\nBenefits & Perks\n\n\nCompetitive salary, stock options & annual bonus\nMedical coverage\nLife and accidental insurance\nVacation & leaves of absence (menstrual, flexible, special, and more!)\nDevelopmental opportunities through education & developmental reimbursements & professional workshops\nMaternity & parental leave\nHybrid & remote model with flexible working hours\nOn-site & remote company events throughout the year\nTech & WFH stipends & new hire allowances\nEmployee referral program\nPremium access to QuillBot\nBenefits and benefit amounts differ by region. A comprehensive list applicable to your region will be provided in your interview process.\n\n\nResearch shows that candidates from underrepresented backgrounds often don't apply for roles if they don't meet all the criteria. We strongly encourage you to apply if you're interested: we'd love to learn how you can amplify our team with your unique experience!\n\nThis role is eligible for hire in India.\n\nWe are a virtual-first company and have employees dispersed throughout the United States, Canada, Germany, Netherlands, and India. We have a market-based pay structure that varies by location. The base pay for this position is dependent on multiple factors, including candidate experience and expertise, and may vary from the amounts listed below. You may also be eligible to participate in our bonus program and may be offered an equity award, benefits, and other types of compensation.\n\n#QuillBot\n\nEqual Employment Opportunity Statement (EEO)\n\nWe are an equal opportunity employer and value diversity and inclusion within our company. We will consider all qualified applicants without regard to race, religion, color, national origin, sex, gender identity, gender expression, sexual orientation, age, marital status, veteran status, or ability status. We will ensure that individuals who are differently abled are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment as provided to other applicants or employees. Please contact us to request accommodation.\n\n",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4265986025": {
    "job_url": "https://www.linkedin.com/jobs/view/4265986025",
    "job_summary": "GenAI Engineer\nGenAI Engineer with verification\nPersistent Systems\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout Position: \n\n\n\n\nDesign, develop, and optimize AI/ML models for practical applications, ensuring high performance, scalability, and reliability. Innovate using advanced GenAI technologies (e.g., LLMs, RAG, OpenAI APIs) to address complex business challenges.\n\n\n\n\nRole: GenAI Engineer\nLocation: Bangalore \nExperience: 6-10 years \nJob Type: Full Time Employment\n\n\n\n\nWhat You'll Do: \n\n\n\n\nWorked on Voice AI / Digital Channels / Agentic AI applications using Playbooks, tooling, connectors, and data sources.\nStrong proficiency in Python for developing and deploying AI applications in a real-time production environment.\nProven experience in designing and implementing agentic AI workflows, orchestrating multiple AI models and external systems.\nWorked on identification, design, and implementation of use cases for GCP Agents in contact centers to improve customer experience and operational efficiency.\nUnderstanding of customer service operations and contact centre technologies.\nExposure GCP AI offerings and Google Dialog flow/Virtual agents exposure\n\n\n\n\nExpertise You'll Bring: \n\n\n\n\nDesign, develop, and implement advanced conversational AI agents using Google Cloud Contact Center AI (CCAI) and other relevant GCP AI services (e.g., Dialogflow CX, Speech-to-Text, Natural Language AI).\nLeverage various GCP AI models to enhance agent capabilities, including intent recognition, entity extraction, sentiment analysis, and knowledge base integration.\nEnsure the secure handling of customer data, implementing robust measures to prevent exposure in chat interactions.\nDevelop strategies and mechanisms to accurately extract customer conversations, even when speech is unclear or ambiguous.\nIntegrate and configure different models offered by GCP for contact centre AI solution\n\n\n\n\nBenefits:\n\n\n\n\nCompetitive salary and benefits package\nCulture focused on talent development with quarterly promotion cycles and company-sponsored higher education and certifications\nOpportunity to work with cutting-edge technologies\nEmployee engagement initiatives such as project parties, flexible work hours, and Long Service awards\nAnnual health check-ups\nInsurance coverage: group term life, personal accident, and Mediclaim hospitalization for self, spouse, two children, and parents\n\n\n\n\nInclusive Environment:\n\n\n\n\nPersistent Ltd. is dedicated to fostering diversity and inclusion in the workplace. We invite applications from all qualified individuals, including those with disabilities, and regardless of gender or gender preference. We welcome diverse candidates from all backgrounds.\n\n\n\n\nWe offer hybrid work options and flexible working hours to accommodate various needs and preferences.\nOur office is equipped with accessible facilities, including adjustable workstations, ergonomic chairs, and assistive technologies to support employees with physical disabilities.\nIf you are a person with disabilities and have specific requirements, please inform us during the application process or at any time during your employment. We are committed to creating an inclusive environment where all employees can thrive.\n\n\n\n\nOur company fosters a values-driven and people-centric work environment that enables our employees to:\n\n\n\n\nAccelerate growth, both professionally and personally\nImpact the world in powerful, positive ways, using the latest technologies\nEnjoy collaborative innovation, with diversity and work-life wellbeing at the core\nUnlock global opportunities to work and learn with the industrys best\n\n\n\n\nLets unleash your full potential at Persistent \n\n\n\n\nPersistent is an Equal Opportunity Employer and prohibits discrimination and harassment of any kind.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4266621069": {
    "job_url": "https://www.linkedin.com/jobs/view/4266621069",
    "job_summary": "Software Engineer (SE 3) - Ruby with AWS\nSoftware Engineer (SE 3) - Ruby with AWS with verification\nGranicus\nBengaluru, Karnataka, India (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nOpening from Default - All locations\n\nThe Company \n\nServing the People Who Serve the People \n\nGranicus is driven by the excitement of building, implementing, and maintaining technology that is transforming the Govtech industry by bringing governments and their constituents together. We are on a mission to support our customers by meeting the needs of their communities and implementing our technology in ways that are equitable and inclusive. Granicus has consistently appeared on the GovTech 100 list over the past 5 years and has been recognized as the best companies to work on BuiltIn. \n\nOver the last 25 years, we have served 5,500 federal, state, and local government agencies and more than 300 million citizen subscribers powering an unmatched Subscriber Network that uses our digital solutions to make the world a better place. With comprehensive cloud-based solutions for communications, government website design, meeting and agenda management software, records management, and digital services, Granicus empowers stronger relationships between government and residents across the U.S., U.K., Australia, New Zealand, and Canada. By simplifying interactions with residents, while disseminating critical information, Granicus brings governments closer to the people they servedriving meaningful change for communities around the globe. \n\nWant to know more? See more of what we do here. \n\n\n\n\nRequired Skills and Qualifications: \n Expert level knowledge of Ruby & Rails and related frameworks\n\n Hands-on engineer who can develop microservices and deploy them on Kubernetes. \n\n Proficient in cloud technologies and developing solutions on the cloud. \n\n Proficient in Kubernetes and Containers. \n\n Proficient in web application development using ReactJS, NodeJS and related web technologies. \n\n 4-8 years of experience developing, testing, shipping, and supporting production-quality PaaS/SaaS solutions. \n\n Proficient in either Golang or Python\n\n Good to have knowledge of JavaScript/Typescript, ReactJS, NodeJS. \n\n Docker, Kubernetes, Helm\n\n AWS Cloud\n\n Experience building and maintaining CI/CD pipelines. \n\n Strong analytical and problem-solving skills\n\n Strong system design and application scalability skills\n\n Passion for learning new things and the ability to do so quickly. \n\n Strong understanding of AWS services, including SES, Pinpoint, Lambda, RDS, API Gateway, and DynamoDB, AWS EKS. \n\n Full-stack development experience with Ruby, Ruby on Rails, and Golang/Python. \n\n Nice to have hands-on experience with Docker, Kubernetes, CI/CD pipelines, and microservices architecture. \n\n Strong exposure to Kafka Streams and both NoSQL and SQL databases. \n\n\n\n\n\nSecurity and Privacy Requirements\nResponsible for Granicus information security by appropriately preserving the Confidentiality, Integrity, and Availability (CIA) of Granicus information assets in accordance with the company's information security program. \nResponsible for ensuring the data privacy of our employees and customers, their data, as well as taking all required privacy training in a timely manner, in accordance with company policies. \n\n\n\n\n\n\n\n\nClosing from Default - All locations\n\n\n\n\nDont have all the skills/experience mentioned above? At Granicus, we are trying to build diverse, inclusive teams. We do not have degree requirements for most of our roles. If you dont meet every requirement above but are excited to learn more, we encourage you to apply. We might just be able to find another role that could be a perfect fit! \n\n\n\n\nSecurity and Privacy Requirements\n\n- Responsible for Granicus information security by appropriately preserving the Confidentiality, Integrity, and Availability (CIA) of Granicus information assets in accordance with the company's information security program.\n\n- Responsible for ensuring the data privacy of our employees and customers, their data, as well as taking all required privacy training in a timely manner, in accordance with company policies.\n\n\n\n\nThe Team\n\n- We are a remote-first company with a globally distributed workforce across the United States, Canada, United Kingdom, India, Armenia, Australia, and New Zealand.\n\n\n\n\nThe Culture\n\n- At Granicus, we are building a transparent, inclusive, and safe space for everyone who wants to be\n\na part of our journey.\n\n- A few culture highlights include  Employee Resource Groups to encourage diverse voices\n\n- Coffee with Mark sessions  Our employees get to interact with our CEO on very important and\n\nsometimes difficult issues ranging from mental health to work-life balance and current affairs. \n\n- Microsoft Teams communities focused on wellness, art, furbabies, family, parenting, and more.-=- - We bring in special guests from time to time to discuss issues that impact our employee\n\npopulation \n\n\n\n\nThe Impact\n\n- We are proud to serve dynamic organizations around the globe that use our digital solutions to make the world a better place  quite literally. We have so many powerful success stories that illustrate how our solutions are impacting the world. See more of our impact here.\n\n\n\n\nGranicus is committed to providing equal employment opportunities. All qualified applicants and employees will be considered for employment and advancement without regard to race, color, religion, creed, national origin, ancestry, sex, gender, gender identity, gender expression, physical or mental disability, age, genetic information, sexual or affectional orientation, marital status, status regarding public assistance, familial status, military or veteran status or any other status protected by applicable law.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4267735246": {
    "job_url": "https://www.linkedin.com/jobs/view/4267735246",
    "job_summary": "Senior Software Engineer - Backend\nSenior Software Engineer - Backend\nKubar.io\nIndia (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nThe ideal candidate is a self-motivated, multi-tasker, and demonstrated team-player. You will be a lead developer responsible for the development of new software products and enhancements to existing products. You should excel in working with large-scale applications and frameworks and have outstanding communication and leadership skills.\n\n\n\n\nWhat you'll do\n\n Work closely with engineers across many teams to architect and build highly scalable and robust backend applications and services.\n\n Write and review high quality, performant and reliable code.\n\n Continuously improve the quality and reliability of services and help define and enhance the patterns and principles that the team follows.\n\n Become the subject matter expert in your area and collaborate closely with Product Managers to understand and refine functional specifications.\n\n Mentor and guide junior members of the team\n\n Participate in the on-call rotation and be willing to jump in and help resolve any incidents within the defined SLA.\n\n Participate in team agile and engineering practices and lead their continuous evolution.\n\n\n\n\nWhat you will need\n\n Bachelor's Degree in Computer Science or other related technical field.\n\n 6+ years of professional software development experience.\n\n 2+ years of experience contributing to the design and architecture of new and existing services.\n\n 4+ years of extensive experience in GoLang designing and building large scale, distributed services.\n\n Currently working with and being proficient with GoLang.\n\n Extensive experience working with at least one modern object-oriented programming language such as Java, GoLang.\n\n Experience designing and building large scale, distributed applications including making tradeoffs in architecture and functionality in a cloud environment.\n\n Experience operating production systems including defining metrics and processes for deploying changes to production reliably in live systems.\n\n Solid understanding of software engineering best practices, including coding standards, code reviews, source control management, build processes, testing, and operations.\n\n\n\n\nPreferred qualifications\n\n Hands on experience with Gin and Echo frameworks in GoLang and building services with them\n\n Extensive experience with building and deploying services on AWS or other CSP. AWS certification is a definite plus.\n\n Contributed to operational excellence including Grafana, Prometheus, LogStash\n\n Experience working with container technology including Docker and Kubernetes.\n\n Experience working in a high-paced start-up environment.\n\n\n\n\nWhat you will get in return\n\n Competitive pay on hourly rate\n\n Working hours flexibility\n\n Learn from industry veterans.\n\n Work on cutting edge problems with cutting edge technologies.\n\n Semiannually bonus options\n\n Possibility of company equity",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4270646832": {
    "job_url": "https://www.linkedin.com/jobs/view/4270646832",
    "job_summary": "Software Engineer\nSoftware Engineer\nMNC\nBengaluru, Karnataka, India (On-site)\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nDear Candidate,\n\n\n\n\nGreetings from Ojas Systems!! We have opening with our esteemed US client for remote job opening for ServiceNow candidate. Please find below the JD\n\n\n\n\nRequirements\n\n5+ years of hands-on experience in ServiceNow CMDB development and management.\n\nExpertise in CMDB data modeling, CI class structures, and relationships.\n\nProficient in Discovery and Service Mapping for accurate CI population.\n\nExperience with data reconciliation, identification rules, and normalization techniques.\n\nStrong scripting skills (JavaScript), Flow Designer, and Business Rules.\n\nExperience integrating ServiceNow CMDB with external data sources and tools.\n\nFamiliarity with ITIL processes, especially related to Configuration and Asset Management.\n\nServiceNow CSA certification; CISDiscovery or CISITOM is a plus.\n\nStrong analytical, communication, and problem-solving skills.\n\n\n\n\nInterested candidates please mail your resume to meghana@ojassystems.com",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4267634854": {
    "job_url": "https://www.linkedin.com/jobs/view/4267634854",
    "job_summary": "Full Stack Engineer\nFull Stack Engineer\nOtomeyt AI\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob Summary:\n\nWe are seeking a skilled and motivated Full Stack Developer with hands-on experience in Java, Spring Boot, Microservices, and Angular. The ideal candidate will be responsible for designing and developing scalable, high-quality applications and contributing to the overall success of our software development lifecycle.\n\n\n\n\nJob Title: Full Stack Developer Lead  Java, Spring Boot, Microservices, Angular\n\nExperience: 6 Years\n\nLocation: [Bangalore - Koramangala)\n\nType: Full-Time\n\n\n\n\nJob Summary:\n\nLooking for a Full Stack Developer with strong experience in Java, Spring Boot, Microservices, and Angular to build scalable web applications.\n\n\n\n\nKey Responsibilities:\n\nDevelop and maintain applications using Java, Spring Boot, Microservices, and Angular.\nBuild REST APIs and responsive front-end interfaces.\nCollaborate with cross-functional teams on requirements and solutions.\nConduct code reviews and ensure best coding practices.\nTroubleshoot, debug, and optimize application performance.\nMentor junior developers and stay updated with emerging tech.\n\n\n\n\nRequirements:\n\nBachelors degree in CS/Engineering or related.\n6+ years of hands-on development experience.\nStrong knowledge of REST APIs, Angular, and Microservices.\nFamiliar with Git, JIRA, Agile methodology.\nGood problem-solving and communication skills.\nBonus: Experience with cloud (AWS/Azure), Docker, CI/CD.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4265976417": {
    "job_url": "https://www.linkedin.com/jobs/view/4265976417",
    "job_summary": "Platform Engineer\nPlatform Engineer with verification\nNAB\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nPurpose:\n\n\n\n\nAt NAB, were passionate about building software that solves problems. We count on our platform engineers to empower users with a rich feature set, high availability, and stellar performance level to pursue their missions. As we expand customer deployments, were seeking an experienced SRE with significant platform engineering experience to deliver core banking services to customers and colleagues. Specifically, we are searching for someone who enjoys collaborating with a cross-functional team to develop real-world solutions and positive user experiences for every interaction.\n\n\n\n\nAccountabilities:\n\n\n\n\nRun the production environment by monitoring availability and taking a holistic view of system health\nRun core banking ledger and switch systems with the domain knowledge to run mission critical systems\nBuild software and systems to manage platform infrastructure and applications in AWS and Azure\nImprove reliability, quality, and time-to-market of our suite of software solutions. Execute chaos tests, performance benchmark tests and functional tests.\nBuild non functional and functional test frameworks for testing various communication protocols like HTTPS, Kafka (AVRO / JSON), AS2805 (SNMP), ODBC, MQ\nMeasure and optimize system performance and reliability, with an eye toward pushing our capabilities forward, getting ahead of customer needs, and innovating for continual improvement.\nProvide primary operational support and engineering for multiple large-scale distributed software applications\nBuild and run automation on components in AWS and Azure\nUplift logging, cyber security and reliability  designing strategies and patterns around achieving them\nRun post mortem incidents via data, objectively and mathematically measure failures and arrive at root cause analysis with the remediation mechanisms that ensures the same incident doesnt occur again.\n\n\n\n\nYour key responsibilities will include:\n\n\n\n\nGather and analyze metrics from operating systems as well as applications to assist in performance tuning and fault finding\nPartner with development teams to improve services through rigorous testing and release procedures\nParticipate in system design consulting, platform management, and capacity planning\nCreate sustainable systems and services through automation and uplifts\nBalance feature development speed and reliability with well-defined service-level objectives\nDesign, implement and maintain different AWS services\nAutomating code with object oriented software engineering principles\nWork across the full spectrum of the Software Development Life Cycle (SDLC)\nActively contribute to planning sessions and other Agile ceremonies across the team\nLiaise with users and stakeholders of the platform\nGuide team members in their technical journey\n\n\n\n\nIn addition to your strong technical capability, you will be a proven team player, problem solver, independent thinker and have a collaborative attitude towards your work and colleagues.\n\n\n\n\nSkills and Experience: \n\n\n\n\nIt is expected that the role holder is well rounded, operationally highly experienced Software engineers  who can write code to build software, the software can be command line interfaces as an example, to interact with platform APIs, or monitoring utilities, or test automation framework, or test stubs / mocks etc, also should have the following skills and experience:\n\n\n\n\nThese platform engineers need to have a mandatory experience of at least 12 years, who have coding knowledge, and have run tech bridges, handled incidents with troubleshooting techniques and are well versed with either Azure or AWS (or both if we can!). Obviously skills of Docker, Terraform, and other Devops like skills apply. But they are different to devops, as they actually write and build software for doing things like what I said above.\nShould have had some prior experience to Financial services that helps them understand what they are dealing with  in Core Banking systems, and the criticality of it, plus the regulatory and compliance aspects which include audits etc.\nShould be able to run and operate the platform with not just customer support, but also build monitoring dashboards etc to showcase the health of the platform and clean documentation to help self service customers on how the platform operates and is consumed.\nLanguages wise, python, java, c++, bash shell would be preferred. Communication\nskills need to be very good as well, to handle operations and incidents\n3+ years of AWS / Azure experience\n5+ years in application development and support\nStrong Experience in Scripting, Linux and CI/CD preferably Jenkins\nStrong programming skills with Python and groovy\nInfrastructure tools such as Terraform, Github and Ansible\nStrong analytical / problem-solving skills\nExcellent communication and interpersonal skills, both oral and written.\nExcellent time management skills\nAbility to assess and implement new technologies and processes.\nAn open mindset and proven ability to innovate and influence.\n\n\n\n\nDesirable:\n\n\n\n\nExperience with shell scripting.\nExposure to DevOps and Agile.\nExposure to Monitoring and Logging tools such as Splunk\nExperience with containerised environments using Docker and Kubernetes\n\n\n\n\nEducation:\n\n\n\n\nTertiary qualification in a relevant technical subject or equivalent experience.\nPostgrad qualifications and self-learning courses and certifications (Coursera, Udacity, AWS, etc.) highly regarded.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4269887968": {
    "job_url": "https://www.linkedin.com/jobs/view/4269887968",
    "job_summary": "Software Engineer\nSoftware Engineer\nHireginie\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nStaff Engineer ( SDE 4)\n\n\n\n\nOur Client: Our client, a leading Insurtech startup specializes in providing innovative and comprehensive employee benefits solutions, offering a range of customizable packages tailored to meet the unique needs of businesses through their tech-first platform. They are backed by leading global investors and are on their scale-up stage.\n\n\n\n\nJob Title: Staff Engineer ( SDE 4)\n\nEducation: B.Tech\n\nExperience: 5 Years \n\nLocation: Bangalore\n\n\n\n\nAbout the Role: Client is seeking a seasoned and passionate Staff Engineer who thrives in lean, high-impact teams and is dedicated to building robust, scalable, and customer-centric products. In this role, you will own significant technical and operational responsibilities, guiding projects from conceptualization through delivery.\n\n\n\n\nResponsibilities:\n\nCollaborating closely with upper management, product, and engineering teams to gather and deeply understand feature requirements.\nDefining clear, scalable system designs and technical specifications aligned with product vision.\nQuickly breaking down complex, large-scale tasks into manageable deliverables and proactively driving their execution.\nWriting clean, maintainable, and scalable code, judiciously balancing code quality with delivery velocity.\nLeading technical discussions, mentoring team members, and effectively communicating with both technical and non-technical stakeholders to remove roadblocks.\nChampioning best practices in software development, testing, deployment, and system monitoring.\nOptimizing infrastructure for cost efficiency, stability, and performance.\nThis role is a direct pathway toward becoming an engineering leader, and you will be responsible for recognizing, hiring, and grooming top engineering talent as per business needs.\n\n\n\n\n\n\n\n\n\n\nRequirement:\n\n\n\n\n5+ years of full-stack engineering experience, including proven experience playing as tech lead in your projects.\nDeep expertise in modern JavaScript (ES2018+), TypeScript, and reactive frameworks (preferably Vue.js, React.js is acceptable).\nExtensive experience with backend systems developed in Node.js and SQL databases, particularly PostgreSQL.\nStrong familiarity with data stores and streaming services (Redis required; Kafka is a plus).\nSolid understanding of Linux-based systems (Ubuntu) and proficient scripting skills (bash/python/etc).\nAdvanced expertise in containerization (Docker, docker-compose), orchestration tools (Kubernetes), and DevOps practices with experience managing self-hosted systems.\nHands-on experience with cloud infrastructure providers (AWS), CDN/security providers (Cloudflare), and infrastructure cost optimization.\nComprehensive knowledge of API design principles (GraphQL knowledge is a plus).\nProficient in using Git, Jira, Notion, Slack for collaborative software development.\nPassionate about Agile methodologies and comfortable working in a fast-paced startup environment.\nDemonstrated ability to rapidly gain deep context in large and complex codebases comprising multiple components and services.\nStrong advocate for lean teams, minimal management overhead, and driving high individual and team impact.\nCommitment to continuous learning, clean coding, documentation, and software design best practices.\nThis role requires working from our office located in Koramangala, Bangalore for at least 3 days per week.\n\n\n\n\nAbout Hireginie: Hireginie is a prominent talent search company specializing in connecting top talent with leading organizations. We are committed to excellence and offer customized recruitment solutions across industries, ensuring a seamless and transparent hiring process. Our mission is to empower both clients and candidates by matching the right talent with the right opportunities, fostering growth and success for all.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4267161817": {
    "job_url": "https://www.linkedin.com/jobs/view/4267161817",
    "job_summary": "SDE-I (Web)\nSDE-I (Web)\n1% Club\nBengaluru, Karnataka, India (On-site)\nViewed\nEasy Apply",
    "job_details": "About the job\n\nAbout 1% Club\n\n1% Club is on a mission to make Financial Independence a reality.\n\nIn under two years, weve built multiple large, profitable businesses under one brand  from financial education and SEBI-registered investment advisory to insurance and credit card services.\n\nBacked by Nikhil Kamath (Zerodha) and a 10 crore fundraise, we also grew an organic distribution of 80 lakh+ followers among Indias English-speaking middle class.\n\nNow, were using this strong foundation to build a tech-first, AI-driven wealth management platform  solving everything money in one seamless app.\n\nAt 1% Club, youll take products from zero to scale, solve deeply technical, user-first problems, and build for millions. If you want to shape the future of how India manages its wealth  this is the place.\n\nWhat will you do?\n\nYoull be working on the core systems behind a platform that's redefining how millions of Indians manage their money, with real-time applications, AI copilots, and blazing-fast apps.\n\nYoull have end-to-end ownership of features, working directly with the CTO and founding team to take ideas from whiteboard to production.\n\nWe care less about what stack youve used and more about how you think. You should be fluid across tech, know the why behind every decision, and treat speed and stability like religion. If you can write clean code, debug production like a ninja, and nerd out on system-level optimization, wed love to have you.\n\nKey Responsibilities\n\n\nDevelop scalable, high-performance applications using React, NextJS, and TypeScript \nEnsure pixel-perfect implementation of UI/UX designs from Figma. \nLeverage NextJS features like SSR, SSG, and dynamic routing to deliver fast, SEO-friendly pages. \nWork closely with Product Managers, Designers & Backend Engineers to deliver seamless user experiences. \nOwn entire features end to end, taking responsibility for coding, unit testing, bug fixing & documentation. \nParticipate in architectural discussions, contribute to the tech roadmap, and drive technical strategy. \n\n\nYoull be a great fit if you have\n\n\nSolid fundamentals in React, HTML5, CSS3 (Flex, Grid), and REST API integrations. \nGood understanding of client-side state management (Context API, Redux, or similar). \nFamiliarity with SSR, SSG, and NextJS optimizations for SEO and performance. \nOwnership and obsession with the product. \nWillingness to learn and adapt to new technologies and tools. \n\n\nBonus points\n\n\nYou can use AI to automate grunt work and 10x your output \nYou have a good eye for details \nYou think like a product owner, not just an engineer \nYou have worked at a FinTech before \n\n\nPerks and Benefits\n\n\nBYOS (Build Your Own Setup): Mac/Windows/Linux, iPad, Monitors - anything you need to work comfortably. \nWork hard, Party harder: Company offsite, team lunch/dinner, game nights, and day outings are a few of the many things youll experience if you work out of the Bengaluru office. \nHighly competitive salary: We offer above-market salary & equity packages. \n\n\nHiring Process\n\nYou can check out our hiring process from here.\n\nApply now to join our team!\n\nSkills: rest api,client-side state management,html5,ssg,coding experience,css3,nextjs,react,context api,typescript,ssr,redux",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4267306560": {
    "job_url": "https://www.linkedin.com/jobs/view/4267306560",
    "job_summary": "Backend Java Developer (AI/ML)\nBackend Java Developer (AI/ML) with verification\nInsight Global\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nPay Rate: 14-17 LPA or $10/hr USD \n\n\n\n\nRequired Skills & Experience\n\n\n\n\n Bachelor or above degree in Computer Science or Engineering\n\n 3+ years of professional experience in backend development.\n\n Proficiency in Java and Python.\n\n Proficiency in designing, implementing, and integrating REST API services.\n\n Experienced with cloud-native development, to develop applications using cloud providers (like GCP).\n\n Experienced in designing and implementation of LLM application and AI agent.\n\n In-depth knowledge of machine learning techniques, including embeddings, attention mechanisms, sequence-to-sequence models, generative AI, and more.\n\n Strong analytical and problem-solving skills.\n\n Fluent English communication and strong collaboration skills.\n\n\n\n\nNice to Have Skills & Experience\n\n\n\n\n Familiar with big data technologies, open-source data processing frameworks. E.g., Spark, Hadoop, and so on.\n\n Experience in risk and compliance domain.\n\n Experience working with libraries such as LangChain, LangGraph, CrewAI, AutoGen and other similar frameworks.\n\n\n\n\nJob Description\n\n\n\n\nInsight Global is looking for a Backend Java Developer to join one of the world's leading online payment platform companies based in San Jose, CA. This is a compliance platform team, who is responsible for overseeing and coordinating responses to global regulatory changes that impact the company. This team tracks evolving regulations across jurisdictions, assess business and technology impacts and drive timely implementation to ensure compliance.\n\n\n\n\nThis team enables he company to stay ahead of regulatory developments and maintain operation readiness in a rapidly changing global environment.\n\n\n\n\nYoull be part of a dynamic and evolving landscape, where you can apply your expertise and make meaningful contributions to our platform, leveraging AI/ML solutions to drive greater efficiency.\n\n\n\n\nPrimary Job Responsibilities\n\n Works with business units and Product Dev teams to design, develop and deliver AI & GenAI powered solutions on one of the largest compliance platforms in the world.\n\n Adopt AI/ML models and LLMs to build agentic solutions, leveraging cutting edge technologies to drive innovation.\n\n Join in the design and development of applications, to support business units for compliance and risk management, fraud detection, business insights, predictive analysis, etc.\n\n Work closely with cross-functional global teams and other stakeholders to deliver features.\n\n Lead feature or component design reviews and is fully recognized as the go-to developer for that component.\n\n Participate in architecture discussions and propose and discuss solutions to platform and product changes.\n\n Stay current with emerging technologies and promote a culture of excellence.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4259992858": {
    "job_url": "https://www.linkedin.com/jobs/view/4259992858",
    "job_summary": "EDA R&D Software Engineer\nEDA R&D Software Engineer with verification\nSynopsys Inc\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob profile:\n\nImplementing various product capabilities within the EDA Software R&D team.\nDesigning and architecting software solutions to meet complex development requirements.\nSpecifying, designing, implementing, and testing software in a dynamic development environment.\nConducting design and code reviews to ensure high-quality software delivery.\nDeveloping highly efficient data structures and algorithms that enhance software performance.\nInnovating and advancing the technology in various domains, contributing to cutting-edge chip design solutions.\nDriving innovation in chip design, contributing to market-shaping technologies\n\n\n\n\nKey Skills:\n\nB.Tech/ M.Tech in Computer Science, Computer Engineering, Electrical Engineering, or a related field.\n5+ years of relevant experience in software development.\nStrong programming skills in C/C++.\nExcellent problem-solving and algorithm development skills.\nFamiliarity with software development processes, debugging tools, and configuration management concepts.\nMust have experience in developing EDA Software tools of Synopsys/ Cadence/ Siemens EDA or other EDA companies.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4266956646": {
    "job_url": "https://www.linkedin.com/jobs/view/4266956646",
    "job_summary": "SDET\nSDET with verification\nCoforge\nGreater Bengaluru Area (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJob Title: Quality Engineer-SDET\n\nSkills: Selenium & Java Coding\n\nExperience: 3 - 8 years\n\nLocation: Bengaluru\n\n\n\n\nWe at Coforge are hiring Quality Assurance Engineers with the following skillset:\n\n\n\n\nTesting & automation frameworks as required for their projects.\nWork on multiple projects to improve the company's best practices from a testing standpoint.\n\n\n\n\nResponsibilities:\n\nDesign, implement, & execute test cases\nEvaluate the testing process & make recommendations as necessary.\nTimely execution of test cases.\nIdentify & record bugs\n\n\n\n\nQualifications:\n\nBachelor's degree or equivalent experience in Computer Science.\nTechnical skills in OOP.\nTeam player.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4252153471": {
    "job_url": "https://www.linkedin.com/jobs/view/4252153471",
    "job_summary": "Software Development Engineer - Kubernetes Internals\nSoftware Development Engineer - Kubernetes Internals\nastuto.ai\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nSoftware Engineer - Kubernetes Internals\n\n\n\n\nAbout Us\n\nAstuto is a full-stack Cloud FinOps startup that helps businesses observe, control, and optimize their cloud costs. Our flagship product, OneLens, leverages AI to produce actionable insights, and its best-in-class Workflow engine makes it super easy for businesses to achieve savings faster than others. We are a SOC 2 Type II compliant and ISO 27001 certified company. \n\n\n\n\nRole Summary:\n\nWere looking for a Senior Engineer to help us build the next generation Kubernetes efficiency platform. The engineer will own the design and development of a Kubernetes-native agent that will collect essential cluster data to enable real-time utilization visibility and drive potential automated actions for recommendations. The role will work closely with data engineers to ensure seamless integration with the core OneLens platform. \n\nThe role will evolve into other aspects of Kubernetes automation and security.\n\n\n\n\nRequirements:\n\n4+ years of experience building SaaS or cloud-native products deployed on Kubernetes, preferably in a startup or high-ownership environment\nHands-on experience with at least one major cloud provider (AWS, GCP, or Azure) and its Kubernetes offering (e.g., EKS, GKE, AKS)\nStrong practical Kubernetes expertise, including provisioning, scaling, and optimization of workloads at large scale\nGood knowledge of Kubernetes internals  operators/controllers, API server, and CRDs\nProficient in Go or Python, with the ability to write clean, production-grade backend code\nExperience building or maintaining REST/gRPC APIs, with working knowledge of frontend/backend integration\nFamiliarity with observability stacks (Prometheus, OpenTelemetry, Grafana), with a strong eye for data quality and insights\nSolid skills in system design, debugging, and performance tuning\nGood to have: Exposure to building or managing batch or streaming data pipelines\nStrong team-first mindset, with excellent communication skills and the ability to work independently and cross-functionally\nBonus: Experience working on customer-facing or self-serve SaaS products",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4266996452": {
    "job_url": "https://www.linkedin.com/jobs/view/4266996452",
    "job_summary": "AI Engineer\nAI Engineer\nSwirl\u00ae\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\n\n\n\nSwirl AI turns every product page into a human-like sales conversation, blending LLMs, video understanding, real-time retrieval and agent orchestration. Weve rocketed from 0  Eight Figures of ARR in few months, and demand is outpacing our 7-person tech team. So, we need one extraordinary engineer to own the core of our platform and push it to Silicon Valley scale.\n\n\n\n\n\n\n\nWhat youll do\n\n\n\n\nFirst 90 days\n\n\n\n\n Deep-dive into our multimodal stack (OpenAI-/Claude-based LLMs, custom SLMs, Azure Video Indexer, Pinecone/RAG, LangGraph)\n\n Ship v2 of our SKU-specific video-+-text agent (latency < 500 ms, zero hallucinations).\n\n Productionize auto-evaluation + guardrails (sentiment, brand safety)\n\n Stand up voice & XR modalities and experiment with on-device inference. \n\n\n\n\n6-12 months\n\n\n\n\n Real-time GEO optimisation\n\n Lead design of our agent marketplace: plug-and-play warranty, finance-offer & upsell agents.\n\n Drive infra hardening to handle 10 M+ interactions / month across multiple Fortune-500 sites.\n\n\n\n\nLong term\n\n\n\n\n Build and mentor an elite AI / ML/systems team.\n\n Architect the path to: self-serve onboarding, global content network.\n\n\n\n\nYou might be a fit if you\n\nHave 1-5+ yrs building production systems at scale\nShipped deep-learning products end-to-end: data pipeline  model training/fine-tuning  safety/guardrails  Serving (K8s, CUDA, Triton, Ray, or similar).\nHands-on with multimodal (video, speech, vision) and agentic/RAG architectures.\nFluent in Python/Typescript/Go; can debug distributed systems at 2 a.m. and still think product.\nThrive in zero-to-one chaos: sketch, hack, iterate, talk to customers, then rewrite for scale.\nBelieve ownership > titles, data-driven rigor > ego, and shipping weekly > polishing forever.\n\n\n\n\n\n\n\nWhat success looks like\n\n\n\n\np50 latency < 500 ms for a multimodal query across 100k videos & 10M documents.\nSwirl AI becomes the reference AI Sales Agent demo in every Fortune-100 board deck.\nWe out-innovate incumbents (Salesforce, Adobe, Shopify) by shipping features 4 faster with a team 10 leaner.\n\n\n\n\n\n\n\nComp, stage & perks\n\n\n\n\nTop-of-market cash + meaningful founding equity (were an early-stage, venture-backed rocket).\nChoose your rig: M-series MacBook + 4k monitor or Linux workstation with RTX 6000.\nRemote-first (US / EU / India time overlap) with quarterly off-sites in Dubai, SF & Bangalore.\nVisa support, health + mental-wellness stipend, conference budget, unlimited books.\nReport directly to Kaizad Hansotia (Founder/CEO) & Akshil Shah (CTO) and shape the product thats already trusted by BYD, Toyota, LG & Lennox.\n\n\n\n\n\n\n\nHow to apply\n\n\n\n\nSend GitHub/LinkedIn + 2-3 sentences on the toughest system youve built to careers@goswirl.ai. Side-projects, papers, or a Loom walk-through of your favourite model-ops trick = huge plus.\n\n\n\n\nWe move fast: expect a 48-hr reply  1 technical deep-dive  paid take-home sprint  offer.\n\nJoin us to make product pages talk, show & sell  at human level, globally.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4271176022": {
    "job_url": "https://www.linkedin.com/jobs/view/4271176022",
    "job_summary": "Senior Engineer I [T500-18019]\nSenior Engineer I [T500-18019] with verification\nlululemon\nBengaluru, Karnataka, India (On-site)\n2 school alumni work here\n2 Indian Institute of Technology (Banaras Hindu University), Varanasi school alumni work here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout lululemon:\n\nlululemon is an innovative performance apparel company for yoga, running, training, and other athletic pursuits. Setting the bar in technical fabrics and functional design, we create transformational products and experiences that support people in moving, growing, connecting, and being well. We owe our success to our innovative products, commitment to our people, and the incredible connections we make in every community we're in. As a company, we focus on creating positive change to build a healthier, thriving future. In particular, that includes creating an equitable, inclusive and growth-focused environment for our people. As we continue to elevate our shopping experience, our India Tech Hub plays a key role in expanding our technology capabilities in Product Systems, Merchandising and Planning, Digital Presence, distribution and logistics, and corporate systems. Our team in India works as an extension of the global team on projects of strategic importance.\n\n\n\n\nSenior Engineer I \n\nAbout this team:\n\nProduct Integrity, Sustainability & Compliance Technology team enables Lululemon's supply chain from raw materials to finished good production through innovative technology solutions. Our purpose is to empower the organization to drive innovation and deliver on its strategic vision that includes cultivating a responsible supply chain through sustainable practices while ensuring a superior product quality and compliance. We are a team that dares to innovate, support each other, elevate our partnerships and collaborate while having fun. As an Engineer, you will work as part of a global team supported by our business and architecture partners to help us collaboratively develop and deliver industry leading technology solutions that drive lululemons business goals.\n\n\n\n\nCore Responsibilities:\n\nAs a Senior Engineer I, you will bring a high level of technical knowledge as well as strong mentoring abilities. You will be counted on as a leader in your technology space as you contribute to all areas of development and operations (pre-production to production). You will work closely with a Technology Manager, using your experience and knowledge to guide a team of Engineers though their day-to-day process, and provide a central escalation point for production concerns. You will be part of an Agile production release team and may perform on-call support functions as needed. As a Senior Engineer I, you would be a primary caretaker of production systems and would maintain a deep understanding of how delivered products are functioning.\n\nAre a main contributor in Agile ceremonies\nProvide mentorship and facilitate engineering training for a team of Engineers\nPerform and delegate engineering assignments to ensure production readiness is maintained\nWork closely with global teams to ensure deliver effective technical solutions\nConduct research to aid in product troubleshooting and optimization efforts\nConduct research to guide product development and tools selection\nProvide an escalation point and participate in on-call support rotations\nActively monitor key metrics and report on trends\nParticipate in our Engineering Community of Practice\nContribute to engineering automation, management or development of production level systems\nContribute to project engineering design and standards verification\nPerform reliability monitoring and support as needed to ensure products meet guest expectations\n\n\n\n\nQualifications:\n\nCompleted Bachelors degree or diploma (or equivalent experience) in Computer Science, Software Engineering or Software Architecture preferred; candidates with substantial and relevant industry experience are also eligible\n10 to 12+ years of Full Stack engineering experience\n6+ years of experience with Angular / AngularJS.\n6+ years of experience in HTML, CSS, and writing cross-browser compatible code.\nA solid understanding of AJAX, JavaScript, and the Bootstrap framework (2+ years experience in Bootstrap).\n6+ years of experience with RESTful services.\nFamiliarity with testing frameworks (basic experience, e.g., Cypress).\nHands-on experience implementing complex Angular applications, directives, controllers, and services.\nStrong knowledge and working experience with programming languages such as java\nStrong knowledge and hands-on experience with designing applications using frameworks like Spring Boot & Java microservices\nStrong knowledge and hands-on experience with designing and implementing systems that use cloud technologies and services such as AWS Lambda and AWS S3.\nStrong knowledge and working experience with data integration technologies such as Kafka\nStrong knowledge and working experience with API based system design\nStrong experience working with relational and no-sql databases such as Postgres, MongoDB\nStrong working experience working with containers and container orchestration systems like Kubernetes.\nStrong hands-on experience with designing and implementing CI/CD workflows\nAbility to learn, understand, and work quickly with new emerging technologies, methodologies, and solutions in the Cloud/IT technology space\nGood knowledge and working experience in Agile methodology and familiar with tools like Jira and Confluence\nGood to have knowledge and experience with infrastructure provisioning tools like Terraform and workflow orchestration tools like Airflow\nGood to have experience with cloud data platforms (e.g., Snowflake), ETL, and SQL optimization for large-scale data transformations.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4269432375": {
    "job_url": "https://www.linkedin.com/jobs/view/4269432375",
    "job_summary": "Databricks Engineer\nDatabricks Engineer\nDataE2E Technologies\nIndia (Remote)\nActively reviewing applicants\nViewed\nEasy Apply",
    "job_details": "About the job\n\nJob Title: Databricks Engineer (Remote)\n\nLocation: Remote\n\nJob Type: Full-Time\n\n\n\n\nAbout the Role:\n\nWe are looking for an experienced Databricks Engineer with a strong background in data engineering to help build and optimize scalable, high-performance data solutions. The ideal candidate has hands-on experience in Databricks production environments and a deep understanding of modern data architecture. You'll work with cross-functional teams to create robust data pipelines and ensure the reliability, quality, and observability of data across platforms.\n\n\n\n\nKey Responsibilities:\n\nDesign, build, and manage large-scale data pipelines and ETL/ELT workflows in Databricks using PySpark/Scala.\nDevelop scalable data solutions using Python and SQL across diverse cloud environments (AWS, Azure, or GCP).\nImplement and optimize data lakes, data warehouses, and data mesh architectures using modern storage formats like Parquet, Avro, and Delta Lake.\nEnsure data governance, observability, and quality across all stages of the data lifecycle.\nCollaborate with data architects, analysts, and DevOps teams to drive architecture design, pipeline performance, and deployment practices.\nOptionally, utilize Docker and Kubernetes for containerized data engineering workflows.\n\n\n\n\nRequired Qualifications:\n\n5+ Years of experience in data engineering, including 3+ years in Databricks production environments.\nStrong hands-on expertise in Python, SQL, and Apache Spark (PySpark/Scala).\nExperience working with cloud platforms (AWS, Azure, or GCP) and building cloud-native data pipelines.\nDeep understanding of data lake, data warehouse, and data mesh principles.\nProficiency with file formats like Parquet, Avro, and Delta Lake.\nFamiliarity with containerization and orchestration tools (Docker, Kubernetes) is a plus.\nSolid grasp of data quality, observability, and governance best practices.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4266341485": {
    "job_url": "https://www.linkedin.com/jobs/view/4266341485",
    "job_summary": "CIEM Engineer [T500-19163]\nCIEM Engineer [T500-19163] with verification\nMUFG\nBengaluru, Karnataka, India (On-site)\n1 company alum works here\n1 Walmart Global Tech India company alum works here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nAbout Us:\n\nMUFG Bank, Ltd. is Japans premier bank, with a global network spanning in more than 40 markets. Outside of Japan, the bank offers an extensive scope of commercial and investment banking products and services to businesses, governments, and individuals worldwide. MUFG Banks parent, Mitsubishi UFJ Financial Group, Inc. (MUFG) is one of the worlds leading financial groups. Headquartered in Tokyo and with over 360 years of history, the Group has about 120,000 employees and offers services including commercial banking, trust banking, securities, credit cards, consumer finance, asset management, and leasing. The Group aims to be the worlds most trusted financial group through close collaboration among our operating companies and flexibly respond to all the financial needs of our customers, serving society, and fostering shared and sustainable growth for a better world. MUFGs shares trade on the Tokyo, Nagoya, and New York stock exchanges.\n\n\n\n\nMUFG Global Service Private Limited:\n\nEstablished in 2020, MUFG Global Service Private Limited (MGS) is 100% subsidiary of MUFG having offices in Bengaluru and Mumbai. MGS India has been set up as a Global Capability Centre / Centre of Excellence to provide support services across various functions such as IT, KYC/ AML, Credit, Operations etc. to MUFG Bank offices globally. MGS India has plans to significantly ramp-up its growth over the next 18-24 months while servicing MUFGs global network across Americas, EMEA and Asia Pacific.\n\n\n\n\nPosition details:\n\nAs a CIAM Engineer, you will be responsible for designing, implementing, and maintaining a secure, scalable and efficient CIAM Solution platforms. This role blends deep security engineering expertise with modern data engineering practices to support enterprise-wide initiatives.\n\n\n\n\nRoles and Responsibilities:\n\nSupport the coding, testing, and / or implementation of client/server applications in support of CIAM Platform implementation; fix any existing or new bugs.\nTrack and record technology development needs; provide input or recommendations for enhancements or modifications to the organization's new technology products.\nProvide technical services on information delivery from the server to mobile clients, integrate specific mobile applications into different systems or platforms.\nGather, develop, analyze, and / or document clients' requirements; translate into technical specification, such as product/sprint backlog; facilitate the functionalities of applications aligning with requirements.\nWork with users, visual designers, and product managers to develop visually appealing user dashboard for on-line data analytic products.\nDesign, modify, develop, write, and/or implement software applications, web-based features, and infrastructure according to user needs and business requirements. \nDevelop, test, and/or debug new or enhanced software applications to ensure that quality and functionality are in line with the requirements; document the results of unit and systems testing.\nIntegrate third party services, applications and functionalities to enhance web performance and e-business success.\nUtilize automated testing tools to perform testing and maintenance.\nCreate test transactions and run tests to find errors and revise application programs.\n\n\n\n\nDetails:\n\nData Pipeline Engineering: Design and manage data ingestion pipelines using tools such as Cribl or Observo to collect, filter, and route logs and telemetry data from diverse sources.\nEnsure optimum performance, high availability, scalability, and stability of solutions\nDesign and develop applications, system to system interfaces, and complete software solutions\nCreate documentation such as functional document design, system design document, user guides, and software development guides\nLeverage automation in testing efforts and the ability to identify tests that would be optimal candidates for automation\n\n\n\n\nJob Requirements: \n\nB.S. Computer Science or equivalent prior work experience in a related field\nMinimum 5-6 years of CIAM engineering experience\n5+ years of experience with standards-based integration (including SAML, Oauth, OIDC, and Reverse Proxy) as both Identity provider and as Service provider. \n5+ years of experience with MFA protocols (including Token, OTP, Biometric, Push, QR Code, FIDO2 Compliance).\nExperience in financial services / banking preferred\nExperience with scripting languages such as Python and Bash, OpenShift, Kubernetes, and AWS, Azure, or any cloud provider\nExperience in installing, configuring, and troubleshooting Unix / Linux based environments\nExperience with virtualization and containerization (e.g., VMware, Virtual Box)\nExperience with monitoring systems\nKnowledgeable in CI/CD principles\nKnowledgeable in DevOps workflow tooling \nKnowledgeable on Atlassian Suite (Jira, Confluence, etc.), ServiceNow",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4270624368": {
    "job_url": "https://www.linkedin.com/jobs/view/4270624368",
    "job_summary": "Staff Engineer, Software development Engineering\nStaff Engineer, Software development Engineering with verification\nSandisk\nBengaluru, Karnataka, India (On-site)\n3 school alumni work here\n3 Indian Institute of Technology (Banaras Hindu University), Varanasi school alumni work here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nCompany Description\n\nSandisk understands how people and businesses consume data and we relentlessly innovate to deliver solutions that enable todays needs and tomorrows next big ideas. With a rich history of groundbreaking innovations in Flash and advanced memory technologies, our solutions have become the beating heart of the digital world were living in and that we have the power to shape.\n\nSandisk meets people and businesses at the intersection of their aspirations and the moment, enabling them to keep moving and pushing possibility forward. We do this through the balance of our powerhouse manufacturing capabilities and our industry-leading portfolio of products that are recognized globally for innovation, performance and quality.\n\nSandisk has two facilities recognized by the World Economic Forum as part of the Global Lighthouse Network for advanced 4IR innovations. These facilities were also recognized as Sustainability Lighthouses for breakthroughs in efficient operations. With our global reach, we ensure the global supply chain has access to the Flash memory it needs to keep our world moving forward.\n\nJob Description\n\nWe are seeking a highly motivated and talented Software Development Engineer with background in database management to join our team at Western Digital. In this role, you will play a key role in the development and maintenance of our digital twin platform and database infrastructure. Key responsibilities include:\n\n\nDesign and implement efficient data pipelines to enable seamless information flow within the digital twin platform, including simulators and storage systems.\nEstablish database linkages across platforms, optimizing data structures for scalability and performance to manage large data volumes effectively.\nDevelop ETL (Extract, Transform, Load) pipelines to process raw data into analysis-ready formats..\nLeverage machine learning and data analytics techniques to optimize the design and manufacturing process, develop design recommendation systems, identify anomalies, and support failure analysis.\n\n\nQualifications\n\nREQUIRED:\n\n\nMS Degree in Computer Science, Statistics, Mathematics, Data Science, or related quantitative/engineering field plus >3 years of relevant industrial experience\nProven experience or coursework in database management, data manipulation, and data science.\nProficiency in both front-end and back-end software/website development.\nStrong knowledge of statistical modeling and data science methods (e.g., data cleansing, aggregation, visualization).\nProficient in one or more programming languages such as Python, SQL.\nStrong analytical and quantitative problem-solving ability\nGood communication, relationship skills and a team player\n\n\nPreferred\n\n\nExperience/coursework/research in machine learning and deep learning.\nExperience with frontend framework, such as PyQt6, QtDesigner, React JS, Redux, Axio, HTML, CSS, and JavaScript\nExperience with backend framework, such as FastAPI, Flask, Django\nInterested in semiconductor industry.\n\n\nAdditional Information\n\nSandisk thrives on the power and potential of diversity. As a global company, we believe the most effective way to embrace the diversity of our customers and communities is to mirror it from within. We believe the fusion of various perspectives results in the best outcomes for our employees, our company, our customers, and the world around us. We are committed to an inclusive environment where every individual can thrive through a sense of belonging, respect and contribution.\n\nSandisk is committed to offering opportunities to applicants with disabilities and ensuring all candidates can successfully navigate our careers website and our hiring process. Please contact us at jobs.accommodations@sandisk.com to advise us of your accommodation request. In your email, please include a description of the specific accommodation you are requesting as well as the job title and requisition number of the position for which you are applying.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4268191675": {
    "job_url": "https://www.linkedin.com/jobs/view/4268191675",
    "job_summary": "Artificial Intelligence Engineer\nArtificial Intelligence Engineer\nUST\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nKey Requirements:\n\nOverall 5+ yrs experience with 2+ years of hands-on experience in developing AI/ML applications and intelligent workflows\nProficiency in Python and frameworks such as TensorFlow, PyTorch, Hugging Face, or Scikit-learn\nStrong understanding of machine learning pipelines and deployment\nExperience with cloud AI/ML platforms\nFamiliarity with workflow tools like Airflow, Kubeflow, or LangChain\nExposure to large language models (LLMs) and GenAI tools is a strong plus\nKnowledge of MLOps practices and tools is preferred",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4261893213": {
    "job_url": "https://www.linkedin.com/jobs/view/4261893213",
    "job_summary": "GEN AI ENGINEER\nGEN AI ENGINEER with verification\nAscendion\nBengaluru, Karnataka, India (Hybrid)\nActively reviewing applicants\nViewed\nEasy Apply",
    "job_details": "About the job\n\nGEN AI ENGINEER\n\nLocation: Bangalore, Hyderabad, Chennai and Hyderabad (Hybrid)\n\nYears of Exp: 8 and Above\n\nShift Timings: 4:00 PM to 12:00 AM / Can extend to 1:00 AM\n\n\n\n\n Solutions using LLM\n\n RAG Pipeline\n\n OCR Tools (Azure Doc Intelligence / Tesseract / John Snow Labs)\n\n Image Pre-processing (denoising / enrichment) in OCR pipeline\n\n Frameworks / Platforms - Langchain / LlamaIndex / CrewAI / Semantic Kernel\n\n Systematic LLM Model Evaluation\n\n Prompt Engineering\n\n Agentic Frameworks / MCP / A2A / Function Calling\n\n Vector search, embedding models, and semantic retrieval\n\n Python Programming\n\n Azure AI Services (Open AI, AI Search, Azure AI Hub, Azure ML Studio)\n\n Copilot Studio",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4267747526": {
    "job_url": "https://www.linkedin.com/jobs/view/4267747526",
    "job_summary": "Software Engineer - Must have 1.5 Yrs - Rs 12.4 LPA\nSoftware Engineer - Must have 1.5 Yrs - Rs 12.4 LPA\nthinkbridge\nIndia (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nWe are looking for a Software Engineer with 1.5 years of experience in SQL, HTML, CSS, JavaScript, TypeScript, and C#. The ideal candidate should have strong problem-solving skills & must be proactive in their communication to work closely with our teams and stakeholders.\n\n\n\n\nAbout thinkbridge\n\n\n\n\nWe are a global digital product development firm that helps growth-stage companies gain the technology sophistication and maturity of leading modern digital businesses. We differentiate ourselves by delivering exceptional quality at scale and speed with our thinkstack accelerators. We started with the vision of being able to build amazing software fast. A new way to build software without any of the compromises that currently plague software development. A new way to focus on the outcomes instead of the tech, tools, methodologies, processes and vanity artifacts.\n\n\n\n\nWhy is thinkbridge a great place to work?\n\n\n\n\nAt thinkbridge, we are not just paving the way for exceptional digital experiences; we're also redefining the future of work. Our \"Remote First\" philosophy allows you to take a dive into a world where work doesnt tie you down. Were pioneering a Remote First approach, ensuring youre connected, no matter where you are. We foster and encourage a diverse and inclusive work culture where employees feel valued, respected, are encouraged to voice their ideas, have equal opportunities and are treated fairly. We encourage and provide for our employees' health and well-being initiating wellness programs, provide mental health resources, and ergonomically designed workspaces to support employees physical and mental health. We understand the value of work-life balance, hence we follow Flexible Work Hours, to ensure they can rejuvenate besides managing their personal commitments without much hassle. At thinkbridge, it's more than just a job. It's a journey of innovation, growth, and balance. Join us in shaping the future!\n\n\n\n\nthinkbridge is a place where you can:\n\n\n\n\nThink bigger  because you have the time, opportunity, and support it takes to dig deeper and tackle larger issues.\nMove faster  because youll be working with experienced, helpful teams who can guide you through challenges, quickly resolve issues, and show you new ways to get things done.\nGo further  because you have the opportunity to grow professionally, add new skills, and take on new responsibilities in an organization that takes a long-term view of every relationship.\n\n\n\n\nthinkbridge..theres a new way there. \n\n\n\n\nWhat is expected of you\n\n\n\n\nPractice robust software engineering.\nUnderstand the domain and solve problems for clients.\nRevise, update, refactor and debug existing software.\nUnit Test and deploy applications and systems.\nDevelop documentation throughout the software development life cycle (SDLC).\n\n\n\n\nIf your beliefs resonate with these, you are looking at the right place!\n\n\n\n\nAccountability  Finish what you started.\nCommunication  Context-aware, pro-active and clean communication.\nOutcome  High throughput.\nQuality  High-quality work and consistency.\nOwnership  Go beyond.\n\n\n\n\nWhat We're Looking For\n\n\n\n\nMust have technical skills\n\n\n\n\nSQL\nHTML, CSS, JavaScript\nTypescript, C#\nGit\n\n\n\n\nGood to have skills\n\n\n\n\nExcellent knowledge of SDLC and Unit Testing\nKnowledge of Jira\nLLM Coding Agents\n\n\n\n\nOffer & Benefits:\n\n\n\n\nAn offer will be released only post selection from all the technical tests.\nA qualified candidate will get an offer of 12.4 LPA.\nDedicated Learning & Development Budget: Fuel your growth with a budget dedicated solely to learning.\nCutting-Edge Projects: Work on exciting projects with the latest technologies.\nEmployee-Friendly Leave Policy: Recharge with ample leave options designed for a healthy work-life balance.\n\n\n\n\nOnsite Interview Requirements & Process:\n\n\n\n\nYou must carry your own laptop (Must have MS Word version OR Notepad).\n\n\n\n\nYou will undergo three 90-minute technical tests, conducted in person at our Pune office, located in Baner.\n\n\n\n\nFirst technical test is a 90-minute SQL assessment conducted through Toggl.\nSecond technical test is also a 90-minute bug fixing and code submission challenge, which must be submitted via Git.\nThird technical test will be a 90-minute for Skills Showcase (Using all the technologies and tools).\n\n\n\n\nNote - The Second technical test is of 90 minutes. You will be given a buggy code where you must find the issue and make the code running, and the code should be submitted via Git.\n\n\n\n\nWork Environment\n\n\n\n\nRemote-First Culture: At thinkbridge, we all work from wherever we choose but come together during set hours to collaborate. Using simple online tools, we stay connected and get great work done.\nLeave & Time-off  All leaves taken are paid leaves. And all the leave and time off are likely pre-approved leaves intended for planned vacations, personal commitments, or any other needs requiring prior approval.\nComprehensive Medical & Term Insurance: Full coverage for you and your family, peace of mind.\nWork-From-Workweek (WWW): Twice or thrice a year, we come together for One-week sprints to collaborate in person, foster stronger team bonds, and align on goals. All travel expenses are covered in the form of allowance, which is called as work week allowance.\nWe organize city-wise, company-sponsored local meetupsfun-filled day outings with your colleagues!\nAt thinkbridge, you get reimbursed for approved certifications and short courses that support your role.\nWe embrace diversity and ensure equal opportunity for everyone, fostering an inclusive workplace where all voices are valued.\n\n\n\n\nJoin thinkbridge to be part of a purpose-driven, innovation-led organization that invests in your growth and empowers you to build a brighter future.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4262531397": {
    "job_url": "https://www.linkedin.com/jobs/view/4262531397",
    "job_summary": "Software Engineer - SAP ABAP\nSoftware Engineer - SAP ABAP with verification\nH&M\nBengaluru, Karnataka, India (On-site)\n6 company alumni work here\n6 Walmart Global Tech India company alumni work here\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nCompany Description\n\nJob Description\n\nWhat Youll Do\n\n\nDesign, build, and maintain scalable and high-performing SAP solutions using ABAP and modern SAP technologies.\nCollaborate with cross-functional teams including Product Owners, SAP architects, and functional consultants to translate business requirements into technical specifications.\nWork across SAP modules such as SD, MM, and FI to deliver end-to-end functionalities through configuration, development, testing, and support.\nLeverage modern SAP tools including RAP, CDS, OData, and SAP Gateway for developing APIs and integrations.\nMaintain high-quality code standards through peer reviews, unit testing (ABAP Unit), and continuous integration practices.\nActively contribute to incident resolution and root cause analysis for production issues, ensuring minimal business disruption.\nStay updated with the latest SAP technology trends such as S/4HANA, BTP, and Fiori/UI5, and bring innovation into your daily work.\n\n\n\nWho Youll Work With\n\n\nYoull be part of the SAP Platform Unit within the Product Development & Engineering team.\nYoull work closely with Product Owners, Functional Consultants, Integration Experts, and fellow ABAP Developers to co-create impactful solutions.\nCollaborate within an agile framework (Scrum/Kanban) that promotes continuous delivery, feedback, and iteration.\n\n\n\nWho You Are\n\n\n35 years of hands-on experience in SAP ABAP development.\nProficiency in object-oriented ABAP, CDS Views, AMDP, and OData Services.\nStrong understanding of integration techniques (IDOC, QRFC, CPI, Azure).\nExperience working on S/4 HANA and RAP (RESTful Application Programming Model).\nFamiliarity with SAP Fiori, UI5, Web Dynpro ABAP, and SAP Gateway.\nWorking knowledge of test automation and SAP quality assurance practices.\n\n\n\nAnd People Who Are\n\n\nCollaborative team players with a problem-solving mindset.\nPassionate about building user-centric, reliable solutions.\nEager learners, open to new technologies and development practices.\nStrong communicators who thrive in multicultural, cross-functional environments.\n\n\n\nWho We Are\n\nH&M Group is a global company of strong fashion brands and ventures. Our goal is to prove that exceptional design, affordable prices, and sustainable solutions can co-exist. We are here to democratize fashion for the many  putting customers at the center of every decision.\n\nWe are thousands of passionate individuals working across the globe, united by our shared values and ambition to create a more inclusive, forward-thinking fashion industry.\n\nWhy Youll Love Working Here\n\n\nCompetitive salary and benefits, including our H&M Incentive Program (HIP) and global staff discount across H&M Group brands.\nEndless development opportunities within a global organization committed to learning and innovation.\nInclusive, diverse culture that empowers employees to bring their full selves to work.\nHybrid working models and a modern tech environment.\n\n\n\nJoin Us\n\nOur strength comes from our people  their ideas, perspectives, and the passion they bring. At H&M Group, youll find an environment where you can truly make a difference.\n\nTake the next step in your career  the journey starts here.\n\nWe are committed to a recruitment process that is fair, inclusive, and competency-based. Kindly do not attach a cover letter as part of your application.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4266332613": {
    "job_url": "https://www.linkedin.com/jobs/view/4266332613",
    "job_summary": "Python API Developer\nPython API Developer with verification\nXebia\nIndia (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\n Job Title: Python API Developer\n\n Preferred Locations:\n\n 1st Preference: Noida\n\n 2nd Preference: Hyderabad\n\n Company: Xebia\n\n Experience Level: 57 Years\n\n Work Mode: Hybrid (3 days/week from office)\n\n Join: Immediate joiners or candidates with  15 days' notice\n\n\n\n\n Job Description\n\nWere looking for an experienced Python API Developer to join our growing engineering team at Xebia. In this role, you'll be responsible for developing scalable, secure, and high-performing APIs while integrating seamlessly with cloud services and enterprise platforms.\n\n\n\n\n Key Responsibilities\n\nDesign, develop, and maintain robust APIs using Python.\nImplement security best practices (OAuth, API keys, etc.) for authentication and authorization.\nMonitor, test, and optimize API performance, uptime, and scalability.\nCollaborate with cross-functional teams to enable integration with AWS and Salesforce platforms.\nWork with data structures and mapping strategies for clean and structured data handling.\nContribute to API gateway management and work on AWS EKS clusters.\n\n\n\n\n Your Profile\n\n57 years of hands-on development experience in Python-based APIs.\nStrong grasp of API authentication, authorization, and security standards.\nExperience with API performance tuning and system monitoring tools.\nExposure to Salesforce integration and AWS services.\nUnderstanding of data structures, transformation, and mapping.\nFamiliarity with AWS EKS clusters and API Gateway configuration.\nStrong team player, analytical thinker, and problem-solver.\n\n\n\n\n How to Apply\n\n Immediate Joiners (or  15 Days' Notice) Only\n\nPlease share your resume with the following details to vijay.s@xebia.com:\n\nFull Name:\n\nTotal Experience:\n\nCurrent CTC:\n\nExpected CTC:\n\nCurrent Location:\n\nPreferred Xebia Location (Noida/Hyderabad):\n\nNotice Period / Last Working Day (if serving):\n\nPrimary Skills:\n\nLinkedIn Profile:\n\n\n\n\n Join Xebia and work on modern cloud-native APIs that power enterprise platforms across the globe.\n\n\n\n\n Hybrid Work | Product-Grade Engineering | Enterprise Integrations | High-Impact Projects\n\n #XebiaHiring #PythonDeveloper #APIJobs #ImmediateJoiners #AWS #SalesforceIntegration #HybridJobs #NoidaJobs #HyderabadJobs",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4263123878": {
    "job_url": "https://www.linkedin.com/jobs/view/4263123878",
    "job_summary": "Software and Data Engineer\nSoftware and Data Engineer\nTechKareer\nBengaluru, Karnataka, India (On-site)\n\u20b91.2M/yr - \u20b92.4M/yr\nViewed\nEasy Apply",
    "job_details": "About the job\n\nYou'll build systems and APIs to collect, curate, and analyze data generated by biomedical dogs, devices and patient data.\n\nImmediate Requirements\n\n\nAPIs & backends handling EHR data, time-series sensor streams, and sensor/hardware integrations via REST apis\nData pipelines & analytics for physiological, behavioral, and neural signals\nML & statistical models for biomedical & detection dog research\nWeb & embedded integrations connecting software to real-world devices\n\n\nYou should be familiar with at least a few of the following domains:\n\n\nSignal processing and basic statistics\nStream processing and online algorithms\nDatabases especially time series databases (victoriametrics), SQL. We have postgres, sqlite, duckdb in our stack\nComputer vision, machine learning\n\n\nYou should be an expert in either Python, C++, or Rust. Our stack is Python-heavy with a few modules written in Rust/C++ where needed. Firmware is written in C/C++ (or Rust). If you plan to write C++/Rust, you may have to generate a Python API using pybind11/PyO3.\n\nWhat You'll Do\n\n\nDevelop data pipelines for real-time & batch processing\nBuild robust APIs & backends for devices, research tools, and data systems\nHandle data transformations, storage, and querying for structured & time-series datasets\nEvaluate and improve upon ML models & analytics.\nCollaborate with hardware & research teams to turn messy real-world data into insights\n\n\nWe prioritize data integrity and correctness over brute-force scaling. If you like building reliable software and working with complex real-world data, lets talk.\n\nSkills: backend development,computer vision,data transformations,databases,analytics,data querying,data,c,python,c++,signal processing,data storage,statistical models,api development,rust,data pipelines,firmware development,stream processing,machine learning",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4266117467": {
    "job_url": "https://www.linkedin.com/jobs/view/4266117467",
    "job_summary": "Software Engineer\nSoftware Engineer\nPerigonAI\nBengaluru, Karnataka, India (Remote)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nPerigonAI is a leading geospatial AI company offering platform solutions and bespoke consultancy services across retail, F&B, real estate, smart cities, and urban planning. Our Big Data Lake, geospatial data analytics and ML & AI engines help clients solve real-world business problems globally.\n\nPosition Overview We're seeking a talented Software Engineer to join our growing engineering team and contribute to our cutting-edge geospatial AI platform. You'll work on building scalable solutions that transform complex geospatial data into actionable insights for our global client base.\n\nThis is a remote position for candidates based in Bangalore (or willing to relocate).\n\n\n\n\nRequirements\n\n2+ years of professional software development experience (excluding internships)\nStrong proficiency in React.js for frontend development\nSolid Node.js backend development experience\nAdvanced TypeScript knowledge and implementation skills\nStrong computer science fundamentals and problem-solving abilities\nExperience with modern development practices and collaborative workflows\n\n\n\n\nNice to Have\n\nExperience working with geospatial data and GIS technologies\nFamiliarity with big data technologies and analytics platforms\nExperience with cloud platforms (AWS, Azure, GCP)\nKnowledge of database technologies (SQL/NoSQL)\nExperience with API design and RESTful services\nFamiliarity with DevOps practices and CI/CD pipelines\nExperience with testing frameworks and methodologies\nAbility to start immediately\nBachelor's Degree\nLocated in Bangalore (or willing to relocate)\n\n\n\n\nWhat You'll Do\n\nDevelop and maintain both frontend and backend components of our geospatial AI platform\nCollaborate with data scientists and analysts to implement scalable solutions\nContribute to architecture decisions and technical strategy\nWork with large-scale data processing and visualisation systems\n\n\n\n\nReady to shape the future of geospatial intelligence? Apply now and join our innovative team!",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4266219805": {
    "job_url": "https://www.linkedin.com/jobs/view/4266219805",
    "job_summary": "Engineer, Development\nEngineer, Development\nAptean India\nBengaluru, Karnataka, India (On-site)\nActively reviewing applicants\nViewed\nPromoted\nEasy Apply",
    "job_details": "About the job\n\nJOB DESCRIPTION: \n\n \n\n \n\n1. JOB IDENTIFICATION\n\nAPTEAN JOB TABLE: \n\nAPTEAN JOB LEVEL: B\n\nAPTEAN JOB TITLE: Engineer, Development \n\n \n\n2. GENERAL JOB SUMMARY \n\n \n\n AI Working knowledge creating AI Agents from development through Deployment\n\n Taking Ownership of Development Activities. \n\n Excellent communication skills across cultures. \n\n Must exhibit excellent Debugging and Analytical skills.\n\n Must have knowledge around troubleshooting, Performance, Deployment, Debugging using Analyzing tools.\n\n Closely work with Support Team and Tech Hub Team.\n\n Experience in Performance and Security Testing.\n\n Owning Critical customer issues and drive through the fixture. \n\n Writing secure, reusable, efficient code with high standards and enforce the same to the team and peers through code reviews.\n\n Working with the Product Owner, Product Manager, Architect and other leads within the team reviewing project\\feature specifications.\n\n Working with the Architect and other leads architecturally designing and delivering high quality, secure and performant features.\n\n Participate in all phases of the lifecycle from understanding requirements through development and finally to any post deployment maintenance activities.\n\n Working within an Agile team implementing features and guiding juniors.\n\n Taking ownership of sprints, features and implementations hitting tight deadlines when needed and reporting on the same to managers.\n\n \n\n \n\n3. SCOPE \n\nKnowledge: AI Agents dev and deployment, C#.net, SQL Server, AWS[S3,SQS, Lambda, Dynamo DB], HTML, CSS, APIs , Sencha/Angular/React framework, Office Web Add-ins, Web Application Architecture.\n\n \n\nComplexity: Expert [4+ years Exp]\n\nSupervision: Yes[ has to supervise Team]\n\n \n\n \n\n4. ORGANIZATION (Indicate the job positions reporting to this role)\n\nFull line: R&D\n\n Job (# of positions): 1\n\nDotted line:\n\n Job (# of positions): \n\n \n\n5. PRINCIPAL DUTIES AND RESPONSIBILITIES \n\n \n\n Usage of AI Models for dev\n\n Web Development and testing of software applications and solutions.\n\n Liaison with Performance and Security Testing Teams.\n\n Need to write Stored Procedures and functions.\n\n Have a good grip on finetuning Application and SQL performance issue.\n\n Must maintain ETL process.\n\n Write APIs and debug using Postman or other tools.\n\n Need to exhibit excellent Analytica and debugging skills and guide team.\n\n Builds and assembles prototype assimilations of software applications and solutions as directed.\n\n Writes code, completes programming, and debugs software applications and solutions.\n\n Review the code and maintain best practices on Dev-Ops.\n\n Maintain SAST and DAST standards. \n\n Owning tasks and drive results towards end-to-end delivery. \n\n Deliver high quality software applications and solutions that are extensible and scalable within the specified timeline.\n\n \n\n \n\n6. JOB SPECIFICATIONS \n\nEducation (Indicate the minimum level of education necessary for this position. Check all that apply and indicate specific degree as applicable to the side (e.g., Bachelors in Computer Science)\n\nRequired Preferred Degree/Certification\n\n   Bachelors degree[BE/BTech]\n\n   Masters degree\n\n   Ph.D.\n\n   J.D. (law)\n\n   Certification: \n\n   Registration:\n\n   Licensure: \n\n   Other: \n\n \n\nWork Experience\n\n \n\n \n\nKnowledge, Skills and Abilities\n\n \n\n AI working knowledge must in developing AI Agents.\n\n Advanced level programming in C# .Net framework and .NET Core, WCF, JavaScript, HTML, CSS, SQL, APIs.\n\n Dev-Ops, CI/CD, Terraforms etc.\n\n Proven experience designing and writing secure and performant applications.\n\n Experience writing technical and functional specifications for product features.\n\n Drive for innovation and learning.\n\n Excellent communication skills with the ability to communicate across cultures and a proven track record mentoring juniors.\n\n Experience working in an Agile methodology.\n\n Strong knowledge of cloud technologies and interest in furthering understanding of designs and best practices for cloud services\n\n Must have strong grip in executing the tasks and achieving the results by working with the Team. \n\n \n\n \n\nDISCLAIMER \n\nThe preceding job description has been designed to indicate the general nature and level of work performed by employees within this classification. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job.",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  },
  "https://www.linkedin.com/jobs/view/4269430123": {
    "job_url": "https://www.linkedin.com/jobs/view/4269430123",
    "job_summary": "SDE 2 \u2013 Backend (Java)- Fintech\nSDE 2 \u2013 Backend (Java)- Fintech\nHYrEzy Tech Solutions\nBengaluru, Karnataka, India (On-site)\n\u20b92.5M/yr - \u20b94.5M/yr\nViewed\nEasy Apply",
    "job_details": "About the job\n\nJob Title: Software Development Engineer 2  Backend (Java)\n\nLocation: Bengaluru (India)\n\nExperience Required: 4+ Years\n\nJob Type: Full-Time | Permanent\n\nDomain: Fintech\n\nAbout the Role:-\n\nOur client, a well-funded and fast-growing AI-first fintech SaaS platform, is seeking Backend Engineers (SDE2 level) to join their dynamic product engineering team. You'll help build scalable and secure tax and finance automation solutions powered by AI, contributing to the platforms rapid growth and innovation.\n\nKey Responsibilities:-\n\n\nDesign, develop, test, and deploy scalable backend services using Java.\nBuild RESTful APIs and scalable microservices in a cloud-native architecture.\nEnsure systems are optimized for performance, security, and fault tolerance.\nCollaborate with product managers, frontend engineers, and other stakeholders.\nContribute to low-level design and participate in regular code reviews.\nWork in an agile, fast-paced product environment with weekly/bi-weekly deployments.\n\n\nWhat Were Looking For:-\n\n\n4+ years of strong backend development experience using Java.\nSolid command over Data Structures, Algorithms, and Low-Level Design (LLD).\nExperience building and scaling services in a cloud-based environment (AWS/GCP/Azure).\nExposure to NoSQL/SQL databases, distributed systems, and message queues.\nPrior experience working in a fast-paced product company or fintech domain is a plus.\nComputer Science Degree (preferably from IIT/NIT/BITS or other Tier-1 institutes).\n\n\nWhy Join?\n\n\nJoin a venture-backed product team solving high-impact real-world fintech problems.\nBe part of a team of 125+ professionals shaping intelligent financial infrastructure.\nBuild on a modern tech stack and work closely with product thinkers and innovators\n\n\nSkills: nosql/sql databases,cloud-native architecture,data structures, algorithms,data structures,hld,message queues,azure,low-level design (lld),sql,restful apis,low-level design,aws,gcp,java,algorithms,distributed systems,nosql,microservices",
    "failed_reason": "",
    "hiring_team": null,
    "connections": null,
    "applied": false,
    "easy_apply": true
  }
}